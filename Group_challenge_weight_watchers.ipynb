{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "WWrRFeKRX-DI",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import libraries and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDtRGZMPNrAM",
    "outputId": "ffc1fd2b-0bac-4a28-e9dd-de135042cc38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\panda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\panda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gc\n",
    "import gensim.downloader as api\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from math import ceil\n",
    "import torch.optim as optim\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load GloVe model with Gensim's API - Twitter specific embedding\n",
    "embeddings_model = api.load(\"glove-twitter-200\")  # 200-dimensional GloVe embeddings\n",
    "\n",
    "#To check that T4 GPU is connected\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"modin[all]\"\n",
    "# import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install swifter\n",
    "# import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csoDmI8_X2OO"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "5SVFWTlQX0Jy",
    "outputId": "137b7b7f-e522-433b-9a21-04250b9125db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArgentinaBelgium72.csv\n",
      "ArgentinaGermanyFinal77.csv\n",
      "AustraliaNetherlands29.csv\n",
      "AustraliaSpain34.csv\n",
      "BelgiumSouthKorea59.csv\n",
      "CameroonBrazil36.csv\n",
      "FranceGermany70.csv\n",
      "FranceNigeria66.csv\n",
      "GermanyAlgeria67.csv\n",
      "GermanyBrazil74.csv\n",
      "GermanyUSA57.csv\n",
      "HondurasSwitzerland54.csv\n",
      "MexicoCroatia37.csv\n",
      "NetherlandsChile35.csv\n",
      "PortugalGhana58.csv\n",
      "USASlovenia2010.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @2014WorIdCup: Argentina vs Belgium\\n\\nWho ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@elijahman_ time to focus on Belgium winning t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @FIFAWorldCup: GLOBAL STADIUM: #Joinin with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @CatholicNewsSvc: #PopeFrancis. Uh-oh. Arge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @soccerdotcom: If he scores vs #BEL we'll a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @nytimes FIFA World Cup -- Final Score: U.S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>Ugh!!! should've been 3-2 USA!  #worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @jaclynkeough: Ha! RT @someecards I'd rathe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @gustavaulia: So many surprises at worldcup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @themotleyfool: Also, Team #USA got robbed....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID MatchID  PeriodID  EventType  \\\n",
       "0           0_0       0         0          0   \n",
       "1           0_0       0         0          0   \n",
       "2           0_0       0         0          0   \n",
       "3           0_0       0         0          0   \n",
       "4           0_0       0         0          0   \n",
       "...         ...     ...       ...        ...   \n",
       "5056045  15_129      15       129          0   \n",
       "5056046  15_129      15       129          0   \n",
       "5056047  15_129      15       129          0   \n",
       "5056048  15_129      15       129          0   \n",
       "5056049  15_129      15       129          0   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        RT @2014WorIdCup: Argentina vs Belgium\\n\\nWho ...  \n",
       "1        @elijahman_ time to focus on Belgium winning t...  \n",
       "2        RT @FIFAWorldCup: GLOBAL STADIUM: #Joinin with...  \n",
       "3        RT @CatholicNewsSvc: #PopeFrancis. Uh-oh. Arge...  \n",
       "4        RT @soccerdotcom: If he scores vs #BEL we'll a...  \n",
       "...                                                    ...  \n",
       "5056045  RT @nytimes FIFA World Cup -- Final Score: U.S...  \n",
       "5056046          Ugh!!! should've been 3-2 USA!  #worldcup  \n",
       "5056047  RT @jaclynkeough: Ha! RT @someecards I'd rathe...  \n",
       "5056048  RT @gustavaulia: So many surprises at worldcup...  \n",
       "5056049  RT @themotleyfool: Also, Team #USA got robbed....  \n",
       "\n",
       "[5056050 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all training files and concatenate them into one dataframe\n",
    "\n",
    "#import os\n",
    "#print(os.getcwd())\n",
    "\n",
    "li = []\n",
    "i = 0\n",
    "for filename in listdir(\"train_tweets\"):\n",
    "    if filename != '.ipynb_checkpoints':\n",
    "        print(filename)\n",
    "        df = pd.read_csv(\"train_tweets/\" + filename)\n",
    "        df.drop(columns=['Timestamp'], inplace=True)\n",
    "        # drop unused column(s)\n",
    "        df['MatchID'] = str(i)\n",
    "        df['ID'] = str(i)+ '_' + df['PeriodID'].astype(str)\n",
    "        # makes sure that the match IDs are ordered from 0,1,2... with no missing values\n",
    "        i+=1\n",
    "        li.append(df)\n",
    "df = pd.concat(li, ignore_index=True)\n",
    "#print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true,
    "id": "zTYShYPVXs2w",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing of tweet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenization\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pCBsffiAbRM0",
    "outputId": "38b4c93f-5af9-444c-c2fa-19a31b586353"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9192bc66e1a4731897585fea23839c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5056050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply preprocessing to each tweet\n",
    "df['Tweet'] = df['Tweet'].swifter.apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YW4PGmMxrF4r"
   },
   "source": [
    "# Tweet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fP-s9Uqmot9q"
   },
   "outputs": [],
   "source": [
    "# Get vector tweet embeddings\n",
    "# TODOOOOOOOOOOOOOOOO maybe instead of avg word embedding for each tweet can get sentence\n",
    "#   embeddings to retain more information\n",
    "#   -> can try more complex functions here\n",
    "#   -> avg embedding of each word for a tweet is fine for now, maybe works well enough\n",
    "\n",
    "# Function to compute the average word vector for a tweet\n",
    "def get_avg_embedding(tweet, model, vector_size=200):\n",
    "    words = tweet.split()  # Tokenize by whitespace\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if not word_vectors:  # If no words in the tweet are in the vocabulary, return a zero vector\n",
    "        return np.zeros(vector_size)\n",
    "    return np.sum(word_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEBgxG9xvc9p"
   },
   "outputs": [],
   "source": [
    "# Crashes after using all available RAM :( on google colab\n",
    "# \n",
    "\n",
    "# obtain vector tweet embeddings\n",
    "vector_size = 200  # Adjust based on the chosen GloVe model\n",
    "# tweet_vectors = np.vstack([get_avg_embedding(tweet, embeddings_model, vector_size) for tweet in df['Tweet']])\n",
    "# tweet_df = pd.DataFrame(tweet_vectors)\n",
    "# tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b354b17bcb46969b692b61ebaef06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/5056050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "df[\"tweet_vector\"] = df[\"Tweet\"].swifter.apply(partial(get_avg_embedding, model=embeddings_model,vector_size=vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4b4cFEFb-qo4"
   },
   "outputs": [],
   "source": [
    "# Attach the vectors into the original dataframe\n",
    "# df = pd.concat([df, tweet_df], axis=1)\n",
    "\n",
    "# Drop the columns that are not useful anymore\n",
    "# no need for Tweet column since we have its corresponding vector embedding\n",
    "df.drop(columns=['Tweet'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.8516128, 2.6584997, -0.28650498, 0.00972297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.68378395, 1.078068, 0.556275, -1.0781101, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.43702668, 2.7180884, 0.44844595, -2.479747...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.81652, 2.24445, -0.59934795, -0.66496515, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.5087266, 6.0086, -0.40718204, -0.7157027, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID MatchID  PeriodID  EventType  \\\n",
       "0  0_0       0         0          0   \n",
       "1  0_0       0         0          0   \n",
       "2  0_0       0         0          0   \n",
       "3  0_0       0         0          0   \n",
       "4  0_0       0         0          0   \n",
       "\n",
       "                                        tweet_vector  \n",
       "0  [1.8516128, 2.6584997, -0.28650498, 0.00972297...  \n",
       "1  [0.68378395, 1.078068, 0.556275, -1.0781101, -...  \n",
       "2  [-0.43702668, 2.7180884, 0.44844595, -2.479747...  \n",
       "3  [1.81652, 2.24445, -0.59934795, -0.66496515, -...  \n",
       "4  [2.5087266, 6.0086, -0.40718204, -0.7157027, 0...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.8516128, 2.6584997, -0.28650498, 0.00972297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.68378395, 1.078068, 0.556275, -1.0781101, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.43702668, 2.7180884, 0.44844595, -2.479747...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.81652, 2.24445, -0.59934795, -0.66496515, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.5087266, 6.0086, -0.40718204, -0.7157027, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.8213418, 4.1725197, 3.30757, -3.5441713, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0414053, 0.5316, 0.98389703, 0.025289953, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.3141033, 4.4534097, 0.09538996, -0.5942371,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8237283, 2.6634202, 1.17653, -0.04314803, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>[3.1642876, 4.1183667, -0.663573, -1.8473239, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID MatchID  PeriodID  EventType  \\\n",
       "0           0_0       0         0          0   \n",
       "1           0_0       0         0          0   \n",
       "2           0_0       0         0          0   \n",
       "3           0_0       0         0          0   \n",
       "4           0_0       0         0          0   \n",
       "...         ...     ...       ...        ...   \n",
       "5056045  15_129      15       129          0   \n",
       "5056046  15_129      15       129          0   \n",
       "5056047  15_129      15       129          0   \n",
       "5056048  15_129      15       129          0   \n",
       "5056049  15_129      15       129          0   \n",
       "\n",
       "                                              tweet_vector  \n",
       "0        [1.8516128, 2.6584997, -0.28650498, 0.00972297...  \n",
       "1        [0.68378395, 1.078068, 0.556275, -1.0781101, -...  \n",
       "2        [-0.43702668, 2.7180884, 0.44844595, -2.479747...  \n",
       "3        [1.81652, 2.24445, -0.59934795, -0.66496515, -...  \n",
       "4        [2.5087266, 6.0086, -0.40718204, -0.7157027, 0...  \n",
       "...                                                    ...  \n",
       "5056045  [2.8213418, 4.1725197, 3.30757, -3.5441713, 1....  \n",
       "5056046  [1.0414053, 0.5316, 0.98389703, 0.025289953, -...  \n",
       "5056047  [0.3141033, 4.4534097, 0.09538996, -0.5942371,...  \n",
       "5056048  [0.8237283, 2.6634202, 1.17653, -0.04314803, 0...  \n",
       "5056049  [3.1642876, 4.1183667, -0.663573, -1.8473239, ...  \n",
       "\n",
       "[5056050 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by now should have df with columns: ID, match id, period id, Event Type, tweet_vector. Tweet_vector is just 200 columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195328f5bd45455c888248f63d555672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# group the tweets into their corresponding periods to generate an average embedding vector for each period\n",
    "# so there are no duplicate period id rows per match\n",
    "# decreases size of data + makes it easier to fit into LSTM model\n",
    "df = df.groupby(['MatchID', 'PeriodID', 'ID']).sum().reset_index()\n",
    "# df['tweet_vector'] = df['tweet_vector'].swifter.apply(np.linalg.norm)\n",
    "df.drop(columns=['ID'], inplace=True) \n",
    "df['MatchID'] = df['MatchID'].astype(int)\n",
    "df['PeriodID'] = df['PeriodID'].astype(int)\n",
    "# need to convert to int before sorting\n",
    "df.sort_values(by=['MatchID', 'PeriodID'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89995.016912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74321.958418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>59479.113281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>76683.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>79997.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>30132.042969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID  EventType  tweet_vector\n",
       "0           0         0          0  89995.016912\n",
       "1           0         1          0  74321.958418\n",
       "2           0         2          0  59479.113281\n",
       "3           0         3          0  76683.356800\n",
       "4           0         4          0  79997.992188\n",
       "...       ...       ...        ...           ...\n",
       "2132        1         1          1      1.000000\n",
       "2133        1         1          1      1.000000\n",
       "2134        1         1          1      1.000000\n",
       "2135        1         1          1      1.000000\n",
       "2136       15       129          0  30132.042969\n",
       "\n",
       "[2137 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"EventType\"] != 0] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0uLXd2pz1CQ"
   },
   "source": [
    "# Separate Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# train on of the first 13 of 16 matches (16*0.8=12.8~=13)\n",
    "# and the test data would be the last 3 matches. \n",
    "# Before submitting on Kaggle we should train on full dataset, so al 16 matches\n",
    "train_percentage = 0.8\n",
    "unique_match_ids = df['MatchID'].unique()\n",
    "print(unique_match_ids)\n",
    "num_matches_training = int(ceil(len(unique_match_ids)*train_percentage))\n",
    "print(num_matches_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "target_match_id = num_matches_training\n",
    "# target_match_id is first match id that will appear in test set\n",
    "# all matches from target_match_id and after will be in test test\n",
    "print(target_match_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df2 = df['MatchID'] == 15\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_index is first row with match id target_match_id\n",
    "# row_index is then the first row of the matches that will go to the test\n",
    "\n",
    "\n",
    "row_index = (df['MatchID'] == target_match_id).idxmax()\n",
    "#row_index = df[df['MatchID'] == target_match_id].first_valid_index()\n",
    "df_X_train = df[:row_index].copy()\n",
    "df_X_test = df[row_index:].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train = df_X_train['EventType']\n",
    "df_y_test = df_X_test['EventType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "        ... \n",
       "1742    4524\n",
       "1743    5069\n",
       "1744    5039\n",
       "1745    4496\n",
       "1746    4489\n",
       "Name: EventType, Length: 1747, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2       780\n",
       "3       964\n",
       "4       920\n",
       "       ... \n",
       "385    1406\n",
       "386    1204\n",
       "387    1088\n",
       "388     979\n",
       "389       0\n",
       "Name: EventType, Length: 390, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test.reset_index(drop=True, inplace=True)\n",
    "df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train.drop(['EventType'], axis=1, inplace=True)\n",
    "df_X_test.drop(['EventType'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89995.016912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74321.958418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>59479.113281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>76683.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>79997.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>12</td>\n",
       "      <td>125</td>\n",
       "      <td>170287.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>182200.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>179321.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>161733.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>173331.843750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1747 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID   tweet_vector\n",
       "0           0         0   89995.016912\n",
       "1           0         1   74321.958418\n",
       "2           0         2   59479.113281\n",
       "3           0         3   76683.356800\n",
       "4           0         4   79997.992188\n",
       "...       ...       ...            ...\n",
       "1742       12       125  170287.890625\n",
       "1743       12       126  182200.671875\n",
       "1744       12       127  179321.937500\n",
       "1745       12       128  161733.671875\n",
       "1746       12       129  173331.843750\n",
       "\n",
       "[1747 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>38095.863281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>32810.191406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>36396.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>41851.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>38474.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>15</td>\n",
       "      <td>125</td>\n",
       "      <td>46413.222656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>15</td>\n",
       "      <td>126</td>\n",
       "      <td>39708.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "      <td>36511.679688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "      <td>33346.469184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>30132.042969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MatchID  PeriodID  tweet_vector\n",
       "0         13         0  38095.863281\n",
       "1         13         1  32810.191406\n",
       "2         13         2  36396.332031\n",
       "3         13         3  41851.816406\n",
       "4         13         4  38474.093750\n",
       "..       ...       ...           ...\n",
       "385       15       125  46413.222656\n",
       "386       15       126  39708.453125\n",
       "387       15       127  36511.679688\n",
       "388       15       128  33346.469184\n",
       "389       15       129  30132.042969\n",
       "\n",
       "[390 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test.reset_index(drop=True, inplace=True)\n",
    "df_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now df_X_train and df_X_test should have columns MatchID, PeriodID, tweet_vector. Tweet_vector is just 200 columns\n",
    "# df_y_train and df_y_test should have 1 column, EventType\n",
    "# the matchids are grouped together so all the rows of the same\n",
    "# match ids are grouped next to each other, and the periodID are ordered chronologically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working on my machine so I keep DF\n",
    "\n",
    "# now we have df_X_train, df_X_test, df_y_train, df_y_test\n",
    "# we no longer need df so we should free up the memory\n",
    "# del df  # remove reference to the original DataFrame\n",
    "# gc.collect()  # force garbage collection to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MatchID  PeriodID\n",
       "0         0       129\n",
       "1         1       179\n",
       "2         2        96\n",
       "3         3       129\n",
       "4         4       129\n",
       "5         5       129\n",
       "6         6       129\n",
       "7         7       129\n",
       "8         8       169\n",
       "9         9       129\n",
       "10       10       129\n",
       "11       11       129\n",
       "12       12       129"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X_train.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "max_periods\n",
    "# as we can see not every match has the same number of periods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MatchID  PeriodID\n",
       "0       13       129\n",
       "1       14       129\n",
       "2       15       129"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X_test.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "max_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data for PyTorch LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor for a PyTorch LSTM should have the shape of (when setting batch_first=True)\n",
    "# (batch_size, seq_len, num_features) when using the batch_first=True parameter\n",
    "# batch_size is number of sequences processed at once\n",
    "\n",
    "# TRY WITHOUT SLIDING WINDOW APPROACH\n",
    "#    which would mean batch size = number of matches\n",
    "#    much easier to format for LSTM as 3D tensor\n",
    "#    dimension of 3D tensor with batch_first=True:(batch_size = num_matches, seq_len = num_periods, num _features = 200)\n",
    "#    (match_id, period_id, num_features=200)\n",
    "#     not every match has the same number of periods!, so seq_len can vary between different matches\n",
    "#     fix: will have to pad with zeroes\n",
    "# we want tensor[match_id][period_id] to return list len 200 of corresponding tweet vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 180, 200)\n",
      "(13, 180)\n"
     ]
    }
   ],
   "source": [
    "# modified for array tweet_vector column\n",
    "def convert_df_to_3D_tensor(df_X, df_y):\n",
    "    # df_X should have columns MatchID, PeriodID, tweet_vector. Tweet_vector is just 200x1 array\n",
    "    # rows with same matchID should be grouped together (adjacent rows)\n",
    "    # df_y should have one column (the EventType)\n",
    "    # returns tensor_X numpy array already padded! shape: (num_matches, max_num_periods, num _features = 200)\n",
    "    # and tensor_y of shape: (num_matches, max_num_periods)\n",
    "    num_matches = len(df_X['MatchID'].unique())\n",
    "    max_periods = df_X.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "    total_max_period = max_periods['PeriodID'].max()\n",
    "    #total_max_period is max seq len\n",
    "\n",
    "    tensor_X = np.zeros((num_matches, total_max_period+1, 200))\n",
    "\n",
    "    tensor_y = np.zeros((num_matches, total_max_period+1))\n",
    "    print(tensor_X.shape)\n",
    "    print(tensor_y.shape)\n",
    "    \n",
    "    i=0\n",
    "    previous_match_id = df_X['MatchID'][0]\n",
    "    for row_index, row in df_X.iterrows():\n",
    "        match_id = int(row['MatchID'])\n",
    "\n",
    "        if match_id != previous_match_id:\n",
    "            i+=1\n",
    "            previous_match_id = match_id\n",
    "        \n",
    "        period_id = int(row['PeriodID'])\n",
    "        \n",
    "        features = row['tweet_vector']  # Skip MatchID and PeriodID\n",
    "        tensor_X[i, period_id, :] = features\n",
    "        tensor_y[i,period_id] = df_y[row_index]\n",
    "        \n",
    "    return tensor_X, tensor_y\n",
    "\n",
    "\n",
    "X_train_tensor, y_train_tensor = convert_df_to_3D_tensor(df_X_train, df_y_train)\n",
    "# X_train_tensor[match_id][period_id] to return list len 200 of corresponding tweet vector\n",
    "# y_train_tensor[match_id][period_id] to return corresponding EventType (1 or 0)\n",
    "# match_id index starts at 0 even if first match in df doesnt have match id 0\n",
    "#X_train_tensor[12][175]\n",
    "#X_train_tensor[12][179]\n",
    "#X_train_tensor[2][129]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train_tensor[0][3])\n",
    "#print(y_train_tensor[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 180, 200])\n",
      "torch.Size([13, 180])\n"
     ]
    }
   ],
   "source": [
    "# SCALE DATA? minmaxscaler for example!\n",
    "# SCALING MIGHT BE UNNECESSARY SINCE OUTPUT OF GLOVE TWEET 200 IS ALREADY SCALED BETWEEN -1 AND 1\n",
    "#scaler = MinMaxScaler()\n",
    "#tensor = scaler.fit_transform(tensor)\n",
    "\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_train_tensor = torch.tensor(X_train_tensor, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_tensor, dtype=torch.float32)\n",
    "\n",
    "print(X_train_tensor.shape)\n",
    "print(y_train_tensor.shape)\n",
    "# X_train_tensor, y_train_tensor are now pytorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO VERIFY ITS CORRECT + MAKE MORE SOPHISTICATED\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out)\n",
    "        out = self.sigmoid(out) # applying sigmoid to convert to probabilities\n",
    "        return out.squeeze(-1)\n",
    "\n",
    "#TODOOOOOOOOOO torch.nn.utils.rnn.pack_padded_sequence. This allows the model to ignore the padded values during computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "all elements of target should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_train_tensor)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#print(f\"shape of outputs: {outputs.shape}\")\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\panda\\miniconda3\\envs\\ipx_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\panda\\miniconda3\\envs\\ipx_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\panda\\miniconda3\\envs\\ipx_torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\panda\\miniconda3\\envs\\ipx_torch\\lib\\site-packages\\torch\\nn\\functional.py:3154\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3152\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: all elements of target should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "hidden_size = 500 # can tune\n",
    "num_layers = 4 # can tune\n",
    "dropout_rate = 0.2 # can tune\n",
    "num_epochs = 500 # can tune\n",
    "lr = 0.001 # can tune\n",
    "\n",
    "model = LSTMModel(input_size=200, hidden_size=hidden_size, num_layers=num_layers, dropout_rate=dropout_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss() # great for binary classification\n",
    "#print(f\"Shape of X_train_tensor: {X_train_tensor.shape}\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    #print(f\"shape of outputs: {outputs.shape}\")\n",
    "    \n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Model is trained! (on training data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 130, 200)\n",
      "(3, 130)\n"
     ]
    }
   ],
   "source": [
    "# convert df_X_test and df_y_test to correct format/dimensions\n",
    "X_test_tensor, y_test_tensor = convert_df_to_3D_tensor(df_X_test, df_y_test)\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_test_tensor = torch.tensor(X_test_tensor, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test_tensor[2][129])\n",
    "#print(y_test_tensor[2][129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "\n",
    "# predictions have values between 0 and 1 because forward pass of LSTM contains sigmoid at output\n",
    "#print(predictions)\n",
    "\n",
    "predicted_classes = (predictions > 0.5).float() # 0.5 is threshold\n",
    "#this converts to same dimensional array of True or false, and .float() converts True to 1 and False to 0\n",
    "\n",
    "#print(predicted_classes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross-Entropy Loss: 1.2680\n",
      "Accuracy: 67.1795\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "\n",
    "loss = criterion(predictions, y_test_tensor) # use predictions for loss calculation\n",
    "\n",
    "print(f\"Binary Cross-Entropy Loss: {loss.item():.4f}\")\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    if y_true.dtype != y_pred.dtype or y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Inputs do not have same type or shape!\")\n",
    "    correct_predictions = (y_true == y_pred).sum().item()\n",
    "    total_predictions = y_true.numel()\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    return accuracy\n",
    "accuracy = accuracy(y_test_tensor, predicted_classes)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "#print(y_test_tensor.shape)\n",
    "#print(predicted_classes.shape)\n",
    "\n",
    "\n",
    "# Visualization of Actual vs Predicted Classes\n",
    "# import matplotlib.pyplot as plt\n",
    "# TODO COULD USE PLT TO VISUALIZE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRAIN MODEL ON ENTIRE TRAINING DATA AND EVALUATE EVAL TWEETS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_X = pd.concat([df_X_train, df_X_test], ignore_index=True)\n",
    "df_y = pd.concat([df_y_train, df_y_test], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df_X_test and df_y_test to correct format/dimensions\n",
    "X_tensor, y_tensor = convert_df_to_3D_tensor(df_X, df_y)\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_tensor = torch.tensor(X_tensor, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "et9Eb8hEz1aC"
   },
   "outputs": [],
   "source": [
    "# NOTES\n",
    "# HOW TO MAKE SURE THAT we:\n",
    "# 1. DO NOT ignore the order of the tweets -> (LSTM)\n",
    "# 2. treat each time period as RELATED to the football match they belong to -> treat each match as a sequence, train LSTM on every sequence\n",
    "#                      since pytorch tensor expects multiple sequences (batches)\n",
    "\n",
    "\n",
    "\n",
    "# for LSTM: Each input sequence should consist of tweets from a specific match, ordered by Period ID.\n",
    "#   tweets of different matches are unrelated, but tweets of a same match are related sequentially (chronologically)\n",
    "#   structure training data such that tweets are grouped by match id, and ordered by period id"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ipx_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
