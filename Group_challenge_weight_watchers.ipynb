{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "WWrRFeKRX-DI",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import libraries and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDtRGZMPNrAM",
    "outputId": "ffc1fd2b-0bac-4a28-e9dd-de135042cc38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/infres/kbrowder-24/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/infres/kbrowder-24/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gc\n",
    "import gensim.downloader as api\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from math import ceil\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load GloVe model with Gensim's API - Twitter specific embedding\n",
    "embeddings_model = api.load(\"glove-twitter-200\")  # 200-dimensional GloVe embeddings\n",
    "\n",
    "#To check that T4 GPU is connected\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csoDmI8_X2OO"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "5SVFWTlQX0Jy",
    "outputId": "137b7b7f-e522-433b-9a21-04250b9125db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AustraliaSpain34.csv\n",
      "PortugalGhana58.csv\n",
      "CameroonBrazil36.csv\n",
      "GermanyBrazil74.csv\n",
      "BelgiumSouthKorea59.csv\n",
      "NetherlandsChile35.csv\n",
      "GermanyAlgeria67.csv\n",
      "FranceGermany70.csv\n",
      "MexicoCroatia37.csv\n",
      "FranceNigeria66.csv\n",
      "AustraliaNetherlands29.csv\n",
      "HondurasSwitzerland54.csv\n",
      "ArgentinaGermanyFinal77.csv\n",
      "ArgentinaBelgium72.csv\n",
      "USASlovenia2010.csv\n",
      "GermanyUSA57.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @soccerdotcom: If #ESP beats #AUS we'll giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit the #SITEP official web site here http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @soccerdotcom: If #ESP beats #AUS we'll giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @worldsoccershop: If there is a winner in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @soccerdotcom: If #AUS beats #ESP we'll giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @BBCSport: Portugal fourth team in top 10 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @NBCSports: USA MOVES ON! Germany beats #US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>Ronaldo could have easily scored 4-5 goals ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @TheSelenatorBoy: Ppl getting mad bc Pepe i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>We grew game after game so we won this one. Al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID MatchID  PeriodID  EventType  \\\n",
       "0           0_0       0         0          0   \n",
       "1           0_0       0         0          0   \n",
       "2           0_0       0         0          0   \n",
       "3           0_0       0         0          0   \n",
       "4           0_0       0         0          0   \n",
       "...         ...     ...       ...        ...   \n",
       "5056045  15_129      15       129          1   \n",
       "5056046  15_129      15       129          1   \n",
       "5056047  15_129      15       129          1   \n",
       "5056048  15_129      15       129          1   \n",
       "5056049  15_129      15       129          1   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        RT @soccerdotcom: If #ESP beats #AUS we'll giv...  \n",
       "1        Visit the #SITEP official web site here http:/...  \n",
       "2        RT @soccerdotcom: If #ESP beats #AUS we'll giv...  \n",
       "3        RT @worldsoccershop: If there is a winner in t...  \n",
       "4        RT @soccerdotcom: If #AUS beats #ESP we'll giv...  \n",
       "...                                                    ...  \n",
       "5056045  RT @BBCSport: Portugal fourth team in top 10 o...  \n",
       "5056046  RT @NBCSports: USA MOVES ON! Germany beats #US...  \n",
       "5056047  Ronaldo could have easily scored 4-5 goals ton...  \n",
       "5056048  RT @TheSelenatorBoy: Ppl getting mad bc Pepe i...  \n",
       "5056049  We grew game after game so we won this one. Al...  \n",
       "\n",
       "[5056050 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all training files and concatenate them into one dataframe\n",
    "\n",
    "#import os\n",
    "#print(os.getcwd())\n",
    "\n",
    "li = []\n",
    "i = 0\n",
    "for filename in listdir(\"train_tweets\"):\n",
    "    if filename != '.ipynb_checkpoints':\n",
    "        print(filename)\n",
    "        df = pd.read_csv(\"train_tweets/\" + filename)\n",
    "        df.drop(columns=['Timestamp'], inplace=True)\n",
    "        # drop unused column(s)\n",
    "        df['MatchID'] = str(i)\n",
    "        df['ID'] = str(i)+ '_' + df['PeriodID'].astype(str)\n",
    "        # makes sure that the match IDs are ordered from 0,1,2... with no missing values\n",
    "        # this is for convenience and so it is easier to debug and follow along\n",
    "        i+=1\n",
    "        li.append(df)\n",
    "df = pd.concat(li, ignore_index=True)\n",
    "#print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true,
    "id": "zTYShYPVXs2w",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing of tweet\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenization\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pCBsffiAbRM0",
    "outputId": "38b4c93f-5af9-444c-c2fa-19a31b586353"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rt soccerdotcom esp beat au well give away spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>visit sitep official web site httptcoehzkslan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rt soccerdotcom esp beat au well give away spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rt worldsoccershop winner au v esp match well ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rt soccerdotcom au beat esp well give away aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>rt bbcsport portugal fourth team top fifa worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>rt nbcsports usa move germany beat usmnt portu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>ronaldo could easily scored goal tonight finis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>rt theselenatorboy ppl getting mad bc pepe bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_129</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>grew game game one always proud portugal matte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID MatchID  PeriodID  EventType  \\\n",
       "0           0_0       0         0          0   \n",
       "1           0_0       0         0          0   \n",
       "2           0_0       0         0          0   \n",
       "3           0_0       0         0          0   \n",
       "4           0_0       0         0          0   \n",
       "...         ...     ...       ...        ...   \n",
       "5056045  15_129      15       129          1   \n",
       "5056046  15_129      15       129          1   \n",
       "5056047  15_129      15       129          1   \n",
       "5056048  15_129      15       129          1   \n",
       "5056049  15_129      15       129          1   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        rt soccerdotcom esp beat au well give away spa...  \n",
       "1        visit sitep official web site httptcoehzkslan ...  \n",
       "2        rt soccerdotcom esp beat au well give away spa...  \n",
       "3        rt worldsoccershop winner au v esp match well ...  \n",
       "4        rt soccerdotcom au beat esp well give away aus...  \n",
       "...                                                    ...  \n",
       "5056045  rt bbcsport portugal fourth team top fifa worl...  \n",
       "5056046  rt nbcsports usa move germany beat usmnt portu...  \n",
       "5056047  ronaldo could easily scored goal tonight finis...  \n",
       "5056048  rt theselenatorboy ppl getting mad bc pepe bra...  \n",
       "5056049  grew game game one always proud portugal matte...  \n",
       "\n",
       "[5056050 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to each tweet\n",
    "df['Tweet'] = df['Tweet'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet'] = df['Tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YW4PGmMxrF4r"
   },
   "source": [
    "# Tweet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fP-s9Uqmot9q"
   },
   "outputs": [],
   "source": [
    "# Get vector tweet embeddings\n",
    "# TODOOOOOOOOOOOOOOOO maybe instead of avg word embedding for each tweet can get sentence\n",
    "#   embeddings to retain more information\n",
    "#   -> can try more complex functions here\n",
    "#   -> avg embedding of each word for a tweet is fine for now, maybe works well enough\n",
    "\n",
    "# Function to compute the average word vector for a tweet\n",
    "def get_avg_embedding(tweet, model, vector_size=200):\n",
    "    words = tweet.split()  # Tokenize by whitespace\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if not word_vectors:  # If no words in the tweet are in the vocabulary, return a zero vector\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(word_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OEBgxG9xvc9p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/kbrowder-24/DeepLearningChallengeCSC_51054_EP/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Pandas Apply: 100%|██████████| 5056050/5056050 [02:22<00:00, 35417.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Crashes after using all available RAM :( on google colab\n",
    "# \n",
    "import swifter\n",
    "\n",
    "# obtain vector tweet embeddings\n",
    "vector_size = 200  # Adjust based on the chosen GloVe model\n",
    "df['tweet_vector'] = df['Tweet'].swifter.apply(get_avg_embedding, model=embeddings_model, vector_size=vector_size)\n",
    "# tweet_vectors = np.vstack([get_avg_embedding(tweet, embeddings_model, vector_size) for tweet in df['Tweet']])\n",
    "# tweet_df = pd.DataFrame(tweet_vectors)\n",
    "# tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066179</td>\n",
       "      <td>0.256214</td>\n",
       "      <td>0.080828</td>\n",
       "      <td>-0.339078</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.146547</td>\n",
       "      <td>0.087490</td>\n",
       "      <td>0.158443</td>\n",
       "      <td>0.247540</td>\n",
       "      <td>-0.031605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215871</td>\n",
       "      <td>-0.080837</td>\n",
       "      <td>0.073679</td>\n",
       "      <td>0.022517</td>\n",
       "      <td>0.070002</td>\n",
       "      <td>0.291239</td>\n",
       "      <td>0.079730</td>\n",
       "      <td>-0.014516</td>\n",
       "      <td>-0.047773</td>\n",
       "      <td>-0.077725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.147469</td>\n",
       "      <td>0.366719</td>\n",
       "      <td>0.104687</td>\n",
       "      <td>0.049433</td>\n",
       "      <td>-0.107243</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.282385</td>\n",
       "      <td>-0.180319</td>\n",
       "      <td>0.176330</td>\n",
       "      <td>0.072163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182058</td>\n",
       "      <td>-0.057134</td>\n",
       "      <td>0.204781</td>\n",
       "      <td>-0.029671</td>\n",
       "      <td>0.042747</td>\n",
       "      <td>-0.094213</td>\n",
       "      <td>0.357618</td>\n",
       "      <td>0.272229</td>\n",
       "      <td>-0.086754</td>\n",
       "      <td>0.139274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223382</td>\n",
       "      <td>0.272528</td>\n",
       "      <td>0.071598</td>\n",
       "      <td>-0.293135</td>\n",
       "      <td>-0.021328</td>\n",
       "      <td>0.048036</td>\n",
       "      <td>0.383690</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>0.172468</td>\n",
       "      <td>0.059215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318161</td>\n",
       "      <td>-0.020952</td>\n",
       "      <td>0.183580</td>\n",
       "      <td>-0.087949</td>\n",
       "      <td>0.183349</td>\n",
       "      <td>-0.040151</td>\n",
       "      <td>0.276681</td>\n",
       "      <td>0.072967</td>\n",
       "      <td>0.056575</td>\n",
       "      <td>-0.014119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.108951</td>\n",
       "      <td>0.288303</td>\n",
       "      <td>0.409793</td>\n",
       "      <td>-0.222190</td>\n",
       "      <td>-0.159377</td>\n",
       "      <td>0.224041</td>\n",
       "      <td>0.826330</td>\n",
       "      <td>0.065553</td>\n",
       "      <td>0.261637</td>\n",
       "      <td>-0.148706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154402</td>\n",
       "      <td>-0.185433</td>\n",
       "      <td>-0.003813</td>\n",
       "      <td>0.109507</td>\n",
       "      <td>-0.344327</td>\n",
       "      <td>-0.001267</td>\n",
       "      <td>0.045143</td>\n",
       "      <td>0.433950</td>\n",
       "      <td>0.021387</td>\n",
       "      <td>0.359580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.112306</td>\n",
       "      <td>0.114112</td>\n",
       "      <td>0.246104</td>\n",
       "      <td>-0.454574</td>\n",
       "      <td>-0.059892</td>\n",
       "      <td>-0.105618</td>\n",
       "      <td>0.328258</td>\n",
       "      <td>-0.055273</td>\n",
       "      <td>0.075983</td>\n",
       "      <td>-0.211882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133122</td>\n",
       "      <td>-0.091702</td>\n",
       "      <td>-0.027074</td>\n",
       "      <td>0.077817</td>\n",
       "      <td>0.030298</td>\n",
       "      <td>0.059711</td>\n",
       "      <td>0.367403</td>\n",
       "      <td>0.361568</td>\n",
       "      <td>-0.169055</td>\n",
       "      <td>0.064508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.066179  0.256214  0.080828 -0.339078  0.017108  0.146547  0.087490   \n",
       "1 -0.147469  0.366719  0.104687  0.049433 -0.107243  0.028485  0.282385   \n",
       "2  0.223382  0.272528  0.071598 -0.293135 -0.021328  0.048036  0.383690   \n",
       "3 -0.108951  0.288303  0.409793 -0.222190 -0.159377  0.224041  0.826330   \n",
       "4 -0.112306  0.114112  0.246104 -0.454574 -0.059892 -0.105618  0.328258   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.158443  0.247540 -0.031605  ... -0.215871 -0.080837  0.073679  0.022517   \n",
       "1 -0.180319  0.176330  0.072163  ... -0.182058 -0.057134  0.204781 -0.029671   \n",
       "2 -0.006551  0.172468  0.059215  ... -0.318161 -0.020952  0.183580 -0.087949   \n",
       "3  0.065553  0.261637 -0.148706  ... -0.154402 -0.185433 -0.003813  0.109507   \n",
       "4 -0.055273  0.075983 -0.211882  ... -0.133122 -0.091702 -0.027074  0.077817   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.070002  0.291239  0.079730 -0.014516 -0.047773 -0.077725  \n",
       "1  0.042747 -0.094213  0.357618  0.272229 -0.086754  0.139274  \n",
       "2  0.183349 -0.040151  0.276681  0.072967  0.056575 -0.014119  \n",
       "3 -0.344327 -0.001267  0.045143  0.433950  0.021387  0.359580  \n",
       "4  0.030298  0.059711  0.367403  0.361568 -0.169055  0.064508  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vectors = np.vstack(df['tweet_vector'])\n",
    "tweet_df = pd.DataFrame(tweet_vectors)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4b4cFEFb-qo4"
   },
   "outputs": [],
   "source": [
    "# Attach the vectors into the original dataframe\n",
    "df = pd.concat([df, tweet_df], axis=1)\n",
    "\n",
    "# Drop the columns that are not useful anymore\n",
    "# no need for Tweet column since we have its corresponding vector embedding\n",
    "df.drop(columns=['tweet_vector'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Tweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066179</td>\n",
       "      <td>0.256214</td>\n",
       "      <td>0.080828</td>\n",
       "      <td>-0.339078</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.146547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215871</td>\n",
       "      <td>-0.080837</td>\n",
       "      <td>0.073679</td>\n",
       "      <td>0.022517</td>\n",
       "      <td>0.070002</td>\n",
       "      <td>0.291239</td>\n",
       "      <td>0.079730</td>\n",
       "      <td>-0.014516</td>\n",
       "      <td>-0.047773</td>\n",
       "      <td>-0.077725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.147469</td>\n",
       "      <td>0.366719</td>\n",
       "      <td>0.104687</td>\n",
       "      <td>0.049433</td>\n",
       "      <td>-0.107243</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182058</td>\n",
       "      <td>-0.057134</td>\n",
       "      <td>0.204781</td>\n",
       "      <td>-0.029671</td>\n",
       "      <td>0.042747</td>\n",
       "      <td>-0.094213</td>\n",
       "      <td>0.357618</td>\n",
       "      <td>0.272229</td>\n",
       "      <td>-0.086754</td>\n",
       "      <td>0.139274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223382</td>\n",
       "      <td>0.272528</td>\n",
       "      <td>0.071598</td>\n",
       "      <td>-0.293135</td>\n",
       "      <td>-0.021328</td>\n",
       "      <td>0.048036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318161</td>\n",
       "      <td>-0.020952</td>\n",
       "      <td>0.183580</td>\n",
       "      <td>-0.087949</td>\n",
       "      <td>0.183349</td>\n",
       "      <td>-0.040151</td>\n",
       "      <td>0.276681</td>\n",
       "      <td>0.072967</td>\n",
       "      <td>0.056575</td>\n",
       "      <td>-0.014119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108951</td>\n",
       "      <td>0.288303</td>\n",
       "      <td>0.409793</td>\n",
       "      <td>-0.222190</td>\n",
       "      <td>-0.159377</td>\n",
       "      <td>0.224041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154402</td>\n",
       "      <td>-0.185433</td>\n",
       "      <td>-0.003813</td>\n",
       "      <td>0.109507</td>\n",
       "      <td>-0.344327</td>\n",
       "      <td>-0.001267</td>\n",
       "      <td>0.045143</td>\n",
       "      <td>0.433950</td>\n",
       "      <td>0.021387</td>\n",
       "      <td>0.359580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.112306</td>\n",
       "      <td>0.114112</td>\n",
       "      <td>0.246104</td>\n",
       "      <td>-0.454574</td>\n",
       "      <td>-0.059892</td>\n",
       "      <td>-0.105618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133122</td>\n",
       "      <td>-0.091702</td>\n",
       "      <td>-0.027074</td>\n",
       "      <td>0.077817</td>\n",
       "      <td>0.030298</td>\n",
       "      <td>0.059711</td>\n",
       "      <td>0.367403</td>\n",
       "      <td>0.361568</td>\n",
       "      <td>-0.169055</td>\n",
       "      <td>0.064508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130473</td>\n",
       "      <td>0.285121</td>\n",
       "      <td>0.018671</td>\n",
       "      <td>-0.052116</td>\n",
       "      <td>0.028197</td>\n",
       "      <td>-0.112828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167767</td>\n",
       "      <td>-0.057690</td>\n",
       "      <td>0.198401</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.162055</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>0.192499</td>\n",
       "      <td>0.099254</td>\n",
       "      <td>-0.090062</td>\n",
       "      <td>0.111031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307439</td>\n",
       "      <td>0.368945</td>\n",
       "      <td>-0.172900</td>\n",
       "      <td>-0.276857</td>\n",
       "      <td>-0.122469</td>\n",
       "      <td>-0.301321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024198</td>\n",
       "      <td>0.115410</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.049138</td>\n",
       "      <td>-0.168726</td>\n",
       "      <td>-0.071524</td>\n",
       "      <td>0.103462</td>\n",
       "      <td>-0.025341</td>\n",
       "      <td>0.071714</td>\n",
       "      <td>-0.055731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147703</td>\n",
       "      <td>0.201878</td>\n",
       "      <td>-0.126858</td>\n",
       "      <td>-0.095563</td>\n",
       "      <td>-0.061741</td>\n",
       "      <td>-0.022171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218651</td>\n",
       "      <td>-0.086297</td>\n",
       "      <td>0.081748</td>\n",
       "      <td>-0.153307</td>\n",
       "      <td>-0.026059</td>\n",
       "      <td>-0.072721</td>\n",
       "      <td>0.151214</td>\n",
       "      <td>-0.086326</td>\n",
       "      <td>-0.116747</td>\n",
       "      <td>-0.127796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.284084</td>\n",
       "      <td>0.080437</td>\n",
       "      <td>0.101969</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.078792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174617</td>\n",
       "      <td>0.055047</td>\n",
       "      <td>-0.047173</td>\n",
       "      <td>-0.010757</td>\n",
       "      <td>0.057742</td>\n",
       "      <td>-0.077205</td>\n",
       "      <td>0.082589</td>\n",
       "      <td>0.080722</td>\n",
       "      <td>0.094374</td>\n",
       "      <td>-0.039958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150365</td>\n",
       "      <td>0.368102</td>\n",
       "      <td>0.212660</td>\n",
       "      <td>-0.239125</td>\n",
       "      <td>0.231010</td>\n",
       "      <td>0.114811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055522</td>\n",
       "      <td>-0.260235</td>\n",
       "      <td>0.108414</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.325267</td>\n",
       "      <td>0.510675</td>\n",
       "      <td>0.093970</td>\n",
       "      <td>0.151666</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.318065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  MatchID  PeriodID  EventType         0         1         2  \\\n",
       "0           0_0        0         0          0  0.066179  0.256214  0.080828   \n",
       "1           0_0        0         0          0 -0.147469  0.366719  0.104687   \n",
       "2           0_0        0         0          0  0.223382  0.272528  0.071598   \n",
       "3           0_0        0         0          0 -0.108951  0.288303  0.409793   \n",
       "4           0_0        0         0          0 -0.112306  0.114112  0.246104   \n",
       "...         ...      ...       ...        ...       ...       ...       ...   \n",
       "5056045  15_169       15       169          0  0.130473  0.285121  0.018671   \n",
       "5056046  15_169       15       169          0  0.307439  0.368945 -0.172900   \n",
       "5056047  15_169       15       169          0  0.147703  0.201878 -0.126858   \n",
       "5056048  15_169       15       169          0  0.016947  0.284084  0.080437   \n",
       "5056049  15_169       15       169          0  0.150365  0.368102  0.212660   \n",
       "\n",
       "                3         4         5  ...       190       191       192  \\\n",
       "0       -0.339078  0.017108  0.146547  ... -0.215871 -0.080837  0.073679   \n",
       "1        0.049433 -0.107243  0.028485  ... -0.182058 -0.057134  0.204781   \n",
       "2       -0.293135 -0.021328  0.048036  ... -0.318161 -0.020952  0.183580   \n",
       "3       -0.222190 -0.159377  0.224041  ... -0.154402 -0.185433 -0.003813   \n",
       "4       -0.454574 -0.059892 -0.105618  ... -0.133122 -0.091702 -0.027074   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "5056045 -0.052116  0.028197 -0.112828  ... -0.167767 -0.057690  0.198401   \n",
       "5056046 -0.276857 -0.122469 -0.301321  ... -0.024198  0.115410  0.005415   \n",
       "5056047 -0.095563 -0.061741 -0.022171  ... -0.218651 -0.086297  0.081748   \n",
       "5056048  0.101969  0.009306  0.078792  ... -0.174617  0.055047 -0.047173   \n",
       "5056049 -0.239125  0.231010  0.114811  ... -0.055522 -0.260235  0.108414   \n",
       "\n",
       "              193       194       195       196       197       198       199  \n",
       "0        0.022517  0.070002  0.291239  0.079730 -0.014516 -0.047773 -0.077725  \n",
       "1       -0.029671  0.042747 -0.094213  0.357618  0.272229 -0.086754  0.139274  \n",
       "2       -0.087949  0.183349 -0.040151  0.276681  0.072967  0.056575 -0.014119  \n",
       "3        0.109507 -0.344327 -0.001267  0.045143  0.433950  0.021387  0.359580  \n",
       "4        0.077817  0.030298  0.059711  0.367403  0.361568 -0.169055  0.064508  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "5056045  0.020693 -0.162055  0.049583  0.192499  0.099254 -0.090062  0.111031  \n",
       "5056046  0.049138 -0.168726 -0.071524  0.103462 -0.025341  0.071714 -0.055731  \n",
       "5056047 -0.153307 -0.026059 -0.072721  0.151214 -0.086326 -0.116747 -0.127796  \n",
       "5056048 -0.010757  0.057742 -0.077205  0.082589  0.080722  0.094374 -0.039958  \n",
       "5056049  0.211310 -0.325267  0.510675  0.093970  0.151666  0.007506  0.318065  \n",
       "\n",
       "[5056050 rows x 204 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by now should have df with columns: ID, match id, period id, Event Type, tweet_vector. Tweet_vector is just 200 columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the tweets into their corresponding periods to generate an average embedding vector for each period\n",
    "# so there are no duplicate period id rows per match\n",
    "# decreases size of data + makes it easier to fit into LSTM model\n",
    "df2 = df.groupby(['MatchID', 'PeriodID', 'ID']).mean().reset_index()\n",
    "df3 = df.groupby(['MatchID', 'PeriodID', 'ID']).std().reset_index().drop(columns=['MatchID', 'PeriodID', 'ID','EventType'])\n",
    "df = pd.concat([df2, df3], axis=1, join='inner')\n",
    "df.drop(columns=['ID'], inplace=True) \n",
    "df['MatchID'] = df['MatchID'].astype(int)\n",
    "df['PeriodID'] = df['PeriodID'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert to int before sorting\n",
    "df.sort_values(by=['MatchID', 'PeriodID'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091459</td>\n",
       "      <td>0.226844</td>\n",
       "      <td>0.094664</td>\n",
       "      <td>-0.141795</td>\n",
       "      <td>-0.008727</td>\n",
       "      <td>0.074108</td>\n",
       "      <td>0.129913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150102</td>\n",
       "      <td>0.139094</td>\n",
       "      <td>0.138360</td>\n",
       "      <td>0.120164</td>\n",
       "      <td>0.186236</td>\n",
       "      <td>0.146713</td>\n",
       "      <td>0.171785</td>\n",
       "      <td>0.153843</td>\n",
       "      <td>0.140646</td>\n",
       "      <td>0.155383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118754</td>\n",
       "      <td>0.224606</td>\n",
       "      <td>0.106361</td>\n",
       "      <td>-0.146739</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>0.092931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145702</td>\n",
       "      <td>0.133928</td>\n",
       "      <td>0.125154</td>\n",
       "      <td>0.131825</td>\n",
       "      <td>0.185473</td>\n",
       "      <td>0.154380</td>\n",
       "      <td>0.178184</td>\n",
       "      <td>0.151329</td>\n",
       "      <td>0.152819</td>\n",
       "      <td>0.171357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105108</td>\n",
       "      <td>0.221155</td>\n",
       "      <td>0.120983</td>\n",
       "      <td>-0.177829</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.067515</td>\n",
       "      <td>0.106421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154059</td>\n",
       "      <td>0.145181</td>\n",
       "      <td>0.141065</td>\n",
       "      <td>0.132949</td>\n",
       "      <td>0.190581</td>\n",
       "      <td>0.154179</td>\n",
       "      <td>0.190066</td>\n",
       "      <td>0.145702</td>\n",
       "      <td>0.139681</td>\n",
       "      <td>0.143230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.114742</td>\n",
       "      <td>0.220896</td>\n",
       "      <td>0.117625</td>\n",
       "      <td>-0.154241</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.066276</td>\n",
       "      <td>0.082330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141530</td>\n",
       "      <td>0.135123</td>\n",
       "      <td>0.133328</td>\n",
       "      <td>0.124843</td>\n",
       "      <td>0.186997</td>\n",
       "      <td>0.141761</td>\n",
       "      <td>0.206638</td>\n",
       "      <td>0.152586</td>\n",
       "      <td>0.141340</td>\n",
       "      <td>0.155276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109419</td>\n",
       "      <td>0.229442</td>\n",
       "      <td>0.113353</td>\n",
       "      <td>-0.161975</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.080471</td>\n",
       "      <td>0.127543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139937</td>\n",
       "      <td>0.133569</td>\n",
       "      <td>0.126487</td>\n",
       "      <td>0.135095</td>\n",
       "      <td>0.175768</td>\n",
       "      <td>0.138774</td>\n",
       "      <td>0.192561</td>\n",
       "      <td>0.150075</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.142274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MatchID  PeriodID  EventType         0         1         2         3  \\\n",
       "0        0         0        0.0  0.091459  0.226844  0.094664 -0.141795   \n",
       "1        0         1        0.0  0.118754  0.224606  0.106361 -0.146739   \n",
       "2        0         2        0.0  0.105108  0.221155  0.120983 -0.177829   \n",
       "3        0         3        1.0  0.114742  0.220896  0.117625 -0.154241   \n",
       "4        0         4        0.0  0.109419  0.229442  0.113353 -0.161975   \n",
       "\n",
       "          4         5         6  ...       190       191       192       193  \\\n",
       "0 -0.008727  0.074108  0.129913  ...  0.150102  0.139094  0.138360  0.120164   \n",
       "1  0.034357  0.057512  0.092931  ...  0.145702  0.133928  0.125154  0.131825   \n",
       "2  0.018819  0.067515  0.106421  ...  0.154059  0.145181  0.141065  0.132949   \n",
       "3  0.013500  0.066276  0.082330  ...  0.141530  0.135123  0.133328  0.124843   \n",
       "4  0.002804  0.080471  0.127543  ...  0.139937  0.133569  0.126487  0.135095   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.186236  0.146713  0.171785  0.153843  0.140646  0.155383  \n",
       "1  0.185473  0.154380  0.178184  0.151329  0.152819  0.171357  \n",
       "2  0.190581  0.154179  0.190066  0.145702  0.139681  0.143230  \n",
       "3  0.186997  0.141761  0.206638  0.152586  0.141340  0.155276  \n",
       "4  0.175768  0.138774  0.192561  0.150075  0.136600  0.142274  \n",
       "\n",
       "[5 rows x 403 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "2132    15\n",
       "2133    15\n",
       "2134    15\n",
       "2135    15\n",
       "2136    15\n",
       "Name: MatchID, Length: 2137, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MatchID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0uLXd2pz1CQ"
   },
   "source": [
    "# Separate Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# train on of the first 13 of 16 matches (16*0.8=12.8~=13)\n",
    "# and the test data would be the last 3 matches. \n",
    "# Before submitting on Kaggle we should train on full dataset, so al 16 matches\n",
    "train_percentage = 0.8\n",
    "unique_match_ids = df['MatchID'].unique()\n",
    "print(unique_match_ids)\n",
    "num_matches_training = int(ceil(len(unique_match_ids)*train_percentage))\n",
    "print(num_matches_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "target_match_id = num_matches_training\n",
    "# target_match_id is first match id that will appear in test set\n",
    "# all matches from target_match_id and after will be in test test\n",
    "print(target_match_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df2 = df['MatchID'] == 15\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_index is first row with match id target_match_id\n",
    "# row_index is then the first row of the matches that will go to the test\n",
    "\n",
    "\n",
    "row_index = (df['MatchID'] == target_match_id).idxmax()\n",
    "#row_index = df[df['MatchID'] == target_match_id].first_valid_index()\n",
    "df_X_train = df[:row_index].copy()\n",
    "df_X_test = df[row_index:].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train = df_X_train['EventType']\n",
    "df_y_test = df_X_test['EventType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       0.0\n",
       "       ... \n",
       "1702    1.0\n",
       "1703    1.0\n",
       "1704    1.0\n",
       "1705    1.0\n",
       "1706    1.0\n",
       "Name: EventType, Length: 1707, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      0.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      1.0\n",
       "      ... \n",
       "425    1.0\n",
       "426    1.0\n",
       "427    1.0\n",
       "428    1.0\n",
       "429    0.0\n",
       "Name: EventType, Length: 430, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test.reset_index(drop=True, inplace=True)\n",
    "df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train.drop(['EventType'], axis=1, inplace=True)\n",
    "df_X_test.drop(['EventType'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091459</td>\n",
       "      <td>0.226844</td>\n",
       "      <td>0.094664</td>\n",
       "      <td>-0.141795</td>\n",
       "      <td>-0.008727</td>\n",
       "      <td>0.074108</td>\n",
       "      <td>0.129913</td>\n",
       "      <td>0.081805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150102</td>\n",
       "      <td>0.139094</td>\n",
       "      <td>0.138360</td>\n",
       "      <td>0.120164</td>\n",
       "      <td>0.186236</td>\n",
       "      <td>0.146713</td>\n",
       "      <td>0.171785</td>\n",
       "      <td>0.153843</td>\n",
       "      <td>0.140646</td>\n",
       "      <td>0.155383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118754</td>\n",
       "      <td>0.224606</td>\n",
       "      <td>0.106361</td>\n",
       "      <td>-0.146739</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>0.092931</td>\n",
       "      <td>0.093373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145702</td>\n",
       "      <td>0.133928</td>\n",
       "      <td>0.125154</td>\n",
       "      <td>0.131825</td>\n",
       "      <td>0.185473</td>\n",
       "      <td>0.154380</td>\n",
       "      <td>0.178184</td>\n",
       "      <td>0.151329</td>\n",
       "      <td>0.152819</td>\n",
       "      <td>0.171357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.105108</td>\n",
       "      <td>0.221155</td>\n",
       "      <td>0.120983</td>\n",
       "      <td>-0.177829</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.067515</td>\n",
       "      <td>0.106421</td>\n",
       "      <td>0.088029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154059</td>\n",
       "      <td>0.145181</td>\n",
       "      <td>0.141065</td>\n",
       "      <td>0.132949</td>\n",
       "      <td>0.190581</td>\n",
       "      <td>0.154179</td>\n",
       "      <td>0.190066</td>\n",
       "      <td>0.145702</td>\n",
       "      <td>0.139681</td>\n",
       "      <td>0.143230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.114742</td>\n",
       "      <td>0.220896</td>\n",
       "      <td>0.117625</td>\n",
       "      <td>-0.154241</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.066276</td>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.101138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141530</td>\n",
       "      <td>0.135123</td>\n",
       "      <td>0.133328</td>\n",
       "      <td>0.124843</td>\n",
       "      <td>0.186997</td>\n",
       "      <td>0.141761</td>\n",
       "      <td>0.206638</td>\n",
       "      <td>0.152586</td>\n",
       "      <td>0.141340</td>\n",
       "      <td>0.155276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.109419</td>\n",
       "      <td>0.229442</td>\n",
       "      <td>0.113353</td>\n",
       "      <td>-0.161975</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.080471</td>\n",
       "      <td>0.127543</td>\n",
       "      <td>0.113681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139937</td>\n",
       "      <td>0.133569</td>\n",
       "      <td>0.126487</td>\n",
       "      <td>0.135095</td>\n",
       "      <td>0.175768</td>\n",
       "      <td>0.138774</td>\n",
       "      <td>0.192561</td>\n",
       "      <td>0.150075</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.142274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>12</td>\n",
       "      <td>125</td>\n",
       "      <td>0.016406</td>\n",
       "      <td>0.207303</td>\n",
       "      <td>0.122610</td>\n",
       "      <td>-0.185337</td>\n",
       "      <td>0.059882</td>\n",
       "      <td>-0.026297</td>\n",
       "      <td>-0.179931</td>\n",
       "      <td>-0.027595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117319</td>\n",
       "      <td>0.077957</td>\n",
       "      <td>0.103621</td>\n",
       "      <td>0.099211</td>\n",
       "      <td>0.100193</td>\n",
       "      <td>0.096737</td>\n",
       "      <td>0.090462</td>\n",
       "      <td>0.100530</td>\n",
       "      <td>0.100542</td>\n",
       "      <td>0.094966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.221915</td>\n",
       "      <td>0.114550</td>\n",
       "      <td>-0.203060</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>-0.014418</td>\n",
       "      <td>-0.184669</td>\n",
       "      <td>-0.022971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117249</td>\n",
       "      <td>0.080074</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.094389</td>\n",
       "      <td>0.092889</td>\n",
       "      <td>0.102525</td>\n",
       "      <td>0.093371</td>\n",
       "      <td>0.089433</td>\n",
       "      <td>0.095177</td>\n",
       "      <td>0.096688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>0.228118</td>\n",
       "      <td>0.106237</td>\n",
       "      <td>-0.203890</td>\n",
       "      <td>0.064713</td>\n",
       "      <td>-0.010159</td>\n",
       "      <td>-0.195339</td>\n",
       "      <td>-0.024019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114349</td>\n",
       "      <td>0.079549</td>\n",
       "      <td>0.091748</td>\n",
       "      <td>0.089967</td>\n",
       "      <td>0.091298</td>\n",
       "      <td>0.100366</td>\n",
       "      <td>0.086416</td>\n",
       "      <td>0.085432</td>\n",
       "      <td>0.094950</td>\n",
       "      <td>0.092479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.216167</td>\n",
       "      <td>0.115334</td>\n",
       "      <td>-0.206855</td>\n",
       "      <td>0.056963</td>\n",
       "      <td>-0.014020</td>\n",
       "      <td>-0.184179</td>\n",
       "      <td>-0.023498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121607</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.096231</td>\n",
       "      <td>0.090386</td>\n",
       "      <td>0.116410</td>\n",
       "      <td>0.102433</td>\n",
       "      <td>0.099101</td>\n",
       "      <td>0.091556</td>\n",
       "      <td>0.097994</td>\n",
       "      <td>0.090036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.154063</td>\n",
       "      <td>0.154744</td>\n",
       "      <td>-0.243277</td>\n",
       "      <td>0.059730</td>\n",
       "      <td>-0.011581</td>\n",
       "      <td>-0.163255</td>\n",
       "      <td>-0.027136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125063</td>\n",
       "      <td>0.128084</td>\n",
       "      <td>0.084811</td>\n",
       "      <td>0.075670</td>\n",
       "      <td>0.176496</td>\n",
       "      <td>0.109646</td>\n",
       "      <td>0.123648</td>\n",
       "      <td>0.109761</td>\n",
       "      <td>0.108878</td>\n",
       "      <td>0.083145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1707 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID         0         1         2         3         4  \\\n",
       "0           0         0  0.091459  0.226844  0.094664 -0.141795 -0.008727   \n",
       "1           0         1  0.118754  0.224606  0.106361 -0.146739  0.034357   \n",
       "2           0         2  0.105108  0.221155  0.120983 -0.177829  0.018819   \n",
       "3           0         3  0.114742  0.220896  0.117625 -0.154241  0.013500   \n",
       "4           0         4  0.109419  0.229442  0.113353 -0.161975  0.002804   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "1702       12       125  0.016406  0.207303  0.122610 -0.185337  0.059882   \n",
       "1703       12       126  0.006691  0.221915  0.114550 -0.203060  0.062033   \n",
       "1704       12       127  0.009526  0.228118  0.106237 -0.203890  0.064713   \n",
       "1705       12       128  0.012527  0.216167  0.115334 -0.206855  0.056963   \n",
       "1706       12       129  0.012556  0.154063  0.154744 -0.243277  0.059730   \n",
       "\n",
       "             5         6         7  ...       190       191       192  \\\n",
       "0     0.074108  0.129913  0.081805  ...  0.150102  0.139094  0.138360   \n",
       "1     0.057512  0.092931  0.093373  ...  0.145702  0.133928  0.125154   \n",
       "2     0.067515  0.106421  0.088029  ...  0.154059  0.145181  0.141065   \n",
       "3     0.066276  0.082330  0.101138  ...  0.141530  0.135123  0.133328   \n",
       "4     0.080471  0.127543  0.113681  ...  0.139937  0.133569  0.126487   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1702 -0.026297 -0.179931 -0.027595  ...  0.117319  0.077957  0.103621   \n",
       "1703 -0.014418 -0.184669 -0.022971  ...  0.117249  0.080074  0.096154   \n",
       "1704 -0.010159 -0.195339 -0.024019  ...  0.114349  0.079549  0.091748   \n",
       "1705 -0.014020 -0.184179 -0.023498  ...  0.121607  0.090769  0.096231   \n",
       "1706 -0.011581 -0.163255 -0.027136  ...  0.125063  0.128084  0.084811   \n",
       "\n",
       "           193       194       195       196       197       198       199  \n",
       "0     0.120164  0.186236  0.146713  0.171785  0.153843  0.140646  0.155383  \n",
       "1     0.131825  0.185473  0.154380  0.178184  0.151329  0.152819  0.171357  \n",
       "2     0.132949  0.190581  0.154179  0.190066  0.145702  0.139681  0.143230  \n",
       "3     0.124843  0.186997  0.141761  0.206638  0.152586  0.141340  0.155276  \n",
       "4     0.135095  0.175768  0.138774  0.192561  0.150075  0.136600  0.142274  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1702  0.099211  0.100193  0.096737  0.090462  0.100530  0.100542  0.094966  \n",
       "1703  0.094389  0.092889  0.102525  0.093371  0.089433  0.095177  0.096688  \n",
       "1704  0.089967  0.091298  0.100366  0.086416  0.085432  0.094950  0.092479  \n",
       "1705  0.090386  0.116410  0.102433  0.099101  0.091556  0.097994  0.090036  \n",
       "1706  0.075670  0.176496  0.109646  0.123648  0.109761  0.108878  0.083145  \n",
       "\n",
       "[1707 rows x 402 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158450</td>\n",
       "      <td>0.257846</td>\n",
       "      <td>-0.022320</td>\n",
       "      <td>-0.093124</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.030830</td>\n",
       "      <td>-0.053258</td>\n",
       "      <td>0.096729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102673</td>\n",
       "      <td>0.083878</td>\n",
       "      <td>0.109620</td>\n",
       "      <td>0.093605</td>\n",
       "      <td>0.115091</td>\n",
       "      <td>0.097729</td>\n",
       "      <td>0.153526</td>\n",
       "      <td>0.091565</td>\n",
       "      <td>0.112612</td>\n",
       "      <td>0.096226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.155688</td>\n",
       "      <td>0.253424</td>\n",
       "      <td>-0.016230</td>\n",
       "      <td>-0.096977</td>\n",
       "      <td>-0.005092</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>-0.054194</td>\n",
       "      <td>0.096167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101436</td>\n",
       "      <td>0.089732</td>\n",
       "      <td>0.119999</td>\n",
       "      <td>0.087486</td>\n",
       "      <td>0.113939</td>\n",
       "      <td>0.102360</td>\n",
       "      <td>0.146392</td>\n",
       "      <td>0.091949</td>\n",
       "      <td>0.106561</td>\n",
       "      <td>0.099398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.151378</td>\n",
       "      <td>0.250213</td>\n",
       "      <td>-0.014755</td>\n",
       "      <td>-0.093997</td>\n",
       "      <td>-0.007001</td>\n",
       "      <td>-0.017874</td>\n",
       "      <td>-0.050230</td>\n",
       "      <td>0.088655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107231</td>\n",
       "      <td>0.090314</td>\n",
       "      <td>0.109008</td>\n",
       "      <td>0.095022</td>\n",
       "      <td>0.122959</td>\n",
       "      <td>0.122943</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.109752</td>\n",
       "      <td>0.097698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.155133</td>\n",
       "      <td>0.225063</td>\n",
       "      <td>-0.012183</td>\n",
       "      <td>-0.098746</td>\n",
       "      <td>-0.018432</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>-0.030708</td>\n",
       "      <td>0.074532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113213</td>\n",
       "      <td>0.092936</td>\n",
       "      <td>0.120383</td>\n",
       "      <td>0.108233</td>\n",
       "      <td>0.122452</td>\n",
       "      <td>0.114112</td>\n",
       "      <td>0.161191</td>\n",
       "      <td>0.090128</td>\n",
       "      <td>0.113850</td>\n",
       "      <td>0.098567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.142482</td>\n",
       "      <td>0.219091</td>\n",
       "      <td>-0.001141</td>\n",
       "      <td>-0.105878</td>\n",
       "      <td>-0.024851</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>-0.063107</td>\n",
       "      <td>0.073013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116427</td>\n",
       "      <td>0.094589</td>\n",
       "      <td>0.124652</td>\n",
       "      <td>0.109602</td>\n",
       "      <td>0.125495</td>\n",
       "      <td>0.116472</td>\n",
       "      <td>0.161296</td>\n",
       "      <td>0.093904</td>\n",
       "      <td>0.115509</td>\n",
       "      <td>0.099558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>0.128309</td>\n",
       "      <td>0.238830</td>\n",
       "      <td>0.046353</td>\n",
       "      <td>-0.057035</td>\n",
       "      <td>-0.072904</td>\n",
       "      <td>0.057241</td>\n",
       "      <td>0.130987</td>\n",
       "      <td>0.057935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137781</td>\n",
       "      <td>0.158275</td>\n",
       "      <td>0.164880</td>\n",
       "      <td>0.113359</td>\n",
       "      <td>0.131535</td>\n",
       "      <td>0.134531</td>\n",
       "      <td>0.128150</td>\n",
       "      <td>0.126427</td>\n",
       "      <td>0.135111</td>\n",
       "      <td>0.126775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>15</td>\n",
       "      <td>166</td>\n",
       "      <td>0.131207</td>\n",
       "      <td>0.238868</td>\n",
       "      <td>0.049916</td>\n",
       "      <td>-0.061460</td>\n",
       "      <td>-0.069031</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.131640</td>\n",
       "      <td>0.062507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141206</td>\n",
       "      <td>0.161633</td>\n",
       "      <td>0.166177</td>\n",
       "      <td>0.113479</td>\n",
       "      <td>0.132183</td>\n",
       "      <td>0.131873</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.126706</td>\n",
       "      <td>0.145706</td>\n",
       "      <td>0.127274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>0.126975</td>\n",
       "      <td>0.240796</td>\n",
       "      <td>0.047862</td>\n",
       "      <td>-0.051878</td>\n",
       "      <td>-0.067845</td>\n",
       "      <td>0.049647</td>\n",
       "      <td>0.120679</td>\n",
       "      <td>0.055225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140779</td>\n",
       "      <td>0.155717</td>\n",
       "      <td>0.165043</td>\n",
       "      <td>0.118110</td>\n",
       "      <td>0.132331</td>\n",
       "      <td>0.127123</td>\n",
       "      <td>0.134572</td>\n",
       "      <td>0.124080</td>\n",
       "      <td>0.143820</td>\n",
       "      <td>0.125589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>0.128527</td>\n",
       "      <td>0.245419</td>\n",
       "      <td>0.044214</td>\n",
       "      <td>-0.055183</td>\n",
       "      <td>-0.067618</td>\n",
       "      <td>0.038687</td>\n",
       "      <td>0.119808</td>\n",
       "      <td>0.060817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136859</td>\n",
       "      <td>0.158013</td>\n",
       "      <td>0.167696</td>\n",
       "      <td>0.115239</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.127883</td>\n",
       "      <td>0.132546</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.140298</td>\n",
       "      <td>0.125825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0.128165</td>\n",
       "      <td>0.241196</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>-0.055317</td>\n",
       "      <td>-0.065858</td>\n",
       "      <td>0.041221</td>\n",
       "      <td>0.123674</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133160</td>\n",
       "      <td>0.156094</td>\n",
       "      <td>0.164026</td>\n",
       "      <td>0.115201</td>\n",
       "      <td>0.127064</td>\n",
       "      <td>0.131418</td>\n",
       "      <td>0.132319</td>\n",
       "      <td>0.121540</td>\n",
       "      <td>0.141156</td>\n",
       "      <td>0.125358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MatchID  PeriodID         0         1         2         3         4  \\\n",
       "0         13         0  0.158450  0.257846 -0.022320 -0.093124 -0.002387   \n",
       "1         13         1  0.155688  0.253424 -0.016230 -0.096977 -0.005092   \n",
       "2         13         2  0.151378  0.250213 -0.014755 -0.093997 -0.007001   \n",
       "3         13         3  0.155133  0.225063 -0.012183 -0.098746 -0.018432   \n",
       "4         13         4  0.142482  0.219091 -0.001141 -0.105878 -0.024851   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "425       15       165  0.128309  0.238830  0.046353 -0.057035 -0.072904   \n",
       "426       15       166  0.131207  0.238868  0.049916 -0.061460 -0.069031   \n",
       "427       15       167  0.126975  0.240796  0.047862 -0.051878 -0.067845   \n",
       "428       15       168  0.128527  0.245419  0.044214 -0.055183 -0.067618   \n",
       "429       15       169  0.128165  0.241196  0.046135 -0.055317 -0.065858   \n",
       "\n",
       "            5         6         7  ...       190       191       192  \\\n",
       "0   -0.030830 -0.053258  0.096729  ...  0.102673  0.083878  0.109620   \n",
       "1   -0.027170 -0.054194  0.096167  ...  0.101436  0.089732  0.119999   \n",
       "2   -0.017874 -0.050230  0.088655  ...  0.107231  0.090314  0.109008   \n",
       "3    0.003481 -0.030708  0.074532  ...  0.113213  0.092936  0.120383   \n",
       "4    0.008641 -0.063107  0.073013  ...  0.116427  0.094589  0.124652   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "425  0.057241  0.130987  0.057935  ...  0.137781  0.158275  0.164880   \n",
       "426  0.056109  0.131640  0.062507  ...  0.141206  0.161633  0.166177   \n",
       "427  0.049647  0.120679  0.055225  ...  0.140779  0.155717  0.165043   \n",
       "428  0.038687  0.119808  0.060817  ...  0.136859  0.158013  0.167696   \n",
       "429  0.041221  0.123674  0.059436  ...  0.133160  0.156094  0.164026   \n",
       "\n",
       "          193       194       195       196       197       198       199  \n",
       "0    0.093605  0.115091  0.097729  0.153526  0.091565  0.112612  0.096226  \n",
       "1    0.087486  0.113939  0.102360  0.146392  0.091949  0.106561  0.099398  \n",
       "2    0.095022  0.122959  0.122943  0.153790  0.089571  0.109752  0.097698  \n",
       "3    0.108233  0.122452  0.114112  0.161191  0.090128  0.113850  0.098567  \n",
       "4    0.109602  0.125495  0.116472  0.161296  0.093904  0.115509  0.099558  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "425  0.113359  0.131535  0.134531  0.128150  0.126427  0.135111  0.126775  \n",
       "426  0.113479  0.132183  0.131873  0.130081  0.126706  0.145706  0.127274  \n",
       "427  0.118110  0.132331  0.127123  0.134572  0.124080  0.143820  0.125589  \n",
       "428  0.115239  0.132956  0.127883  0.132546  0.123431  0.140298  0.125825  \n",
       "429  0.115201  0.127064  0.131418  0.132319  0.121540  0.141156  0.125358  \n",
       "\n",
       "[430 rows x 402 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test.reset_index(drop=True, inplace=True)\n",
    "df_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now df_X_train and df_X_test should have columns MatchID, PeriodID, tweet_vector. Tweet_vector is just 200 columns\n",
    "# df_y_train and df_y_test should have 1 column, EventType\n",
    "# the matchids are grouped together so all the rows of the same\n",
    "# match ids are grouped next to each other, and the periodID are ordered chronologically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "897"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have df_X_train, df_X_test, df_y_train, df_y_test\n",
    "# we no longer need df so we should free up the memory\n",
    "del df  # remove reference to the original DataFrame\n",
    "gc.collect()  # force garbage collection to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MatchID  PeriodID\n",
       "0         0       129\n",
       "1         1       129\n",
       "2         2       129\n",
       "3         3       179\n",
       "4         4        96\n",
       "5         5       129\n",
       "6         6       129\n",
       "7         7       129\n",
       "8         8       129\n",
       "9         9       129\n",
       "10       10       129\n",
       "11       11       129\n",
       "12       12       129"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X_train.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "max_periods\n",
    "# as we can see not every match has the same number of periods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MatchID  PeriodID\n",
       "0       13       129\n",
       "1       14       129\n",
       "2       15       169"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X_test.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "max_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Train and Test data for PyTorch LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor for a PyTorch LSTM should have the shape of (when setting batch_first=True)\n",
    "# (batch_size, seq_len, num_features) when using the batch_first=True parameter\n",
    "# batch_size is number of sequences processed at once\n",
    "\n",
    "# TRY WITHOUT SLIDING WINDOW APPROACH\n",
    "#    which would mean batch size = number of matches\n",
    "#    much easier to format for LSTM as 3D tensor\n",
    "#    dimension of 3D tensor with batch_first=True:(batch_size = num_matches, seq_len = num_periods, num _features = 200)\n",
    "#    (match_id, period_id, num_features=200)\n",
    "#     not every match has the same number of periods!, so seq_len can vary between different matches\n",
    "#     fix: pad with zeroes\n",
    "# we want X_tensor[match_id][period_id] to return list len 200 of corresponding tweet vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_3D_tensor(df_X, df_y):\n",
    "    # df_X should have columns MatchID, PeriodID, tweet_vector. Tweet_vector is just 200 columns\n",
    "    # rows with same matchID should be grouped together (adjacent rows)\n",
    "    # df_y should have one column (the EventType)\n",
    "    # returns tensor_X numpy array already padded! shape: (num_matches, max_num_periods, num _features = 200)\n",
    "    # and tensor_y of shape: (num_matches, max_num_periods) \n",
    "    \n",
    "    num_matches = len(df_X['MatchID'].unique())\n",
    "    max_periods = df_X.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "    total_max_period = max_periods['PeriodID'].max()\n",
    "    #total_max_period is max seq len\n",
    "\n",
    "    tensor_X = np.zeros((num_matches, total_max_period+1, 200*2))\n",
    "\n",
    "    tensor_y = np.zeros((num_matches, total_max_period+1))\n",
    "    print(tensor_X.shape)\n",
    "    print(tensor_y.shape)\n",
    "    \n",
    "    i=0\n",
    "    previous_match_id = df_X['MatchID'][0]\n",
    "    for row_index, row in df_X.iterrows():\n",
    "        match_id = int(row['MatchID'])\n",
    "\n",
    "        if match_id != previous_match_id:\n",
    "            i+=1\n",
    "            previous_match_id = match_id\n",
    "        \n",
    "        period_id = int(row['PeriodID'])\n",
    "        \n",
    "        features = row[2:].values  # Skip MatchID and PeriodID\n",
    "        tensor_X[i, period_id, :] = features\n",
    "        tensor_y[i,period_id] = df_y[row_index]\n",
    "        \n",
    "    return tensor_X, tensor_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 180, 400)\n",
      "(13, 180)\n",
      "torch.Size([13, 180, 400])\n",
      "torch.Size([13, 180])\n"
     ]
    }
   ],
   "source": [
    "# SCALING MIGHT BE UNNECESSARY SINCE OUTPUT OF GLOVE TWEET 200 IS ALREADY SCALED BETWEEN -1 AND 1\n",
    "#scaler = MinMaxScaler()\n",
    "#tensor = scaler.fit_transform(tensor)\n",
    "\n",
    "X_train_tensor, y_train_tensor = convert_df_to_3D_tensor(df_X_train, df_y_train)\n",
    "# X_train_tensor[match_id][period_id] to return list len 200 of corresponding tweet vector\n",
    "# y_train_tensor[match_id][period_id] to return corresponding EventType (1 or 0)\n",
    "# match_id index starts at 0 even if first match in df doesnt have match id 0\n",
    "#X_train_tensor[12][175]\n",
    "#X_train_tensor[12][179]\n",
    "#X_train_tensor[2][129]\n",
    "\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_train_tensor = torch.tensor(X_train_tensor, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_tensor, dtype=torch.float32)\n",
    "\n",
    "print(X_train_tensor.shape)\n",
    "print(y_train_tensor.shape)\n",
    "# X_train_tensor, y_train_tensor are now pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([130, 130, 130, 180,  97, 130, 130, 130, 130, 130, 130, 130, 130])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use pack_padded_sequence for variable length sequences\n",
    "# torch.nn.utils.rnn.pack_padded_sequence. This allows the model to ignore the padded values during computation.\n",
    "max_periods = df_X_train.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "X_train_seq_lengths = (max_periods['PeriodID']+1).tolist() # add +1 since max period ID + 1 is the seq len\n",
    "X_train_seq_lengths = torch.tensor(X_train_seq_lengths)\n",
    "X_train_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 170, 400)\n",
      "(3, 170)\n"
     ]
    }
   ],
   "source": [
    "# convert df_X_test and df_y_test to correct format/dimensions\n",
    "X_test_tensor, y_test_tensor = convert_df_to_3D_tensor(df_X_test, df_y_test)\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_test_tensor = torch.tensor(X_test_tensor, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([130, 130, 170])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X_test.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "X_test_seq_lengths = (max_periods['PeriodID']+1).tolist() # add +1 since max period ID + 1 is the seq len\n",
    "X_test_seq_lengths = torch.tensor(X_test_seq_lengths)\n",
    "X_test_seq_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Use PackedSequence, since # of periods in matches (seq len) varies in between matches\n",
    "        # so LSTM only processes the actual sequence content, ignoring padded values\n",
    "        # prevents model from learning patterns from padding (noise)        \n",
    "        \n",
    "        # Pack the input\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # Process with LSTM\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        \n",
    "        # Unpack the output\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        out = self.fc(lstm_out)\n",
    "        out = self.sigmoid(out) # applying sigmoid to convert to probabilities\n",
    "\n",
    "        return out.squeeze(-1)\n",
    "\n",
    "\n",
    "def get_loss_criterion():\n",
    "    ###### reduction = 'none' needed to only calculate loss on non-padded values using mask\n",
    "    return nn.BCELoss(reduction='none') # BCE great for binary classification\n",
    "\n",
    "def get_optimizer(lr, model):\n",
    "    #optim.NAdam(model.parameters(), lr=lr)\n",
    "    #return optim.Adam(model.parameters(), lr=lr)\n",
    "    return optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, X, y, seq_lengths, num_epochs, verbose=True, device='cpu'):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X, seq_lengths)\n",
    "        #print(f\"shape of outputs: {outputs.shape}\")\n",
    "        #break\n",
    "    \n",
    "        loss = criterion(outputs, y) # apply loss to padded values also\n",
    "\n",
    "        # Use the mask to compute loss only on non-padded elements\n",
    "        # so only non-padded elements contribute to the loss\n",
    "        mask = (torch.arange(outputs.size(1)).unsqueeze(0) < seq_lengths.unsqueeze(1)).float().to(device)\n",
    "        #print(f\"Mask shape: {mask.shape}\")\n",
    "        #print(mask[10][97:])\n",
    "        \n",
    "        # mask has shape [num_sequences, max_seq_length], with 1s for valid positions and 0s for padded positions in each sequence.\n",
    "\n",
    "    \n",
    "        #print(f\"Loss shape: {loss.shape}\")\n",
    "        # set loss of padded values to zero using mask!\n",
    "        # also normalize loss by number of valid (non-padded elements)\n",
    "        loss = (loss * mask).sum() / mask.sum() \n",
    "        #print(loss.shape)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "         \n",
    "        \n",
    "        if verbose and (epoch % 100 == 0 or epoch == num_epochs-1):\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        #if loss.item()<0.1: # 0.1 is threshold, stop training when loss is this small\n",
    "        #    break\n",
    "\n",
    "    #print(\"Model is trained!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(predictions, y_test_tensor, X_test_seq_lengths, criterion):\n",
    "    # NOT USED BUT COULD BE USEFUL\n",
    "    loss = criterion(predictions, y_test_tensor) # use predictions for loss calculation\n",
    "\n",
    "    mask = (torch.arange(predictions.size(1)).unsqueeze(0) < X_test_seq_lengths.unsqueeze(1)).float()\n",
    "    print(mask)\n",
    "    loss = (loss * mask).sum() / mask.sum() \n",
    "\n",
    "    print(f\"Binary Cross-Entropy Loss: {loss.item():.4f}\")\n",
    "    return loss\n",
    "\n",
    "def get_accuracy(y_true, y_pred):\n",
    "    if y_true.dtype != y_pred.dtype or y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Inputs do not have same type or shape!\")\n",
    "    correct_predictions = (y_true == y_pred).sum().item()\n",
    "    total_predictions = y_true.numel()\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def predict(model, X, seq_lengths, threshold=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X, seq_lengths)\n",
    "\n",
    "    # predictions have values between 0 and 1 because forward pass of LSTM contains sigmoid at output\n",
    "    #print(predictions)\n",
    "\n",
    "    \n",
    "    predicted_classes = (predictions > threshold).float() \n",
    "    #this converts to same dimensional array of True or false, and .float() converts True to 1 and False to 0\n",
    "    \n",
    "    #print(predicted_classes)\n",
    "    return predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 32, num_layers: 2\n",
      "\t-> accuracy of run #0: 74.11764705882354\n",
      "\t-> accuracy of run #1: 73.13725490196077\n",
      "\t-> accuracy of run #2: 71.17647058823529\n",
      "\tavg accuracy: 72.81045751633987\n",
      "hidden_size: 64, num_layers: 2\n",
      "\t-> accuracy of run #0: 58.03921568627452\n",
      "\t-> accuracy of run #1: 59.21568627450981\n",
      "\t-> accuracy of run #2: 74.50980392156863\n",
      "\tavg accuracy: 63.92156862745099\n",
      "hidden_size: 128, num_layers: 2\n",
      "\t-> accuracy of run #0: 77.25490196078432\n",
      "\t-> accuracy of run #1: 78.03921568627452\n",
      "\t-> accuracy of run #2: 60.0\n",
      "\tavg accuracy: 71.76470588235294\n",
      "hidden_size: 256, num_layers: 2\n",
      "\t-> accuracy of run #0: 74.70588235294117\n",
      "\t-> accuracy of run #1: 73.72549019607844\n",
      "\t-> accuracy of run #2: 74.70588235294117\n",
      "\tavg accuracy: 74.37908496732025\n",
      "hidden_size: 32, num_layers: 3\n",
      "\t-> accuracy of run #0: 75.88235294117646\n",
      "\t-> accuracy of run #1: 74.70588235294117\n",
      "\t-> accuracy of run #2: 75.68627450980392\n",
      "\tavg accuracy: 75.42483660130718\n",
      "hidden_size: 64, num_layers: 3\n",
      "\t-> accuracy of run #0: 77.25490196078432\n",
      "\t-> accuracy of run #1: 76.47058823529412\n",
      "\t-> accuracy of run #2: 62.745098039215684\n",
      "\tavg accuracy: 72.15686274509804\n",
      "hidden_size: 128, num_layers: 3\n",
      "\t-> accuracy of run #0: 71.96078431372548\n",
      "\t-> accuracy of run #1: 76.66666666666667\n",
      "\t-> accuracy of run #2: 75.09803921568627\n",
      "\tavg accuracy: 74.57516339869281\n",
      "hidden_size: 256, num_layers: 3\n",
      "\t-> accuracy of run #0: 74.90196078431373\n",
      "\t-> accuracy of run #1: 72.74509803921568\n",
      "\t-> accuracy of run #2: 76.07843137254902\n",
      "\tavg accuracy: 74.57516339869281\n",
      "hidden_size: 32, num_layers: 4\n",
      "\t-> accuracy of run #0: 73.92156862745098\n",
      "\t-> accuracy of run #1: 74.90196078431373\n",
      "\t-> accuracy of run #2: 76.86274509803923\n",
      "\tavg accuracy: 75.22875816993464\n",
      "hidden_size: 64, num_layers: 4\n",
      "\t-> accuracy of run #0: 74.31372549019608\n",
      "\t-> accuracy of run #1: 74.11764705882354\n",
      "\t-> accuracy of run #2: 73.52941176470588\n",
      "\tavg accuracy: 73.98692810457517\n",
      "hidden_size: 128, num_layers: 4\n",
      "\t-> accuracy of run #0: 77.25490196078432\n",
      "\t-> accuracy of run #1: 73.33333333333333\n",
      "\t-> accuracy of run #2: 76.47058823529412\n",
      "\tavg accuracy: 75.68627450980392\n",
      "hidden_size: 256, num_layers: 4\n",
      "\t-> accuracy of run #0: 61.96078431372549\n",
      "\t-> accuracy of run #1: 73.13725490196077\n",
      "\t-> accuracy of run #2: 76.27450980392156\n",
      "\tavg accuracy: 70.45751633986927\n",
      "\n",
      "Best hidden size: 128, Best num layers: 4 with accuracy of 75.68627450980392\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.2 # can tune\n",
    "num_epochs = 300 # can tune\n",
    "lr = 0.005 # can tune\n",
    "def find_best_hyperparameters(params):\n",
    "    # input: list of tuples (hidden_size, num_layers)\n",
    "    # returns tuple (hidden_size, num_layers) with highest accuracy on test data\n",
    "    # since prediction accuracy over multiple runs of the same hidden_size, num_layer\n",
    "    #     varies, we take the avg over multiple runs\n",
    "    accuracies = []\n",
    "    num_runs = 3 # can tune\n",
    "    \n",
    "    for hidden_size, num_layers in params:\n",
    "        temp_accuracies = [] \n",
    "        # temp_accuracies:\n",
    "        #     holds all (num_runs) accuracies of current param tuple, to take avg of later\n",
    "        \n",
    "        criterion = get_loss_criterion()\n",
    "        criterion = criterion.to(gpu)\n",
    "        print(f\"hidden_size: {hidden_size}, num_layers: {num_layers}\")\n",
    "        for r in range(num_runs):\n",
    "            # Dropout introduces randomness in both training and evaluation phases\n",
    "            # so we should retrain and retest for every run\n",
    "\n",
    "            model = LSTMModel(input_size=400, hidden_size=hidden_size, num_layers=num_layers, dropout_rate=dropout_rate)\n",
    "            model = model.to(gpu)\n",
    "            optimizer = get_optimizer(lr, model)\n",
    "            \n",
    "            # train on training data\n",
    "            train_model(model, optimizer, criterion, X_train_tensor.to(gpu), y_train_tensor.to(gpu), X_train_seq_lengths, num_epochs, verbose=False, device=gpu)\n",
    "            # predict on test data\n",
    "            predicted_classes = predict(model, X_test_tensor.to(gpu), X_test_seq_lengths)\n",
    "            # get accuracy on test data\n",
    "            accuracy = get_accuracy(y_test_tensor.to(gpu), predicted_classes)\n",
    "            temp_accuracies.append(accuracy)\n",
    "            print(f\"\\t-> accuracy of run #{r}: {accuracy}\")\n",
    "        accuracy = sum(temp_accuracies)/len(temp_accuracies)\n",
    "        # overall accuracy of a param tuple is the avg of the accuracy over multiple runs\n",
    "        print(f\"\\tavg accuracy: {accuracy}\")\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    # FIND INDEX OF HIGHEST ACCURACY AND RETURN CORRESPONDONG HIDDENS SIZE NUM LAYER TUPLE\n",
    "    max_accuracy_index = accuracies.index(max(accuracies))\n",
    "    return params[max_accuracy_index], max(accuracies)\n",
    "    \n",
    "possible_params = [(32, 2), (64, 2), (128, 2), (256, 2), \n",
    "                  (32, 3), (64, 3), (128, 3), (256, 3), \n",
    "                  (32, 4), (64, 4), (128, 4), (256, 4)]\n",
    "(best_hidden_size, best_num_layers), max_accuracy = find_best_hyperparameters(possible_params)\n",
    "print(f\"\\nBest hidden size: {best_hidden_size}, Best num layers: {best_num_layers} with accuracy of {max_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "(2137, 402)\n",
      "(2137,)\n"
     ]
    }
   ],
   "source": [
    "# RETRAIN MODEL ON ENTIRE TRAINING DATA AND EVALUATE EVAL TWEETS\n",
    "\n",
    "\n",
    "df_X = pd.concat([df_X_train, df_X_test], ignore_index=True)\n",
    "df_y = pd.concat([df_y_train, df_y_test], ignore_index=True)\n",
    "print(df_X['MatchID'].unique())\n",
    "print(df_X.shape)\n",
    "print(df_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091459</td>\n",
       "      <td>0.226844</td>\n",
       "      <td>0.094664</td>\n",
       "      <td>-0.141795</td>\n",
       "      <td>-0.008727</td>\n",
       "      <td>0.074108</td>\n",
       "      <td>0.129913</td>\n",
       "      <td>0.081805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150102</td>\n",
       "      <td>0.139094</td>\n",
       "      <td>0.138360</td>\n",
       "      <td>0.120164</td>\n",
       "      <td>0.186236</td>\n",
       "      <td>0.146713</td>\n",
       "      <td>0.171785</td>\n",
       "      <td>0.153843</td>\n",
       "      <td>0.140646</td>\n",
       "      <td>0.155383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118754</td>\n",
       "      <td>0.224606</td>\n",
       "      <td>0.106361</td>\n",
       "      <td>-0.146739</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>0.092931</td>\n",
       "      <td>0.093373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145702</td>\n",
       "      <td>0.133928</td>\n",
       "      <td>0.125154</td>\n",
       "      <td>0.131825</td>\n",
       "      <td>0.185473</td>\n",
       "      <td>0.154380</td>\n",
       "      <td>0.178184</td>\n",
       "      <td>0.151329</td>\n",
       "      <td>0.152819</td>\n",
       "      <td>0.171357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.105108</td>\n",
       "      <td>0.221155</td>\n",
       "      <td>0.120983</td>\n",
       "      <td>-0.177829</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.067515</td>\n",
       "      <td>0.106421</td>\n",
       "      <td>0.088029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154059</td>\n",
       "      <td>0.145181</td>\n",
       "      <td>0.141065</td>\n",
       "      <td>0.132949</td>\n",
       "      <td>0.190581</td>\n",
       "      <td>0.154179</td>\n",
       "      <td>0.190066</td>\n",
       "      <td>0.145702</td>\n",
       "      <td>0.139681</td>\n",
       "      <td>0.143230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.114742</td>\n",
       "      <td>0.220896</td>\n",
       "      <td>0.117625</td>\n",
       "      <td>-0.154241</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.066276</td>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.101138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141530</td>\n",
       "      <td>0.135123</td>\n",
       "      <td>0.133328</td>\n",
       "      <td>0.124843</td>\n",
       "      <td>0.186997</td>\n",
       "      <td>0.141761</td>\n",
       "      <td>0.206638</td>\n",
       "      <td>0.152586</td>\n",
       "      <td>0.141340</td>\n",
       "      <td>0.155276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.109419</td>\n",
       "      <td>0.229442</td>\n",
       "      <td>0.113353</td>\n",
       "      <td>-0.161975</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.080471</td>\n",
       "      <td>0.127543</td>\n",
       "      <td>0.113681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139937</td>\n",
       "      <td>0.133569</td>\n",
       "      <td>0.126487</td>\n",
       "      <td>0.135095</td>\n",
       "      <td>0.175768</td>\n",
       "      <td>0.138774</td>\n",
       "      <td>0.192561</td>\n",
       "      <td>0.150075</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.142274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>0.128309</td>\n",
       "      <td>0.238830</td>\n",
       "      <td>0.046353</td>\n",
       "      <td>-0.057035</td>\n",
       "      <td>-0.072904</td>\n",
       "      <td>0.057241</td>\n",
       "      <td>0.130987</td>\n",
       "      <td>0.057935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137781</td>\n",
       "      <td>0.158275</td>\n",
       "      <td>0.164880</td>\n",
       "      <td>0.113359</td>\n",
       "      <td>0.131535</td>\n",
       "      <td>0.134531</td>\n",
       "      <td>0.128150</td>\n",
       "      <td>0.126427</td>\n",
       "      <td>0.135111</td>\n",
       "      <td>0.126775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>15</td>\n",
       "      <td>166</td>\n",
       "      <td>0.131207</td>\n",
       "      <td>0.238868</td>\n",
       "      <td>0.049916</td>\n",
       "      <td>-0.061460</td>\n",
       "      <td>-0.069031</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.131640</td>\n",
       "      <td>0.062507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141206</td>\n",
       "      <td>0.161633</td>\n",
       "      <td>0.166177</td>\n",
       "      <td>0.113479</td>\n",
       "      <td>0.132183</td>\n",
       "      <td>0.131873</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.126706</td>\n",
       "      <td>0.145706</td>\n",
       "      <td>0.127274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>0.126975</td>\n",
       "      <td>0.240796</td>\n",
       "      <td>0.047862</td>\n",
       "      <td>-0.051878</td>\n",
       "      <td>-0.067845</td>\n",
       "      <td>0.049647</td>\n",
       "      <td>0.120679</td>\n",
       "      <td>0.055225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140779</td>\n",
       "      <td>0.155717</td>\n",
       "      <td>0.165043</td>\n",
       "      <td>0.118110</td>\n",
       "      <td>0.132331</td>\n",
       "      <td>0.127123</td>\n",
       "      <td>0.134572</td>\n",
       "      <td>0.124080</td>\n",
       "      <td>0.143820</td>\n",
       "      <td>0.125589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>0.128527</td>\n",
       "      <td>0.245419</td>\n",
       "      <td>0.044214</td>\n",
       "      <td>-0.055183</td>\n",
       "      <td>-0.067618</td>\n",
       "      <td>0.038687</td>\n",
       "      <td>0.119808</td>\n",
       "      <td>0.060817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136859</td>\n",
       "      <td>0.158013</td>\n",
       "      <td>0.167696</td>\n",
       "      <td>0.115239</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.127883</td>\n",
       "      <td>0.132546</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.140298</td>\n",
       "      <td>0.125825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0.128165</td>\n",
       "      <td>0.241196</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>-0.055317</td>\n",
       "      <td>-0.065858</td>\n",
       "      <td>0.041221</td>\n",
       "      <td>0.123674</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133160</td>\n",
       "      <td>0.156094</td>\n",
       "      <td>0.164026</td>\n",
       "      <td>0.115201</td>\n",
       "      <td>0.127064</td>\n",
       "      <td>0.131418</td>\n",
       "      <td>0.132319</td>\n",
       "      <td>0.121540</td>\n",
       "      <td>0.141156</td>\n",
       "      <td>0.125358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID         0         1         2         3         4  \\\n",
       "0           0         0  0.091459  0.226844  0.094664 -0.141795 -0.008727   \n",
       "1           0         1  0.118754  0.224606  0.106361 -0.146739  0.034357   \n",
       "2           0         2  0.105108  0.221155  0.120983 -0.177829  0.018819   \n",
       "3           0         3  0.114742  0.220896  0.117625 -0.154241  0.013500   \n",
       "4           0         4  0.109419  0.229442  0.113353 -0.161975  0.002804   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "2132       15       165  0.128309  0.238830  0.046353 -0.057035 -0.072904   \n",
       "2133       15       166  0.131207  0.238868  0.049916 -0.061460 -0.069031   \n",
       "2134       15       167  0.126975  0.240796  0.047862 -0.051878 -0.067845   \n",
       "2135       15       168  0.128527  0.245419  0.044214 -0.055183 -0.067618   \n",
       "2136       15       169  0.128165  0.241196  0.046135 -0.055317 -0.065858   \n",
       "\n",
       "             5         6         7  ...       190       191       192  \\\n",
       "0     0.074108  0.129913  0.081805  ...  0.150102  0.139094  0.138360   \n",
       "1     0.057512  0.092931  0.093373  ...  0.145702  0.133928  0.125154   \n",
       "2     0.067515  0.106421  0.088029  ...  0.154059  0.145181  0.141065   \n",
       "3     0.066276  0.082330  0.101138  ...  0.141530  0.135123  0.133328   \n",
       "4     0.080471  0.127543  0.113681  ...  0.139937  0.133569  0.126487   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2132  0.057241  0.130987  0.057935  ...  0.137781  0.158275  0.164880   \n",
       "2133  0.056109  0.131640  0.062507  ...  0.141206  0.161633  0.166177   \n",
       "2134  0.049647  0.120679  0.055225  ...  0.140779  0.155717  0.165043   \n",
       "2135  0.038687  0.119808  0.060817  ...  0.136859  0.158013  0.167696   \n",
       "2136  0.041221  0.123674  0.059436  ...  0.133160  0.156094  0.164026   \n",
       "\n",
       "           193       194       195       196       197       198       199  \n",
       "0     0.120164  0.186236  0.146713  0.171785  0.153843  0.140646  0.155383  \n",
       "1     0.131825  0.185473  0.154380  0.178184  0.151329  0.152819  0.171357  \n",
       "2     0.132949  0.190581  0.154179  0.190066  0.145702  0.139681  0.143230  \n",
       "3     0.124843  0.186997  0.141761  0.206638  0.152586  0.141340  0.155276  \n",
       "4     0.135095  0.175768  0.138774  0.192561  0.150075  0.136600  0.142274  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2132  0.113359  0.131535  0.134531  0.128150  0.126427  0.135111  0.126775  \n",
       "2133  0.113479  0.132183  0.131873  0.130081  0.126706  0.145706  0.127274  \n",
       "2134  0.118110  0.132331  0.127123  0.134572  0.124080  0.143820  0.125589  \n",
       "2135  0.115239  0.132956  0.127883  0.132546  0.123431  0.140298  0.125825  \n",
       "2136  0.115201  0.127064  0.131418  0.132319  0.121540  0.141156  0.125358  \n",
       "\n",
       "[2137 rows x 402 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       0.0\n",
       "       ... \n",
       "2132    1.0\n",
       "2133    1.0\n",
       "2134    1.0\n",
       "2135    1.0\n",
       "2136    0.0\n",
       "Name: EventType, Length: 2137, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 180, 400)\n",
      "(16, 180)\n"
     ]
    }
   ],
   "source": [
    "# convert df_X_test and df_y_test to correct format/dimensions\n",
    "X_tensor, y_tensor = convert_df_to_3D_tensor(df_X, df_y)\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_tensor = torch.tensor(X_tensor, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 180, 400])\n",
      "torch.Size([16, 180])\n"
     ]
    }
   ],
   "source": [
    "print(X_tensor.shape)\n",
    "print(y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([130, 130, 130, 180,  97, 130, 130, 130, 130, 130, 130, 130, 130, 130,\n",
       "        130, 170])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "X_seq_lengths = (max_periods['PeriodID']+1).tolist() # add +1 since max period ID + 1 is the seq len\n",
    "X_seq_lengths = torch.tensor(X_seq_lengths)\n",
    "X_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hidden size: 256, Best num layers: 2 with accuracy of 68.07692307692308\n",
    "#best_hidden_size = 32\n",
    "#best_num_layers = 3\n",
    "# these seem to work very well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128, 4\n",
      "Epoch [0/600], Loss: 0.6935\n",
      "Epoch [100/600], Loss: 0.5770\n",
      "Epoch [200/600], Loss: 0.3363\n",
      "Epoch [300/600], Loss: 0.0896\n",
      "Epoch [400/600], Loss: 0.0249\n",
      "Epoch [500/600], Loss: 0.0415\n",
      "Epoch [599/600], Loss: 0.0053\n"
     ]
    }
   ],
   "source": [
    "# retrain model on all 16 matches (with best hyper parameters found above)\n",
    "print(f\"{best_hidden_size}, {best_num_layers}\")\n",
    "model = LSTMModel(input_size=400, hidden_size=best_hidden_size, num_layers=best_num_layers, dropout_rate=dropout_rate)\n",
    "model = model.to(gpu)\n",
    "optimizer = get_optimizer(lr, model)\n",
    "criterion = get_loss_criterion()\n",
    "criterion = criterion.to(gpu)\n",
    "\n",
    "train_model(model, optimizer, criterion, X_tensor.to(gpu), y_tensor.to(gpu), X_seq_lengths, num_epochs=600, device=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreeceIvoryCoast44.csv\n",
      "[9]\n",
      "NetherlandsMexico64.csv\n",
      "[15]\n",
      "GermanyGhana32.csv\n",
      "[6]\n",
      "GermanySerbia2010.csv\n",
      "[16]\n"
     ]
    }
   ],
   "source": [
    "# READ EVAL_TWEETS AND PREPROCESS DATA\n",
    "\n",
    "# Read all eval files and concatenate them into one dataframe\n",
    "\n",
    "li = []\n",
    "i = 0\n",
    "match_id_order = {}\n",
    "for filename in listdir(\"eval_tweets\"):\n",
    "    if filename != '.ipynb_checkpoints':\n",
    "        print(filename)\n",
    "        df_eval = pd.read_csv(\"eval_tweets/\" + filename)\n",
    "        df_eval.drop(columns=['Timestamp'], inplace=True)\n",
    "        # drop unused column(s)\n",
    "        print(df_eval['MatchID'].unique())\n",
    "        match_id = str(df_eval['MatchID'].unique()[0])\n",
    "        match_id_order[match_id] = i\n",
    "        # match_id_order[match_id]  = i means that the predictions of match_id are in the ith sequence\n",
    "        df_eval['MatchID'] = str(i)\n",
    "        df_eval['ID'] = str(i)+ '_' + df_eval['PeriodID'].astype(str)\n",
    "        # makes sure that the match IDs are ordered from 0,1,2... with no missing values\n",
    "        # this is for convenience and so it is easier to debug and follow along\n",
    "        i+=1\n",
    "        li.append(df_eval)\n",
    "df_eval = pd.concat(li, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wana place a bet on an ivory coast win but ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#WatchLive @FIFAWorldCup: Greece vs. Ivory Coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gonna watch the Colombia and Japan game becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#CIV vs #COL &amp; #GRE vs #JPN! It would be inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @DuncanCastles: Quite a statistic this: Gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072923</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>LETS GO #USA #worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072924</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>another upset in #WC2010 #Srb beat #Ger by 1-0 !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072925</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>RT @FIFAcom: #GER 0:1 #SRB: TheÂ finalÂ whistl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072926</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>dukung yg menang -_- RT @AlikaZahira: #bra #fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072927</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>Serbia win?wow...unexpected,hm? #worldcup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072928 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID MatchID  PeriodID  \\\n",
       "0          0_0       0         0   \n",
       "1          0_0       0         0   \n",
       "2          0_0       0         0   \n",
       "3          0_0       0         0   \n",
       "4          0_0       0         0   \n",
       "...        ...     ...       ...   \n",
       "1072923  3_129       3       129   \n",
       "1072924  3_129       3       129   \n",
       "1072925  3_129       3       129   \n",
       "1072926  3_129       3       129   \n",
       "1072927  3_129       3       129   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        Wana place a bet on an ivory coast win but ain...  \n",
       "1        #WatchLive @FIFAWorldCup: Greece vs. Ivory Coa...  \n",
       "2        Gonna watch the Colombia and Japan game becaus...  \n",
       "3        #CIV vs #COL & #GRE vs #JPN! It would be inter...  \n",
       "4        RT @DuncanCastles: Quite a statistic this: Gre...  \n",
       "...                                                    ...  \n",
       "1072923                             LETS GO #USA #worldcup  \n",
       "1072924  another upset in #WC2010 #Srb beat #Ger by 1-0 !!  \n",
       "1072925  RT @FIFAcom: #GER 0:1 #SRB: TheÂ finalÂ whistl...  \n",
       "1072926  dukung yg menang -_- RT @AlikaZahira: #bra #fr...  \n",
       "1072927          Serbia win?wow...unexpected,hm? #worldcup  \n",
       "\n",
       "[1072928 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply:   0%|          | 5198/1072928 [00:00<00:40, 26116.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1072928/1072928 [00:39<00:00, 26989.83it/s]\n"
     ]
    }
   ],
   "source": [
    "df_eval['Tweet'] = df_eval['Tweet'].swifter.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.134681</td>\n",
       "      <td>0.229862</td>\n",
       "      <td>-0.042323</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>-0.203157</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.330626</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.155409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071476</td>\n",
       "      <td>-0.158876</td>\n",
       "      <td>-0.003906</td>\n",
       "      <td>-0.285829</td>\n",
       "      <td>0.167653</td>\n",
       "      <td>-0.065119</td>\n",
       "      <td>0.301132</td>\n",
       "      <td>0.072499</td>\n",
       "      <td>0.408611</td>\n",
       "      <td>0.011564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.039456</td>\n",
       "      <td>0.129093</td>\n",
       "      <td>0.275312</td>\n",
       "      <td>-0.218841</td>\n",
       "      <td>-0.140618</td>\n",
       "      <td>0.050320</td>\n",
       "      <td>-0.131703</td>\n",
       "      <td>-0.141104</td>\n",
       "      <td>0.387860</td>\n",
       "      <td>-0.262571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197294</td>\n",
       "      <td>-0.105539</td>\n",
       "      <td>-0.111869</td>\n",
       "      <td>0.043191</td>\n",
       "      <td>0.016699</td>\n",
       "      <td>0.038589</td>\n",
       "      <td>0.253951</td>\n",
       "      <td>-0.076240</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>-0.038478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.014135</td>\n",
       "      <td>0.097365</td>\n",
       "      <td>0.242030</td>\n",
       "      <td>-0.263193</td>\n",
       "      <td>-0.336750</td>\n",
       "      <td>0.127846</td>\n",
       "      <td>0.323738</td>\n",
       "      <td>-0.024958</td>\n",
       "      <td>0.320704</td>\n",
       "      <td>-0.346318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190761</td>\n",
       "      <td>-0.274125</td>\n",
       "      <td>0.035664</td>\n",
       "      <td>-0.119048</td>\n",
       "      <td>0.020838</td>\n",
       "      <td>-0.030073</td>\n",
       "      <td>0.063768</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>-0.005234</td>\n",
       "      <td>0.117632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152916</td>\n",
       "      <td>0.359603</td>\n",
       "      <td>0.275224</td>\n",
       "      <td>-0.033671</td>\n",
       "      <td>-0.038763</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>-0.083626</td>\n",
       "      <td>-0.031100</td>\n",
       "      <td>0.300301</td>\n",
       "      <td>0.081735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026851</td>\n",
       "      <td>-0.156188</td>\n",
       "      <td>0.142420</td>\n",
       "      <td>0.092976</td>\n",
       "      <td>-0.050861</td>\n",
       "      <td>0.107874</td>\n",
       "      <td>0.201227</td>\n",
       "      <td>0.074644</td>\n",
       "      <td>-0.096115</td>\n",
       "      <td>-0.003723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.132566</td>\n",
       "      <td>0.179217</td>\n",
       "      <td>0.242708</td>\n",
       "      <td>0.092353</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.071389</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>0.104104</td>\n",
       "      <td>0.240512</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030989</td>\n",
       "      <td>-0.123497</td>\n",
       "      <td>0.078241</td>\n",
       "      <td>0.070216</td>\n",
       "      <td>0.026782</td>\n",
       "      <td>0.100645</td>\n",
       "      <td>0.133896</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>-0.094329</td>\n",
       "      <td>-0.016839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.134681  0.229862 -0.042323  0.013444 -0.203157  0.074970  0.330626   \n",
       "1 -0.039456  0.129093  0.275312 -0.218841 -0.140618  0.050320 -0.131703   \n",
       "2 -0.014135  0.097365  0.242030 -0.263193 -0.336750  0.127846  0.323738   \n",
       "3  0.152916  0.359603  0.275224 -0.033671 -0.038763  0.013550 -0.083626   \n",
       "4  0.132566  0.179217  0.242708  0.092353 -0.000681  0.071389  0.046733   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.040816  0.315068  0.155409  ...  0.071476 -0.158876 -0.003906 -0.285829   \n",
       "1 -0.141104  0.387860 -0.262571  ...  0.197294 -0.105539 -0.111869  0.043191   \n",
       "2 -0.024958  0.320704 -0.346318  ...  0.190761 -0.274125  0.035664 -0.119048   \n",
       "3 -0.031100  0.300301  0.081735  ... -0.026851 -0.156188  0.142420  0.092976   \n",
       "4  0.104104  0.240512  0.004074  ... -0.030989 -0.123497  0.078241  0.070216   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.167653 -0.065119  0.301132  0.072499  0.408611  0.011564  \n",
       "1  0.016699  0.038589  0.253951 -0.076240  0.007587 -0.038478  \n",
       "2  0.020838 -0.030073  0.063768  0.070300 -0.005234  0.117632  \n",
       "3 -0.050861  0.107874  0.201227  0.074644 -0.096115 -0.003723  \n",
       "4  0.026782  0.100645  0.133896  0.100492 -0.094329 -0.016839  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vectors = np.vstack([get_avg_embedding(tweet, embeddings_model, vector_size) for tweet in df_eval['Tweet']])\n",
    "tweet_df = pd.DataFrame(tweet_vectors)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the vectors into the original dataframe\n",
    "df_eval = pd.concat([df_eval, tweet_df], axis=1)\n",
    "\n",
    "# Drop the columns that are not useful anymore\n",
    "# no need for Tweet column since we have its corresponding vector embedding\n",
    "df_eval.drop(columns=['Tweet'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.134681</td>\n",
       "      <td>0.229862</td>\n",
       "      <td>-0.042323</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>-0.203157</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.330626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071476</td>\n",
       "      <td>-0.158876</td>\n",
       "      <td>-0.003906</td>\n",
       "      <td>-0.285829</td>\n",
       "      <td>0.167653</td>\n",
       "      <td>-0.065119</td>\n",
       "      <td>0.301132</td>\n",
       "      <td>0.072499</td>\n",
       "      <td>0.408611</td>\n",
       "      <td>0.011564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.039456</td>\n",
       "      <td>0.129093</td>\n",
       "      <td>0.275312</td>\n",
       "      <td>-0.218841</td>\n",
       "      <td>-0.140618</td>\n",
       "      <td>0.050320</td>\n",
       "      <td>-0.131703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197294</td>\n",
       "      <td>-0.105539</td>\n",
       "      <td>-0.111869</td>\n",
       "      <td>0.043191</td>\n",
       "      <td>0.016699</td>\n",
       "      <td>0.038589</td>\n",
       "      <td>0.253951</td>\n",
       "      <td>-0.076240</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>-0.038478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014135</td>\n",
       "      <td>0.097365</td>\n",
       "      <td>0.242030</td>\n",
       "      <td>-0.263193</td>\n",
       "      <td>-0.336750</td>\n",
       "      <td>0.127846</td>\n",
       "      <td>0.323738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190761</td>\n",
       "      <td>-0.274125</td>\n",
       "      <td>0.035664</td>\n",
       "      <td>-0.119048</td>\n",
       "      <td>0.020838</td>\n",
       "      <td>-0.030073</td>\n",
       "      <td>0.063768</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>-0.005234</td>\n",
       "      <td>0.117632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152916</td>\n",
       "      <td>0.359603</td>\n",
       "      <td>0.275224</td>\n",
       "      <td>-0.033671</td>\n",
       "      <td>-0.038763</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>-0.083626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026851</td>\n",
       "      <td>-0.156188</td>\n",
       "      <td>0.142420</td>\n",
       "      <td>0.092976</td>\n",
       "      <td>-0.050861</td>\n",
       "      <td>0.107874</td>\n",
       "      <td>0.201227</td>\n",
       "      <td>0.074644</td>\n",
       "      <td>-0.096115</td>\n",
       "      <td>-0.003723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132566</td>\n",
       "      <td>0.179217</td>\n",
       "      <td>0.242708</td>\n",
       "      <td>0.092353</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.071389</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030989</td>\n",
       "      <td>-0.123497</td>\n",
       "      <td>0.078241</td>\n",
       "      <td>0.070216</td>\n",
       "      <td>0.026782</td>\n",
       "      <td>0.100645</td>\n",
       "      <td>0.133896</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>-0.094329</td>\n",
       "      <td>-0.016839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072923</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>0.242499</td>\n",
       "      <td>0.274799</td>\n",
       "      <td>0.253372</td>\n",
       "      <td>-0.344633</td>\n",
       "      <td>0.068218</td>\n",
       "      <td>0.214728</td>\n",
       "      <td>0.314110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092508</td>\n",
       "      <td>-0.006807</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>-0.015627</td>\n",
       "      <td>0.096820</td>\n",
       "      <td>0.532033</td>\n",
       "      <td>-0.064175</td>\n",
       "      <td>-0.045848</td>\n",
       "      <td>-0.013750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072924</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>0.303763</td>\n",
       "      <td>0.572543</td>\n",
       "      <td>0.057643</td>\n",
       "      <td>-0.208308</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.081378</td>\n",
       "      <td>0.025993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206641</td>\n",
       "      <td>-0.101010</td>\n",
       "      <td>-0.044188</td>\n",
       "      <td>-0.060697</td>\n",
       "      <td>-0.091385</td>\n",
       "      <td>0.103763</td>\n",
       "      <td>0.232590</td>\n",
       "      <td>-0.094657</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.056341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072925</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>0.414611</td>\n",
       "      <td>0.130372</td>\n",
       "      <td>-0.059497</td>\n",
       "      <td>0.081376</td>\n",
       "      <td>-0.034127</td>\n",
       "      <td>-0.195386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147604</td>\n",
       "      <td>-0.150352</td>\n",
       "      <td>-0.072764</td>\n",
       "      <td>-0.004861</td>\n",
       "      <td>-0.175550</td>\n",
       "      <td>0.377446</td>\n",
       "      <td>0.180492</td>\n",
       "      <td>0.206887</td>\n",
       "      <td>-0.409686</td>\n",
       "      <td>0.206524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072926</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>0.137295</td>\n",
       "      <td>0.125495</td>\n",
       "      <td>0.025162</td>\n",
       "      <td>-0.160762</td>\n",
       "      <td>0.075350</td>\n",
       "      <td>-0.050837</td>\n",
       "      <td>-0.310498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182690</td>\n",
       "      <td>-0.233215</td>\n",
       "      <td>-0.060355</td>\n",
       "      <td>0.166417</td>\n",
       "      <td>-0.706687</td>\n",
       "      <td>-0.028383</td>\n",
       "      <td>-0.080826</td>\n",
       "      <td>0.050139</td>\n",
       "      <td>-0.361144</td>\n",
       "      <td>0.299408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072927</th>\n",
       "      <td>3_129</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>-0.121697</td>\n",
       "      <td>0.563845</td>\n",
       "      <td>0.377195</td>\n",
       "      <td>0.066125</td>\n",
       "      <td>0.265674</td>\n",
       "      <td>-0.329643</td>\n",
       "      <td>-0.164325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510405</td>\n",
       "      <td>-0.587385</td>\n",
       "      <td>-0.138131</td>\n",
       "      <td>0.138874</td>\n",
       "      <td>-0.708015</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.460785</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.266575</td>\n",
       "      <td>0.082980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072928 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID MatchID  PeriodID         0         1         2         3  \\\n",
       "0          0_0       0         0 -0.134681  0.229862 -0.042323  0.013444   \n",
       "1          0_0       0         0 -0.039456  0.129093  0.275312 -0.218841   \n",
       "2          0_0       0         0 -0.014135  0.097365  0.242030 -0.263193   \n",
       "3          0_0       0         0  0.152916  0.359603  0.275224 -0.033671   \n",
       "4          0_0       0         0  0.132566  0.179217  0.242708  0.092353   \n",
       "...        ...     ...       ...       ...       ...       ...       ...   \n",
       "1072923  3_129       3       129  0.242499  0.274799  0.253372 -0.344633   \n",
       "1072924  3_129       3       129  0.303763  0.572543  0.057643 -0.208308   \n",
       "1072925  3_129       3       129  0.043595  0.414611  0.130372 -0.059497   \n",
       "1072926  3_129       3       129  0.137295  0.125495  0.025162 -0.160762   \n",
       "1072927  3_129       3       129 -0.121697  0.563845  0.377195  0.066125   \n",
       "\n",
       "                4         5         6  ...       190       191       192  \\\n",
       "0       -0.203157  0.074970  0.330626  ...  0.071476 -0.158876 -0.003906   \n",
       "1       -0.140618  0.050320 -0.131703  ...  0.197294 -0.105539 -0.111869   \n",
       "2       -0.336750  0.127846  0.323738  ...  0.190761 -0.274125  0.035664   \n",
       "3       -0.038763  0.013550 -0.083626  ... -0.026851 -0.156188  0.142420   \n",
       "4       -0.000681  0.071389  0.046733  ... -0.030989 -0.123497  0.078241   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "1072923  0.068218  0.214728  0.314110  ... -0.092508 -0.006807  0.001040   \n",
       "1072924  0.002397  0.081378  0.025993  ... -0.206641 -0.101010 -0.044188   \n",
       "1072925  0.081376 -0.034127 -0.195386  ... -0.147604 -0.150352 -0.072764   \n",
       "1072926  0.075350 -0.050837 -0.310498  ... -0.182690 -0.233215 -0.060355   \n",
       "1072927  0.265674 -0.329643 -0.164325  ... -0.510405 -0.587385 -0.138131   \n",
       "\n",
       "              193       194       195       196       197       198       199  \n",
       "0       -0.285829  0.167653 -0.065119  0.301132  0.072499  0.408611  0.011564  \n",
       "1        0.043191  0.016699  0.038589  0.253951 -0.076240  0.007587 -0.038478  \n",
       "2       -0.119048  0.020838 -0.030073  0.063768  0.070300 -0.005234  0.117632  \n",
       "3        0.092976 -0.050861  0.107874  0.201227  0.074644 -0.096115 -0.003723  \n",
       "4        0.070216  0.026782  0.100645  0.133896  0.100492 -0.094329 -0.016839  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "1072923  0.088608 -0.015627  0.096820  0.532033 -0.064175 -0.045848 -0.013750  \n",
       "1072924 -0.060697 -0.091385  0.103763  0.232590 -0.094657 -0.023285 -0.056341  \n",
       "1072925 -0.004861 -0.175550  0.377446  0.180492  0.206887 -0.409686  0.206524  \n",
       "1072926  0.166417 -0.706687 -0.028383 -0.080826  0.050139 -0.361144  0.299408  \n",
       "1072927  0.138874 -0.708015  0.442100  0.460785  0.160100  0.266575  0.082980  \n",
       "\n",
       "[1072928 rows x 203 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by now should have df with columns: ID, match id, period id, tweet_vector. Tweet_vector is just 200 columns\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the tweets into their corresponding periods to generate an average embedding vector for each period\n",
    "# so there are no duplicate period id rows per match\n",
    "# decreases size of data + makes it easier to fit into LSTM model\n",
    "df2 = df_eval.groupby(['MatchID', 'PeriodID', 'ID']).mean().reset_index()\n",
    "df3 = df_eval.groupby(['MatchID', 'PeriodID', 'ID']).std().reset_index().drop(columns=['MatchID', 'PeriodID', 'ID'])\n",
    "df_eval = pd.concat([df2, df3], axis=1, join='inner')\n",
    "df_eval.drop(columns=['ID'], inplace=True) \n",
    "df_eval['MatchID'] = df_eval['MatchID'].astype(int)\n",
    "df_eval['PeriodID'] = df_eval['PeriodID'].astype(int)\n",
    "# need to convert to int before sorting\n",
    "df_eval.sort_values(by=['MatchID', 'PeriodID'], inplace=True)\n",
    "df_eval.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.149446</td>\n",
       "      <td>0.173955</td>\n",
       "      <td>-0.034232</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.020943</td>\n",
       "      <td>0.098379</td>\n",
       "      <td>0.032518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153034</td>\n",
       "      <td>0.157182</td>\n",
       "      <td>0.145271</td>\n",
       "      <td>0.145639</td>\n",
       "      <td>0.128065</td>\n",
       "      <td>0.125192</td>\n",
       "      <td>0.133178</td>\n",
       "      <td>0.117571</td>\n",
       "      <td>0.166727</td>\n",
       "      <td>0.132553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001169</td>\n",
       "      <td>0.133767</td>\n",
       "      <td>0.182607</td>\n",
       "      <td>-0.027490</td>\n",
       "      <td>-0.134708</td>\n",
       "      <td>-0.008566</td>\n",
       "      <td>0.098646</td>\n",
       "      <td>0.020663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165164</td>\n",
       "      <td>0.157495</td>\n",
       "      <td>0.153015</td>\n",
       "      <td>0.132694</td>\n",
       "      <td>0.143167</td>\n",
       "      <td>0.135772</td>\n",
       "      <td>0.140925</td>\n",
       "      <td>0.114819</td>\n",
       "      <td>0.156178</td>\n",
       "      <td>0.136774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.124594</td>\n",
       "      <td>0.206335</td>\n",
       "      <td>-0.035794</td>\n",
       "      <td>-0.129705</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>0.088574</td>\n",
       "      <td>0.039749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179429</td>\n",
       "      <td>0.153216</td>\n",
       "      <td>0.157596</td>\n",
       "      <td>0.163330</td>\n",
       "      <td>0.146216</td>\n",
       "      <td>0.140805</td>\n",
       "      <td>0.146061</td>\n",
       "      <td>0.118530</td>\n",
       "      <td>0.154841</td>\n",
       "      <td>0.137328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>0.103209</td>\n",
       "      <td>0.217068</td>\n",
       "      <td>-0.027762</td>\n",
       "      <td>-0.135133</td>\n",
       "      <td>-0.004802</td>\n",
       "      <td>0.100052</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188828</td>\n",
       "      <td>0.158445</td>\n",
       "      <td>0.164582</td>\n",
       "      <td>0.156278</td>\n",
       "      <td>0.158240</td>\n",
       "      <td>0.125951</td>\n",
       "      <td>0.137621</td>\n",
       "      <td>0.116231</td>\n",
       "      <td>0.167588</td>\n",
       "      <td>0.138395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>0.120250</td>\n",
       "      <td>0.216792</td>\n",
       "      <td>-0.039718</td>\n",
       "      <td>-0.133382</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.087144</td>\n",
       "      <td>0.011984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168040</td>\n",
       "      <td>0.162860</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>0.151131</td>\n",
       "      <td>0.155388</td>\n",
       "      <td>0.129262</td>\n",
       "      <td>0.135698</td>\n",
       "      <td>0.111947</td>\n",
       "      <td>0.167701</td>\n",
       "      <td>0.136485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>0.090554</td>\n",
       "      <td>0.227452</td>\n",
       "      <td>0.107798</td>\n",
       "      <td>-0.111091</td>\n",
       "      <td>0.034236</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>0.053129</td>\n",
       "      <td>0.087328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141611</td>\n",
       "      <td>0.150539</td>\n",
       "      <td>0.144765</td>\n",
       "      <td>0.121783</td>\n",
       "      <td>0.213598</td>\n",
       "      <td>0.167302</td>\n",
       "      <td>0.200576</td>\n",
       "      <td>0.145017</td>\n",
       "      <td>0.134677</td>\n",
       "      <td>0.162230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>0.086859</td>\n",
       "      <td>0.236306</td>\n",
       "      <td>0.107814</td>\n",
       "      <td>-0.125368</td>\n",
       "      <td>0.026619</td>\n",
       "      <td>0.063352</td>\n",
       "      <td>0.062930</td>\n",
       "      <td>0.091589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151063</td>\n",
       "      <td>0.137519</td>\n",
       "      <td>0.143547</td>\n",
       "      <td>0.122245</td>\n",
       "      <td>0.208562</td>\n",
       "      <td>0.167594</td>\n",
       "      <td>0.192131</td>\n",
       "      <td>0.140914</td>\n",
       "      <td>0.139188</td>\n",
       "      <td>0.161331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>0.096795</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>0.109566</td>\n",
       "      <td>-0.119462</td>\n",
       "      <td>0.023341</td>\n",
       "      <td>0.063660</td>\n",
       "      <td>0.084856</td>\n",
       "      <td>0.081134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0.149445</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.129571</td>\n",
       "      <td>0.209414</td>\n",
       "      <td>0.163841</td>\n",
       "      <td>0.206865</td>\n",
       "      <td>0.140748</td>\n",
       "      <td>0.136384</td>\n",
       "      <td>0.156831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>0.090397</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.104989</td>\n",
       "      <td>-0.123692</td>\n",
       "      <td>0.035497</td>\n",
       "      <td>0.059867</td>\n",
       "      <td>0.049117</td>\n",
       "      <td>0.097395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140717</td>\n",
       "      <td>0.153050</td>\n",
       "      <td>0.143886</td>\n",
       "      <td>0.126306</td>\n",
       "      <td>0.216549</td>\n",
       "      <td>0.164243</td>\n",
       "      <td>0.209510</td>\n",
       "      <td>0.134931</td>\n",
       "      <td>0.139319</td>\n",
       "      <td>0.163781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>0.093171</td>\n",
       "      <td>0.211392</td>\n",
       "      <td>0.110376</td>\n",
       "      <td>-0.122744</td>\n",
       "      <td>0.044559</td>\n",
       "      <td>0.057522</td>\n",
       "      <td>0.053157</td>\n",
       "      <td>0.104916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142342</td>\n",
       "      <td>0.152407</td>\n",
       "      <td>0.147561</td>\n",
       "      <td>0.126262</td>\n",
       "      <td>0.213129</td>\n",
       "      <td>0.169691</td>\n",
       "      <td>0.202239</td>\n",
       "      <td>0.150067</td>\n",
       "      <td>0.147779</td>\n",
       "      <td>0.170372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MatchID  PeriodID         0         1         2         3         4  \\\n",
       "0          0         0  0.015923  0.149446  0.173955 -0.034232 -0.112096   \n",
       "1          0         1 -0.001169  0.133767  0.182607 -0.027490 -0.134708   \n",
       "2          0         2  0.007580  0.124594  0.206335 -0.035794 -0.129705   \n",
       "3          0         3 -0.010865  0.103209  0.217068 -0.027762 -0.135133   \n",
       "4          0         4 -0.011664  0.120250  0.216792 -0.039718 -0.133382   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "511        3       125  0.090554  0.227452  0.107798 -0.111091  0.034236   \n",
       "512        3       126  0.086859  0.236306  0.107814 -0.125368  0.026619   \n",
       "513        3       127  0.096795  0.220505  0.109566 -0.119462  0.023341   \n",
       "514        3       128  0.090397  0.227700  0.104989 -0.123692  0.035497   \n",
       "515        3       129  0.093171  0.211392  0.110376 -0.122744  0.044559   \n",
       "\n",
       "            5         6         7  ...       190       191       192  \\\n",
       "0   -0.020943  0.098379  0.032518  ...  0.153034  0.157182  0.145271   \n",
       "1   -0.008566  0.098646  0.020663  ...  0.165164  0.157495  0.153015   \n",
       "2   -0.000459  0.088574  0.039749  ...  0.179429  0.153216  0.157596   \n",
       "3   -0.004802  0.100052  0.011394  ...  0.188828  0.158445  0.164582   \n",
       "4    0.006180  0.087144  0.011984  ...  0.168040  0.162860  0.142301   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "511  0.063783  0.053129  0.087328  ...  0.141611  0.150539  0.144765   \n",
       "512  0.063352  0.062930  0.091589  ...  0.151063  0.137519  0.143547   \n",
       "513  0.063660  0.084856  0.081134  ...  0.147333  0.149445  0.145800   \n",
       "514  0.059867  0.049117  0.097395  ...  0.140717  0.153050  0.143886   \n",
       "515  0.057522  0.053157  0.104916  ...  0.142342  0.152407  0.147561   \n",
       "\n",
       "          193       194       195       196       197       198       199  \n",
       "0    0.145639  0.128065  0.125192  0.133178  0.117571  0.166727  0.132553  \n",
       "1    0.132694  0.143167  0.135772  0.140925  0.114819  0.156178  0.136774  \n",
       "2    0.163330  0.146216  0.140805  0.146061  0.118530  0.154841  0.137328  \n",
       "3    0.156278  0.158240  0.125951  0.137621  0.116231  0.167588  0.138395  \n",
       "4    0.151131  0.155388  0.129262  0.135698  0.111947  0.167701  0.136485  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "511  0.121783  0.213598  0.167302  0.200576  0.145017  0.134677  0.162230  \n",
       "512  0.122245  0.208562  0.167594  0.192131  0.140914  0.139188  0.161331  \n",
       "513  0.129571  0.209414  0.163841  0.206865  0.140748  0.136384  0.156831  \n",
       "514  0.126306  0.216549  0.164243  0.209510  0.134931  0.139319  0.163781  \n",
       "515  0.126262  0.213129  0.169691  0.202239  0.150067  0.147779  0.170372  \n",
       "\n",
       "[516 rows x 402 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO EVENTTYPE, CAN ONLY MAKE PREDICTIONS WITHOUT KNOWING ACCURACY\n",
    "\n",
    "# there is no df_y when we are trying to evaluate the matches in eval_tweets\n",
    "# for kaggle submission!!\n",
    "# let df_y have all zeros with the same number of rows as df_X\n",
    "# this is just to make code run more easily, df_y\n",
    "#     and tensor_y (value returned by convert_df_to_3D_tensor) will not be used\n",
    "\n",
    "# df_y has no real meaning, only for ease of coding!\n",
    "df_y = pd.Series(0, index=df_eval.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "511    0\n",
       "512    0\n",
       "513    0\n",
       "514    0\n",
       "515    0\n",
       "Length: 516, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 130, 400)\n",
      "(4, 130)\n"
     ]
    }
   ],
   "source": [
    "X_eval_tensor, _ = convert_df_to_3D_tensor(df_eval, df_y)\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_eval_tensor = torch.tensor(X_eval_tensor, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0159,  0.1494,  0.1740,  ...,  0.1176,  0.1667,  0.1326],\n",
       "         [-0.0012,  0.1338,  0.1826,  ...,  0.1148,  0.1562,  0.1368],\n",
       "         [ 0.0076,  0.1246,  0.2063,  ...,  0.1185,  0.1548,  0.1373],\n",
       "         ...,\n",
       "         [ 0.0140,  0.0887,  0.1781,  ...,  0.1278,  0.1420,  0.1155],\n",
       "         [ 0.0052,  0.0957,  0.1780,  ...,  0.1288,  0.1455,  0.1176],\n",
       "         [ 0.0159,  0.0961,  0.1673,  ...,  0.1238,  0.1439,  0.1177]],\n",
       "\n",
       "        [[ 0.1054,  0.2370,  0.0124,  ...,  0.1405,  0.1483,  0.1417],\n",
       "         [ 0.0932,  0.2318,  0.0044,  ...,  0.1463,  0.1466,  0.1404],\n",
       "         [ 0.0896,  0.2348, -0.0018,  ...,  0.1432,  0.1410,  0.1417],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1589,  0.2648,  0.0580,  ...,  0.1181,  0.1100,  0.1266],\n",
       "         [ 0.1563,  0.2714,  0.0593,  ...,  0.1116,  0.1123,  0.1254],\n",
       "         [ 0.1459,  0.2406,  0.0577,  ...,  0.1453,  0.0953,  0.1061],\n",
       "         ...,\n",
       "         [ 0.1209,  0.2895,  0.1666,  ...,  0.1154,  0.1118,  0.1206],\n",
       "         [ 0.1459,  0.2925,  0.1178,  ...,  0.1104,  0.1260,  0.1212],\n",
       "         [ 0.1424,  0.2870,  0.1126,  ...,  0.1135,  0.1281,  0.1257]],\n",
       "\n",
       "        [[ 0.0911,  0.2609,  0.0674,  ...,  0.1296,  0.1357,  0.1542],\n",
       "         [ 0.0741,  0.2192,  0.1009,  ...,  0.1401,  0.1585,  0.1863],\n",
       "         [ 0.0641,  0.2537,  0.0954,  ...,  0.1388,  0.1361,  0.1720],\n",
       "         ...,\n",
       "         [ 0.0968,  0.2205,  0.1096,  ...,  0.1407,  0.1364,  0.1568],\n",
       "         [ 0.0904,  0.2277,  0.1050,  ...,  0.1349,  0.1393,  0.1638],\n",
       "         [ 0.0932,  0.2114,  0.1104,  ...,  0.1501,  0.1478,  0.1704]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eval_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([130, 126, 130, 130])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_eval.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "eval_seq_lengths = (max_periods['PeriodID']+1).tolist() # add +1 since max period ID + 1 is the seq len\n",
    "eval_seq_lengths = torch.tensor(eval_seq_lengths)\n",
    "eval_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "predicted_classes = predict(model, X_eval_tensor, eval_seq_lengths, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "         0., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "         1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "         0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 130])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE CSV OF OUTPUT WITH CORRECT MATCH IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists!\n"
     ]
    }
   ],
   "source": [
    "# confirm file \"our_predictions.csv\" exists\n",
    "# the first column is already hardcoded since it always has the same values\n",
    "\n",
    "file_name = \"our_predictions.csv\"\n",
    "\n",
    "if path.exists(file_name):\n",
    "    print(\"File exists!\")\n",
    "else:\n",
    "    raise ValueError(f\"File '{file_name}' does not exist in the current directory.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now loop through file and add predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9': 0, '15': 1, '6': 2, '16': 3}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match_id_order[match_id]  = i means that the predictions of match_id are in the ith sequence\n",
    "match_id_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 and 0 has prediction: 0.0\n",
      "6 and 1 has prediction: 0.0\n",
      "6 and 2 has prediction: 0.0\n",
      "6 and 3 has prediction: 0.0\n",
      "6 and 4 has prediction: 0.0\n",
      "6 and 5 has prediction: 0.0\n",
      "6 and 6 has prediction: 1.0\n",
      "6 and 7 has prediction: 1.0\n",
      "6 and 8 has prediction: 1.0\n",
      "6 and 9 has prediction: 0.0\n",
      "6 and 10 has prediction: 1.0\n",
      "6 and 11 has prediction: 0.0\n",
      "6 and 12 has prediction: 0.0\n",
      "6 and 13 has prediction: 0.0\n",
      "6 and 14 has prediction: 0.0\n",
      "6 and 15 has prediction: 0.0\n",
      "6 and 16 has prediction: 0.0\n",
      "6 and 17 has prediction: 0.0\n",
      "6 and 18 has prediction: 0.0\n",
      "6 and 19 has prediction: 0.0\n",
      "6 and 20 has prediction: 0.0\n",
      "6 and 21 has prediction: 0.0\n",
      "6 and 22 has prediction: 1.0\n",
      "6 and 23 has prediction: 1.0\n",
      "6 and 24 has prediction: 1.0\n",
      "6 and 25 has prediction: 1.0\n",
      "6 and 26 has prediction: 0.0\n",
      "6 and 27 has prediction: 0.0\n",
      "6 and 28 has prediction: 0.0\n",
      "6 and 29 has prediction: 1.0\n",
      "6 and 30 has prediction: 0.0\n",
      "6 and 31 has prediction: 0.0\n",
      "6 and 32 has prediction: 0.0\n",
      "6 and 33 has prediction: 0.0\n",
      "6 and 34 has prediction: 0.0\n",
      "6 and 35 has prediction: 0.0\n",
      "6 and 36 has prediction: 0.0\n",
      "6 and 37 has prediction: 0.0\n",
      "6 and 38 has prediction: 0.0\n",
      "6 and 39 has prediction: 0.0\n",
      "6 and 40 has prediction: 0.0\n",
      "6 and 41 has prediction: 0.0\n",
      "6 and 42 has prediction: 0.0\n",
      "6 and 43 has prediction: 0.0\n",
      "6 and 44 has prediction: 1.0\n",
      "6 and 45 has prediction: 0.0\n",
      "6 and 46 has prediction: 0.0\n",
      "6 and 47 has prediction: 0.0\n",
      "6 and 48 has prediction: 0.0\n",
      "6 and 49 has prediction: 0.0\n",
      "6 and 50 has prediction: 0.0\n",
      "6 and 51 has prediction: 0.0\n",
      "6 and 52 has prediction: 0.0\n",
      "6 and 53 has prediction: 0.0\n",
      "6 and 54 has prediction: 0.0\n",
      "6 and 55 has prediction: 0.0\n",
      "6 and 56 has prediction: 1.0\n",
      "6 and 57 has prediction: 1.0\n",
      "6 and 58 has prediction: 0.0\n",
      "6 and 59 has prediction: 0.0\n",
      "6 and 60 has prediction: 1.0\n",
      "6 and 61 has prediction: 1.0\n",
      "6 and 62 has prediction: 0.0\n",
      "6 and 63 has prediction: 0.0\n",
      "6 and 64 has prediction: 0.0\n",
      "6 and 65 has prediction: 0.0\n",
      "6 and 66 has prediction: 0.0\n",
      "6 and 67 has prediction: 0.0\n",
      "6 and 68 has prediction: 0.0\n",
      "6 and 69 has prediction: 0.0\n",
      "6 and 70 has prediction: 0.0\n",
      "6 and 71 has prediction: 0.0\n",
      "6 and 72 has prediction: 1.0\n",
      "6 and 73 has prediction: 0.0\n",
      "6 and 74 has prediction: 0.0\n",
      "6 and 75 has prediction: 0.0\n",
      "6 and 76 has prediction: 0.0\n",
      "6 and 77 has prediction: 0.0\n",
      "6 and 78 has prediction: 0.0\n",
      "6 and 79 has prediction: 1.0\n",
      "6 and 80 has prediction: 1.0\n",
      "6 and 81 has prediction: 1.0\n",
      "6 and 82 has prediction: 1.0\n",
      "6 and 83 has prediction: 1.0\n",
      "6 and 84 has prediction: 1.0\n",
      "6 and 85 has prediction: 1.0\n",
      "6 and 86 has prediction: 0.0\n",
      "6 and 87 has prediction: 1.0\n",
      "6 and 88 has prediction: 0.0\n",
      "6 and 89 has prediction: 0.0\n",
      "6 and 90 has prediction: 0.0\n",
      "6 and 91 has prediction: 1.0\n",
      "6 and 92 has prediction: 1.0\n",
      "6 and 93 has prediction: 1.0\n",
      "6 and 94 has prediction: 1.0\n",
      "6 and 95 has prediction: 1.0\n",
      "6 and 96 has prediction: 1.0\n",
      "6 and 97 has prediction: 1.0\n",
      "6 and 98 has prediction: 1.0\n",
      "6 and 99 has prediction: 1.0\n",
      "6 and 100 has prediction: 1.0\n",
      "6 and 101 has prediction: 1.0\n",
      "6 and 102 has prediction: 1.0\n",
      "6 and 103 has prediction: 1.0\n",
      "6 and 104 has prediction: 1.0\n",
      "6 and 105 has prediction: 1.0\n",
      "6 and 106 has prediction: 1.0\n",
      "6 and 107 has prediction: 1.0\n",
      "6 and 108 has prediction: 1.0\n",
      "6 and 109 has prediction: 1.0\n",
      "6 and 110 has prediction: 1.0\n",
      "6 and 111 has prediction: 0.0\n",
      "6 and 112 has prediction: 0.0\n",
      "6 and 113 has prediction: 0.0\n",
      "6 and 114 has prediction: 1.0\n",
      "6 and 115 has prediction: 1.0\n",
      "6 and 116 has prediction: 1.0\n",
      "6 and 117 has prediction: 0.0\n",
      "6 and 118 has prediction: 1.0\n",
      "6 and 119 has prediction: 0.0\n",
      "6 and 120 has prediction: 0.0\n",
      "6 and 121 has prediction: 1.0\n",
      "6 and 122 has prediction: 1.0\n",
      "6 and 123 has prediction: 1.0\n",
      "6 and 124 has prediction: 0.0\n",
      "6 and 125 has prediction: 0.0\n",
      "6 and 126 has prediction: 0.0\n",
      "6 and 127 has prediction: 1.0\n",
      "6 and 128 has prediction: 1.0\n",
      "6 and 129 has prediction: 0.0\n",
      "9 and 0 has prediction: 0.0\n",
      "9 and 1 has prediction: 0.0\n",
      "9 and 2 has prediction: 0.0\n",
      "9 and 3 has prediction: 0.0\n",
      "9 and 4 has prediction: 0.0\n",
      "9 and 5 has prediction: 0.0\n",
      "9 and 6 has prediction: 1.0\n",
      "9 and 7 has prediction: 1.0\n",
      "9 and 8 has prediction: 0.0\n",
      "9 and 9 has prediction: 1.0\n",
      "9 and 10 has prediction: 1.0\n",
      "9 and 11 has prediction: 1.0\n",
      "9 and 12 has prediction: 0.0\n",
      "9 and 13 has prediction: 0.0\n",
      "9 and 14 has prediction: 0.0\n",
      "9 and 15 has prediction: 0.0\n",
      "9 and 16 has prediction: 0.0\n",
      "9 and 17 has prediction: 0.0\n",
      "9 and 18 has prediction: 0.0\n",
      "9 and 19 has prediction: 0.0\n",
      "9 and 20 has prediction: 0.0\n",
      "9 and 21 has prediction: 0.0\n",
      "9 and 22 has prediction: 0.0\n",
      "9 and 23 has prediction: 0.0\n",
      "9 and 24 has prediction: 1.0\n",
      "9 and 25 has prediction: 1.0\n",
      "9 and 26 has prediction: 0.0\n",
      "9 and 27 has prediction: 0.0\n",
      "9 and 28 has prediction: 0.0\n",
      "9 and 29 has prediction: 0.0\n",
      "9 and 30 has prediction: 1.0\n",
      "9 and 31 has prediction: 1.0\n",
      "9 and 32 has prediction: 0.0\n",
      "9 and 33 has prediction: 0.0\n",
      "9 and 34 has prediction: 0.0\n",
      "9 and 35 has prediction: 1.0\n",
      "9 and 36 has prediction: 0.0\n",
      "9 and 37 has prediction: 0.0\n",
      "9 and 38 has prediction: 0.0\n",
      "9 and 39 has prediction: 0.0\n",
      "9 and 40 has prediction: 0.0\n",
      "9 and 41 has prediction: 0.0\n",
      "9 and 42 has prediction: 0.0\n",
      "9 and 43 has prediction: 1.0\n",
      "9 and 44 has prediction: 1.0\n",
      "9 and 45 has prediction: 0.0\n",
      "9 and 46 has prediction: 0.0\n",
      "9 and 47 has prediction: 0.0\n",
      "9 and 48 has prediction: 0.0\n",
      "9 and 49 has prediction: 0.0\n",
      "9 and 50 has prediction: 0.0\n",
      "9 and 51 has prediction: 0.0\n",
      "9 and 52 has prediction: 1.0\n",
      "9 and 53 has prediction: 1.0\n",
      "9 and 54 has prediction: 1.0\n",
      "9 and 55 has prediction: 1.0\n",
      "9 and 56 has prediction: 1.0\n",
      "9 and 57 has prediction: 1.0\n",
      "9 and 58 has prediction: 1.0\n",
      "9 and 59 has prediction: 0.0\n",
      "9 and 60 has prediction: 1.0\n",
      "9 and 61 has prediction: 1.0\n",
      "9 and 62 has prediction: 1.0\n",
      "9 and 63 has prediction: 0.0\n",
      "9 and 64 has prediction: 0.0\n",
      "9 and 65 has prediction: 0.0\n",
      "9 and 66 has prediction: 0.0\n",
      "9 and 67 has prediction: 0.0\n",
      "9 and 68 has prediction: 0.0\n",
      "9 and 69 has prediction: 0.0\n",
      "9 and 70 has prediction: 1.0\n",
      "9 and 71 has prediction: 0.0\n",
      "9 and 72 has prediction: 0.0\n",
      "9 and 73 has prediction: 0.0\n",
      "9 and 74 has prediction: 1.0\n",
      "9 and 75 has prediction: 0.0\n",
      "9 and 76 has prediction: 0.0\n",
      "9 and 77 has prediction: 0.0\n",
      "9 and 78 has prediction: 0.0\n",
      "9 and 79 has prediction: 0.0\n",
      "9 and 80 has prediction: 0.0\n",
      "9 and 81 has prediction: 0.0\n",
      "9 and 82 has prediction: 0.0\n",
      "9 and 83 has prediction: 0.0\n",
      "9 and 84 has prediction: 0.0\n",
      "9 and 85 has prediction: 0.0\n",
      "9 and 86 has prediction: 0.0\n",
      "9 and 87 has prediction: 0.0\n",
      "9 and 88 has prediction: 0.0\n",
      "9 and 89 has prediction: 0.0\n",
      "9 and 90 has prediction: 0.0\n",
      "9 and 91 has prediction: 0.0\n",
      "9 and 92 has prediction: 1.0\n",
      "9 and 93 has prediction: 1.0\n",
      "9 and 94 has prediction: 0.0\n",
      "9 and 95 has prediction: 0.0\n",
      "9 and 96 has prediction: 0.0\n",
      "9 and 97 has prediction: 0.0\n",
      "9 and 98 has prediction: 0.0\n",
      "9 and 99 has prediction: 0.0\n",
      "9 and 100 has prediction: 0.0\n",
      "9 and 101 has prediction: 0.0\n",
      "9 and 102 has prediction: 1.0\n",
      "9 and 103 has prediction: 1.0\n",
      "9 and 104 has prediction: 1.0\n",
      "9 and 105 has prediction: 1.0\n",
      "9 and 106 has prediction: 1.0\n",
      "9 and 107 has prediction: 1.0\n",
      "9 and 108 has prediction: 1.0\n",
      "9 and 109 has prediction: 0.0\n",
      "9 and 110 has prediction: 1.0\n",
      "9 and 111 has prediction: 0.0\n",
      "9 and 112 has prediction: 1.0\n",
      "9 and 113 has prediction: 1.0\n",
      "9 and 114 has prediction: 1.0\n",
      "9 and 115 has prediction: 1.0\n",
      "9 and 116 has prediction: 1.0\n",
      "9 and 117 has prediction: 1.0\n",
      "9 and 118 has prediction: 1.0\n",
      "9 and 119 has prediction: 0.0\n",
      "9 and 120 has prediction: 1.0\n",
      "9 and 121 has prediction: 1.0\n",
      "9 and 122 has prediction: 1.0\n",
      "9 and 123 has prediction: 1.0\n",
      "9 and 124 has prediction: 1.0\n",
      "9 and 125 has prediction: 1.0\n",
      "9 and 126 has prediction: 1.0\n",
      "9 and 127 has prediction: 1.0\n",
      "9 and 128 has prediction: 0.0\n",
      "9 and 129 has prediction: 0.0\n",
      "15 and 0 has prediction: 0.0\n",
      "15 and 1 has prediction: 0.0\n",
      "15 and 2 has prediction: 0.0\n",
      "15 and 3 has prediction: 0.0\n",
      "15 and 4 has prediction: 0.0\n",
      "15 and 5 has prediction: 1.0\n",
      "15 and 6 has prediction: 1.0\n",
      "15 and 7 has prediction: 1.0\n",
      "15 and 8 has prediction: 1.0\n",
      "15 and 9 has prediction: 1.0\n",
      "15 and 10 has prediction: 1.0\n",
      "15 and 11 has prediction: 1.0\n",
      "15 and 12 has prediction: 0.0\n",
      "15 and 13 has prediction: 1.0\n",
      "15 and 14 has prediction: 0.0\n",
      "15 and 15 has prediction: 0.0\n",
      "15 and 16 has prediction: 0.0\n",
      "15 and 17 has prediction: 0.0\n",
      "15 and 18 has prediction: 0.0\n",
      "15 and 19 has prediction: 0.0\n",
      "15 and 20 has prediction: 0.0\n",
      "15 and 21 has prediction: 0.0\n",
      "15 and 22 has prediction: 0.0\n",
      "15 and 23 has prediction: 0.0\n",
      "15 and 24 has prediction: 0.0\n",
      "15 and 25 has prediction: 0.0\n",
      "15 and 26 has prediction: 0.0\n",
      "15 and 27 has prediction: 1.0\n",
      "15 and 28 has prediction: 0.0\n",
      "15 and 29 has prediction: 0.0\n",
      "15 and 30 has prediction: 0.0\n",
      "15 and 31 has prediction: 0.0\n",
      "15 and 32 has prediction: 0.0\n",
      "15 and 33 has prediction: 0.0\n",
      "15 and 34 has prediction: 1.0\n",
      "15 and 35 has prediction: 0.0\n",
      "15 and 36 has prediction: 0.0\n",
      "15 and 37 has prediction: 1.0\n",
      "15 and 38 has prediction: 0.0\n",
      "15 and 39 has prediction: 1.0\n",
      "15 and 40 has prediction: 0.0\n",
      "15 and 41 has prediction: 0.0\n",
      "15 and 42 has prediction: 0.0\n",
      "15 and 43 has prediction: 0.0\n",
      "15 and 44 has prediction: 0.0\n",
      "15 and 45 has prediction: 0.0\n",
      "15 and 46 has prediction: 0.0\n",
      "15 and 47 has prediction: 0.0\n",
      "15 and 48 has prediction: 0.0\n",
      "15 and 49 has prediction: 0.0\n",
      "15 and 50 has prediction: 0.0\n",
      "15 and 51 has prediction: 0.0\n",
      "15 and 52 has prediction: 1.0\n",
      "15 and 53 has prediction: 1.0\n",
      "15 and 54 has prediction: 1.0\n",
      "15 and 55 has prediction: 1.0\n",
      "15 and 56 has prediction: 1.0\n",
      "15 and 57 has prediction: 1.0\n",
      "15 and 58 has prediction: 0.0\n",
      "15 and 59 has prediction: 0.0\n",
      "15 and 60 has prediction: 0.0\n",
      "15 and 61 has prediction: 0.0\n",
      "15 and 62 has prediction: 0.0\n",
      "15 and 63 has prediction: 0.0\n",
      "15 and 64 has prediction: 0.0\n",
      "15 and 65 has prediction: 1.0\n",
      "15 and 66 has prediction: 0.0\n",
      "15 and 67 has prediction: 1.0\n",
      "15 and 68 has prediction: 0.0\n",
      "15 and 69 has prediction: 0.0\n",
      "15 and 70 has prediction: 0.0\n",
      "15 and 71 has prediction: 1.0\n",
      "15 and 72 has prediction: 0.0\n",
      "15 and 73 has prediction: 1.0\n",
      "15 and 74 has prediction: 1.0\n",
      "15 and 75 has prediction: 1.0\n",
      "15 and 76 has prediction: 1.0\n",
      "15 and 77 has prediction: 1.0\n",
      "15 and 78 has prediction: 0.0\n",
      "15 and 79 has prediction: 0.0\n",
      "15 and 80 has prediction: 0.0\n",
      "15 and 81 has prediction: 0.0\n",
      "15 and 82 has prediction: 1.0\n",
      "15 and 83 has prediction: 1.0\n",
      "15 and 84 has prediction: 0.0\n",
      "15 and 85 has prediction: 0.0\n",
      "15 and 86 has prediction: 0.0\n",
      "15 and 87 has prediction: 0.0\n",
      "15 and 88 has prediction: 0.0\n",
      "15 and 89 has prediction: 0.0\n",
      "15 and 90 has prediction: 0.0\n",
      "15 and 91 has prediction: 0.0\n",
      "15 and 92 has prediction: 0.0\n",
      "15 and 93 has prediction: 1.0\n",
      "15 and 94 has prediction: 0.0\n",
      "15 and 95 has prediction: 1.0\n",
      "15 and 96 has prediction: 0.0\n",
      "15 and 97 has prediction: 0.0\n",
      "15 and 98 has prediction: 0.0\n",
      "15 and 99 has prediction: 0.0\n",
      "15 and 100 has prediction: 0.0\n",
      "15 and 101 has prediction: 0.0\n",
      "15 and 102 has prediction: 0.0\n",
      "15 and 103 has prediction: 0.0\n",
      "15 and 104 has prediction: 0.0\n",
      "15 and 105 has prediction: 0.0\n",
      "15 and 106 has prediction: 0.0\n",
      "15 and 107 has prediction: 0.0\n",
      "15 and 108 has prediction: 0.0\n",
      "15 and 109 has prediction: 0.0\n",
      "15 and 110 has prediction: 1.0\n",
      "15 and 111 has prediction: 1.0\n",
      "15 and 112 has prediction: 1.0\n",
      "15 and 113 has prediction: 1.0\n",
      "15 and 114 has prediction: 1.0\n",
      "15 and 115 has prediction: 1.0\n",
      "15 and 116 has prediction: 0.0\n",
      "15 and 117 has prediction: 1.0\n",
      "15 and 118 has prediction: 1.0\n",
      "15 and 119 has prediction: 1.0\n",
      "15 and 120 has prediction: 1.0\n",
      "15 and 121 has prediction: 1.0\n",
      "15 and 122 has prediction: 1.0\n",
      "15 and 123 has prediction: 1.0\n",
      "15 and 124 has prediction: 1.0\n",
      "15 and 125 has prediction: 1.0\n",
      "16 and 0 has prediction: 1.0\n",
      "16 and 1 has prediction: 1.0\n",
      "16 and 2 has prediction: 1.0\n",
      "16 and 3 has prediction: 1.0\n",
      "16 and 4 has prediction: 0.0\n",
      "16 and 5 has prediction: 1.0\n",
      "16 and 6 has prediction: 1.0\n",
      "16 and 7 has prediction: 1.0\n",
      "16 and 8 has prediction: 0.0\n",
      "16 and 9 has prediction: 1.0\n",
      "16 and 10 has prediction: 0.0\n",
      "16 and 11 has prediction: 0.0\n",
      "16 and 12 has prediction: 1.0\n",
      "16 and 13 has prediction: 1.0\n",
      "16 and 14 has prediction: 1.0\n",
      "16 and 15 has prediction: 0.0\n",
      "16 and 16 has prediction: 0.0\n",
      "16 and 17 has prediction: 1.0\n",
      "16 and 18 has prediction: 1.0\n",
      "16 and 19 has prediction: 0.0\n",
      "16 and 20 has prediction: 0.0\n",
      "16 and 21 has prediction: 0.0\n",
      "16 and 22 has prediction: 1.0\n",
      "16 and 23 has prediction: 1.0\n",
      "16 and 24 has prediction: 0.0\n",
      "16 and 25 has prediction: 0.0\n",
      "16 and 26 has prediction: 0.0\n",
      "16 and 27 has prediction: 0.0\n",
      "16 and 28 has prediction: 1.0\n",
      "16 and 29 has prediction: 1.0\n",
      "16 and 30 has prediction: 1.0\n",
      "16 and 31 has prediction: 1.0\n",
      "16 and 32 has prediction: 1.0\n",
      "16 and 33 has prediction: 1.0\n",
      "16 and 34 has prediction: 0.0\n",
      "16 and 35 has prediction: 1.0\n",
      "16 and 36 has prediction: 1.0\n",
      "16 and 37 has prediction: 1.0\n",
      "16 and 38 has prediction: 0.0\n",
      "16 and 39 has prediction: 0.0\n",
      "16 and 40 has prediction: 1.0\n",
      "16 and 41 has prediction: 1.0\n",
      "16 and 42 has prediction: 1.0\n",
      "16 and 43 has prediction: 1.0\n",
      "16 and 44 has prediction: 1.0\n",
      "16 and 45 has prediction: 1.0\n",
      "16 and 46 has prediction: 1.0\n",
      "16 and 47 has prediction: 1.0\n",
      "16 and 48 has prediction: 1.0\n",
      "16 and 49 has prediction: 1.0\n",
      "16 and 50 has prediction: 1.0\n",
      "16 and 51 has prediction: 1.0\n",
      "16 and 52 has prediction: 1.0\n",
      "16 and 53 has prediction: 0.0\n",
      "16 and 54 has prediction: 1.0\n",
      "16 and 55 has prediction: 1.0\n",
      "16 and 56 has prediction: 1.0\n",
      "16 and 57 has prediction: 1.0\n",
      "16 and 58 has prediction: 1.0\n",
      "16 and 59 has prediction: 1.0\n",
      "16 and 60 has prediction: 1.0\n",
      "16 and 61 has prediction: 1.0\n",
      "16 and 62 has prediction: 1.0\n",
      "16 and 63 has prediction: 0.0\n",
      "16 and 64 has prediction: 1.0\n",
      "16 and 65 has prediction: 0.0\n",
      "16 and 66 has prediction: 0.0\n",
      "16 and 67 has prediction: 0.0\n",
      "16 and 68 has prediction: 0.0\n",
      "16 and 69 has prediction: 0.0\n",
      "16 and 70 has prediction: 1.0\n",
      "16 and 71 has prediction: 1.0\n",
      "16 and 72 has prediction: 1.0\n",
      "16 and 73 has prediction: 0.0\n",
      "16 and 74 has prediction: 0.0\n",
      "16 and 75 has prediction: 0.0\n",
      "16 and 76 has prediction: 0.0\n",
      "16 and 77 has prediction: 0.0\n",
      "16 and 78 has prediction: 0.0\n",
      "16 and 79 has prediction: 0.0\n",
      "16 and 80 has prediction: 0.0\n",
      "16 and 81 has prediction: 1.0\n",
      "16 and 82 has prediction: 1.0\n",
      "16 and 83 has prediction: 0.0\n",
      "16 and 84 has prediction: 1.0\n",
      "16 and 85 has prediction: 1.0\n",
      "16 and 86 has prediction: 1.0\n",
      "16 and 87 has prediction: 1.0\n",
      "16 and 88 has prediction: 1.0\n",
      "16 and 89 has prediction: 1.0\n",
      "16 and 90 has prediction: 1.0\n",
      "16 and 91 has prediction: 0.0\n",
      "16 and 92 has prediction: 1.0\n",
      "16 and 93 has prediction: 1.0\n",
      "16 and 94 has prediction: 1.0\n",
      "16 and 95 has prediction: 1.0\n",
      "16 and 96 has prediction: 1.0\n",
      "16 and 97 has prediction: 1.0\n",
      "16 and 98 has prediction: 1.0\n",
      "16 and 99 has prediction: 0.0\n",
      "16 and 100 has prediction: 0.0\n",
      "16 and 101 has prediction: 0.0\n",
      "16 and 102 has prediction: 0.0\n",
      "16 and 103 has prediction: 0.0\n",
      "16 and 104 has prediction: 0.0\n",
      "16 and 105 has prediction: 1.0\n",
      "16 and 106 has prediction: 1.0\n",
      "16 and 107 has prediction: 1.0\n",
      "16 and 108 has prediction: 0.0\n",
      "16 and 109 has prediction: 0.0\n",
      "16 and 110 has prediction: 0.0\n",
      "16 and 111 has prediction: 1.0\n",
      "16 and 112 has prediction: 1.0\n",
      "16 and 113 has prediction: 0.0\n",
      "16 and 114 has prediction: 0.0\n",
      "16 and 115 has prediction: 0.0\n",
      "16 and 116 has prediction: 1.0\n",
      "16 and 117 has prediction: 1.0\n",
      "16 and 118 has prediction: 1.0\n",
      "16 and 119 has prediction: 0.0\n",
      "16 and 120 has prediction: 1.0\n",
      "16 and 121 has prediction: 1.0\n",
      "16 and 122 has prediction: 1.0\n",
      "16 and 123 has prediction: 1.0\n",
      "16 and 124 has prediction: 1.0\n",
      "16 and 125 has prediction: 1.0\n",
      "16 and 126 has prediction: 1.0\n",
      "16 and 127 has prediction: 1.0\n",
      "16 and 128 has prediction: 1.0\n",
      "16 and 129 has prediction: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "with open(file_name, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    rows = list(reader)\n",
    "\n",
    "# add the prediction to each row\n",
    "\n",
    "for i in range(1,len(rows)): # skip first row: ID,EventType\n",
    "    row = rows[i]\n",
    "    # row[0] is first column: ID: matchID_periodID\n",
    "    # row[1] is second column: EventType, which we want to write with the prediction\n",
    "    \n",
    "    match_id, period_id = row[0].split(\"_\")\n",
    "    \n",
    "    prediction = predicted_classes[match_id_order[match_id]][int(period_id)]\n",
    "    print(f\"{match_id} and {period_id} has prediction: {prediction}\")\n",
    "    row[1] = float(prediction)\n",
    "\n",
    "# write the modified data back to the CSV file\n",
    "with open(file_name, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_predictions.csv contains the predictions!\n",
    "# our_predictions.csv NEEDS TO BE IN CURRENT DIRECTORY WITH FIRST ROW AND FIRST COLUMN WITH EXPECTED VALUES\n",
    "#     THIS IS WHY our_predictions.csv is added to github repo, it is needed to run the code\n",
    "# DONE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "et9Eb8hEz1aC"
   },
   "outputs": [],
   "source": [
    "# NOTES\n",
    "# HOW TO MAKE SURE THAT we:\n",
    "# 1. DO NOT ignore the order of the tweets -> (LSTM)\n",
    "# 2. treat each time period as RELATED to the football match they belong to -> treat each match as a sequence, train LSTM on every sequence\n",
    "#                      since pytorch tensor expects multiple sequences (batches)\n",
    "\n",
    "\n",
    "\n",
    "# for LSTM: Each input sequence consists of tweet embeddings (200 dimensional) from a specific match, ordered by Period ID.\n",
    "#   tweets of different matches are unrelated, but tweets of a same match are related sequentially (chronologically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ipx_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
