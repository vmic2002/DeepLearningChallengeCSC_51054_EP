{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "WWrRFeKRX-DI",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import libraries and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDtRGZMPNrAM",
    "outputId": "ffc1fd2b-0bac-4a28-e9dd-de135042cc38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/infres/kbrowder-24/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/infres/kbrowder-24/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gc\n",
    "import gensim.downloader as api\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from math import ceil\n",
    "import torch.optim as optim\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load GloVe model with Gensim's API - Twitter specific embedding\n",
    "embeddings_model = api.load(\"glove-twitter-200\")  # 200-dimensional GloVe embeddings\n",
    "\n",
    "#To check that T4 GPU is connected\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"modin[all]\"\n",
    "# import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install swifter\n",
    "# import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/kbrowder-24/DeepLearningChallengeCSC_51054_EP/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Options: \"ray\" or \"dask\"\n",
    "# import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swifter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csoDmI8_X2OO"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "5SVFWTlQX0Jy",
    "outputId": "137b7b7f-e522-433b-9a21-04250b9125db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USASlovenia2010.csv\n",
      "ArgentinaBelgium72.csv\n",
      "AustraliaSpain34.csv\n",
      "ArgentinaGermanyFinal77.csv\n",
      "AustraliaNetherlands29.csv\n",
      "BelgiumSouthKorea59.csv\n",
      "HondurasSwitzerland54.csv\n",
      "FranceGermany70.csv\n",
      "GermanyBrazil74.csv\n",
      "GermanyUSA57.csv\n",
      "MexicoCroatia37.csv\n",
      "FranceNigeria66.csv\n",
      "CameroonBrazil36.csv\n",
      "NetherlandsChile35.csv\n",
      "PortugalGhana58.csv\n",
      "GermanyAlgeria67.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>#USA All My Stateside Followers Stand Up And R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>@Lynz_89 I think the ref might have been Basil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>Hoping a #USA win can help ease the pain of la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>When does this actually start?  #worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>Hanson and Roy are a proper pundit line up. #w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>RT @FOXSoccer: 3/4 of the #WorldCup quarterfin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>RT @Rodolph_hilal: Plz guys RETWEET .. \\n\\nLet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>RT @Joey7Barton: Algeria can take a lot of pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>RT @caughtoffside: #ALG gave it their all, was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>So be it...  #FRA #GER in 1/4 finals ^_^ #worl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID MatchID  PeriodID  EventType      Timestamp  \\\n",
       "0           0_0       0         0          0  1276869000000   \n",
       "1           0_0       0         0          0  1276869000000   \n",
       "2           0_0       0         0          0  1276869000000   \n",
       "3           0_0       0         0          0  1276869000000   \n",
       "4           0_0       0         0          0  1276869000000   \n",
       "...         ...     ...       ...        ...            ...   \n",
       "5056045  15_169      15       169          0  1404168000000   \n",
       "5056046  15_169      15       169          0  1404168000000   \n",
       "5056047  15_169      15       169          0  1404168000000   \n",
       "5056048  15_169      15       169          0  1404168000000   \n",
       "5056049  15_169      15       169          0  1404168000000   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        #USA All My Stateside Followers Stand Up And R...  \n",
       "1        @Lynz_89 I think the ref might have been Basil...  \n",
       "2        Hoping a #USA win can help ease the pain of la...  \n",
       "3                When does this actually start?  #worldcup  \n",
       "4        Hanson and Roy are a proper pundit line up. #w...  \n",
       "...                                                    ...  \n",
       "5056045  RT @FOXSoccer: 3/4 of the #WorldCup quarterfin...  \n",
       "5056046  RT @Rodolph_hilal: Plz guys RETWEET .. \\n\\nLet...  \n",
       "5056047  RT @Joey7Barton: Algeria can take a lot of pos...  \n",
       "5056048  RT @caughtoffside: #ALG gave it their all, was...  \n",
       "5056049  So be it...  #FRA #GER in 1/4 finals ^_^ #worl...  \n",
       "\n",
       "[5056050 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all training files and concatenate them into one dataframe\n",
    "\n",
    "#import os\n",
    "#print(os.getcwd())\n",
    "\n",
    "li = []\n",
    "i = 0\n",
    "for filename in listdir(\"train_tweets\"):\n",
    "    if filename != '.ipynb_checkpoints':\n",
    "        print(filename)\n",
    "        df = pd.read_csv(\"train_tweets/\" + filename)\n",
    "        # df.drop(columns=['Timestamp'], inplace=True)\n",
    "        # drop unused column(s)\n",
    "        df['MatchID'] = str(i)\n",
    "        df['ID'] = str(i)+ '_' + df['PeriodID'].astype(str)\n",
    "        # makes sure that the match IDs are ordered from 0,1,2... with no missing values\n",
    "        i+=1\n",
    "        li.append(df)\n",
    "df = pd.concat(li, ignore_index=True)\n",
    "#print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "id": "zTYShYPVXs2w",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing of tweet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove non letter and whitespace\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    # text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenization\n",
    "    words = text.split()\n",
    "    # Remove stopwords and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    # words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pCBsffiAbRM0",
    "outputId": "38b4c93f-5af9-444c-c2fa-19a31b586353"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 5056050/5056050 [02:55<00:00, 28851.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>usa stateside follower stand represent beautif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>lynz think ref might basil fawlty actually wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>hoping usa win help ease pain last night loss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>actually start worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>hanson roy proper pundit line worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>rt foxsoccer worldcup quarterfinal set ger v f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>rt rodolphhilal plz guy retweet let trend alg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>rt joeybarton algeria take lot positive big bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>rt caughtoffside alg gave wasnt enough heart t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>fra ger final worldcup mmfutis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID MatchID  PeriodID  EventType      Timestamp  \\\n",
       "0           0_0       0         0          0  1276869000000   \n",
       "1           0_0       0         0          0  1276869000000   \n",
       "2           0_0       0         0          0  1276869000000   \n",
       "3           0_0       0         0          0  1276869000000   \n",
       "4           0_0       0         0          0  1276869000000   \n",
       "...         ...     ...       ...        ...            ...   \n",
       "5056045  15_169      15       169          0  1404168000000   \n",
       "5056046  15_169      15       169          0  1404168000000   \n",
       "5056047  15_169      15       169          0  1404168000000   \n",
       "5056048  15_169      15       169          0  1404168000000   \n",
       "5056049  15_169      15       169          0  1404168000000   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        usa stateside follower stand represent beautif...  \n",
       "1        lynz think ref might basil fawlty actually wor...  \n",
       "2        hoping usa win help ease pain last night loss ...  \n",
       "3                                  actually start worldcup  \n",
       "4                   hanson roy proper pundit line worldcup  \n",
       "...                                                    ...  \n",
       "5056045  rt foxsoccer worldcup quarterfinal set ger v f...  \n",
       "5056046  rt rodolphhilal plz guy retweet let trend alg ...  \n",
       "5056047  rt joeybarton algeria take lot positive big bi...  \n",
       "5056048  rt caughtoffside alg gave wasnt enough heart t...  \n",
       "5056049                     fra ger final worldcup mmfutis  \n",
       "\n",
       "[5056050 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to each tweet\n",
    "df['Tweet'] = df['Tweet'].swifter.apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YW4PGmMxrF4r"
   },
   "source": [
    "# Tweet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fP-s9Uqmot9q"
   },
   "outputs": [],
   "source": [
    "# Get vector tweet embeddings\n",
    "# TODOOOOOOOOOOOOOOOO maybe instead of avg word embedding for each tweet can get sentence\n",
    "#   embeddings to retain more information\n",
    "#   -> can try more complex functions here\n",
    "#   -> avg embedding of each word for a tweet is fine for now, maybe works well enough\n",
    "\n",
    "# Function to compute the average word vector for a tweet\n",
    "def get_avg_embedding(tweet, model, vector_size=200):\n",
    "    words = tweet.split()  # Tokenize by whitespace\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if not word_vectors:  # If no words in the tweet are in the vocabulary, return a zero vector\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(word_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OEBgxG9xvc9p"
   },
   "outputs": [],
   "source": [
    "# Crashes after using all available RAM :( on google colab\n",
    "# \n",
    "\n",
    "# obtain vector tweet embeddings\n",
    "vector_size = 200  # Adjust based on the chosen GloVe model\n",
    "# tweet_vectors = np.vstack([get_avg_embedding(tweet, embeddings_model, vector_size) for tweet in df['Tweet']])\n",
    "# tweet_df = pd.DataFrame(tweet_vectors)\n",
    "# tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 5056050/5056050 [02:23<00:00, 35148.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "f = partial(get_avg_embedding, model=embeddings_model,vector_size=vector_size)\n",
    "f.__name__ = \"paritla\"\n",
    "f.__module__ = get_avg_embedding.__module__\n",
    "\n",
    "df[\"tweet_vector\"] = df[\"Tweet\"].swifter.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4b4cFEFb-qo4"
   },
   "outputs": [],
   "source": [
    "# Attach the vectors into the original dataframe\n",
    "# df = pd.concat([df, tweet_df], axis=1)\n",
    "\n",
    "# Drop the columns that are not useful anymore\n",
    "# no need for Tweet column since we have its corresponding vector embedding\n",
    "df.drop(columns=['Tweet'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[0.066179484, 0.25621355, 0.08082778, -0.33907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[-0.1474687, 0.3667189, 0.10468656, 0.049433, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[0.22338197, 0.27252772, 0.07159816, -0.293135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[-0.10895123, 0.28830335, 0.40979335, -0.22218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[-0.112306446, 0.11411217, 0.24610366, -0.4545...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID MatchID  PeriodID  EventType      Timestamp  \\\n",
       "0  0_0       0         0          0  1276869000000   \n",
       "1  0_0       0         0          0  1276869000000   \n",
       "2  0_0       0         0          0  1276869000000   \n",
       "3  0_0       0         0          0  1276869000000   \n",
       "4  0_0       0         0          0  1276869000000   \n",
       "\n",
       "                                        tweet_vector  \n",
       "0  [0.066179484, 0.25621355, 0.08082778, -0.33907...  \n",
       "1  [-0.1474687, 0.3667189, 0.10468656, 0.049433, ...  \n",
       "2  [0.22338197, 0.27252772, 0.07159816, -0.293135...  \n",
       "3  [-0.10895123, 0.28830335, 0.40979335, -0.22218...  \n",
       "4  [-0.112306446, 0.11411217, 0.24610366, -0.4545...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[0.066179484, 0.25621355, 0.08082778, -0.33907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[-0.1474687, 0.3667189, 0.10468656, 0.049433, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[0.22338197, 0.27252772, 0.07159816, -0.293135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[-0.10895123, 0.28830335, 0.40979335, -0.22218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>[-0.112306446, 0.11411217, 0.24610366, -0.4545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>[0.13047262, 0.2851209, 0.018671205, -0.052115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>[0.30743918, 0.36894467, -0.1729, -0.27685714,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>[0.14770256, 0.20187803, -0.1268579, -0.095563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>[0.016947214, 0.28408444, 0.08043686, 0.101969...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>[0.15036534, 0.3681025, 0.21266, -0.239125, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID MatchID  PeriodID  EventType      Timestamp  \\\n",
       "0           0_0       0         0          0  1276869000000   \n",
       "1           0_0       0         0          0  1276869000000   \n",
       "2           0_0       0         0          0  1276869000000   \n",
       "3           0_0       0         0          0  1276869000000   \n",
       "4           0_0       0         0          0  1276869000000   \n",
       "...         ...     ...       ...        ...            ...   \n",
       "5056045  15_169      15       169          0  1404168000000   \n",
       "5056046  15_169      15       169          0  1404168000000   \n",
       "5056047  15_169      15       169          0  1404168000000   \n",
       "5056048  15_169      15       169          0  1404168000000   \n",
       "5056049  15_169      15       169          0  1404168000000   \n",
       "\n",
       "                                              tweet_vector  \n",
       "0        [0.066179484, 0.25621355, 0.08082778, -0.33907...  \n",
       "1        [-0.1474687, 0.3667189, 0.10468656, 0.049433, ...  \n",
       "2        [0.22338197, 0.27252772, 0.07159816, -0.293135...  \n",
       "3        [-0.10895123, 0.28830335, 0.40979335, -0.22218...  \n",
       "4        [-0.112306446, 0.11411217, 0.24610366, -0.4545...  \n",
       "...                                                    ...  \n",
       "5056045  [0.13047262, 0.2851209, 0.018671205, -0.052115...  \n",
       "5056046  [0.30743918, 0.36894467, -0.1729, -0.27685714,...  \n",
       "5056047  [0.14770256, 0.20187803, -0.1268579, -0.095563...  \n",
       "5056048  [0.016947214, 0.28408444, 0.08043686, 0.101969...  \n",
       "5056049  [0.15036534, 0.3681025, 0.21266, -0.239125, 0....  \n",
       "\n",
       "[5056050 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by now should have df with columns: ID, match id, period id, Event Type, tweet_vector. Tweet_vector is just 200 columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_chunks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2726494/1731830507.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['chunk'] = df.groupby(['MatchID', 'PeriodID']).apply(\n"
     ]
    }
   ],
   "source": [
    "# Sort by MatchID, PeriodID, and Timestamp to maintain order\n",
    "df = df.sort_values(by=['MatchID', 'PeriodID', 'Timestamp']).reset_index(drop=True)\n",
    "\n",
    "# Helper function to assign chunks\n",
    "def assign_chunks(group, n_chunks=period_chunks):\n",
    "    chunk_size = len(group) / n_chunks\n",
    "    return (np.floor(np.arange(len(group)) / chunk_size)).astype(int)\n",
    "\n",
    "# Apply chunk assignment within each MatchID and PeriodID\n",
    "df['chunk'] = df.groupby(['MatchID', 'PeriodID']).apply(\n",
    "    lambda group: assign_chunks(group)\n",
    ").explode().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the tweets into their corresponding periods to generate an average embedding vector for each period\n",
    "# so there are no duplicate period id rows per match\n",
    "# decreases size of data + makes it easier to fit into LSTM model\n",
    "df = df.groupby(['MatchID', 'PeriodID', 'ID','chunk']).mean().reset_index()\n",
    "df.drop(columns=['ID'], inplace=True) \n",
    "df['MatchID'] = df['MatchID'].astype(int)\n",
    "df['PeriodID'] = df['PeriodID'].astype(int)\n",
    "# need to convert to int before sorting\n",
    "df.sort_values(by=['MatchID', 'PeriodID', 'chunk'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>chunk</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.049786884, 0.1913198, 0.068040654, -0.15670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.09133990850442877, 0.25186495755154353, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.11688901, 0.22027843, 0.10215302, -0.159173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.12811066, 0.23626624, 0.11524634, -0.131818...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.07077107, 0.23463808, 0.07358122, -0.123566...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.12749639, 0.23482081, 0.052804522, -0.06213...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.13463659662257052, 0.23993844279640894, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.12705522455795054, 0.24554795088920525, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10683</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.121888824, 0.24418654, 0.042192977, -0.0525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10684</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.12975031620621433, 0.24148471927183437, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10685 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MatchID  PeriodID  chunk  EventType     Timestamp  \\\n",
       "0            0         0      0        0.0  1.276869e+12   \n",
       "1            0         0      1        0.0  1.276869e+12   \n",
       "2            0         0      2        0.0  1.276869e+12   \n",
       "3            0         0      3        0.0  1.276869e+12   \n",
       "4            0         0      4        0.0  1.276869e+12   \n",
       "...        ...       ...    ...        ...           ...   \n",
       "10680       15       169      0        0.0  1.404168e+12   \n",
       "10681       15       169      1        0.0  1.404168e+12   \n",
       "10682       15       169      2        0.0  1.404168e+12   \n",
       "10683       15       169      3        0.0  1.404168e+12   \n",
       "10684       15       169      4        0.0  1.404168e+12   \n",
       "\n",
       "                                            tweet_vector  \n",
       "0      [0.049786884, 0.1913198, 0.068040654, -0.15670...  \n",
       "1      [0.09133990850442877, 0.25186495755154353, 0.1...  \n",
       "2      [0.11688901, 0.22027843, 0.10215302, -0.159173...  \n",
       "3      [0.12811066, 0.23626624, 0.11524634, -0.131818...  \n",
       "4      [0.07077107, 0.23463808, 0.07358122, -0.123566...  \n",
       "...                                                  ...  \n",
       "10680  [0.12749639, 0.23482081, 0.052804522, -0.06213...  \n",
       "10681  [0.13463659662257052, 0.23993844279640894, 0.0...  \n",
       "10682  [0.12705522455795054, 0.24554795088920525, 0.0...  \n",
       "10683  [0.121888824, 0.24418654, 0.042192977, -0.0525...  \n",
       "10684  [0.12975031620621433, 0.24148471927183437, 0.0...  \n",
       "\n",
       "[10685 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.loc[df[\"EventType\"] != 0, \"EventType\"] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tweet_vector'] = df['tweet_vector'].swifter.apply(lambda v: v / np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = (\n",
    "    df.groupby(['MatchID', 'PeriodID'])\n",
    "    .agg(\n",
    "        period_matrix=('tweet_vector', lambda x: np.stack(x.to_numpy())),  # Stack the mean vectors\n",
    "        mean_event_type=('EventType', 'mean')  # Compute the mean event type\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'period_matrix': 'tweet_vector', 'mean_event_type':'EventType'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "      <th>EventType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.04978688433766365, 0.1913197934627533, 0.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.09943458437919617, 0.1979677975177765, 0.1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.1325032, 0.21106924, 0.112774804, -0.15817...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.11102492362260818, 0.21936477720737457, 0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.1170713551396477, 0.20770213977042315, 0.1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>[[0.12381656467914581, 0.24038036167621613, 0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>15</td>\n",
       "      <td>166</td>\n",
       "      <td>[[0.13367936, 0.2413072, 0.04921915, -0.065234...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>[[0.12520525245914096, 0.23613955238201428, 0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>[[0.13684346, 0.24208261, 0.042130414, -0.0524...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>[[0.1274963915348053, 0.23482081294059753, 0.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID                                       tweet_vector  \\\n",
       "0           0         0  [[0.04978688433766365, 0.1913197934627533, 0.0...   \n",
       "1           0         1  [[0.09943458437919617, 0.1979677975177765, 0.1...   \n",
       "2           0         2  [[0.1325032, 0.21106924, 0.112774804, -0.15817...   \n",
       "3           0         3  [[0.11102492362260818, 0.21936477720737457, 0....   \n",
       "4           0         4  [[0.1170713551396477, 0.20770213977042315, 0.1...   \n",
       "...       ...       ...                                                ...   \n",
       "2132       15       165  [[0.12381656467914581, 0.24038036167621613, 0....   \n",
       "2133       15       166  [[0.13367936, 0.2413072, 0.04921915, -0.065234...   \n",
       "2134       15       167  [[0.12520525245914096, 0.23613955238201428, 0....   \n",
       "2135       15       168  [[0.13684346, 0.24208261, 0.042130414, -0.0524...   \n",
       "2136       15       169  [[0.1274963915348053, 0.23482081294059753, 0.0...   \n",
       "\n",
       "      EventType  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           1.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "2132        1.0  \n",
       "2133        1.0  \n",
       "2134        1.0  \n",
       "2135        1.0  \n",
       "2136        0.0  \n",
       "\n",
       "[2137 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0uLXd2pz1CQ"
   },
   "source": [
    "# Separate Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# train on of the first 13 of 16 matches (16*0.8=12.8~=13)\n",
    "# and the test data would be the last 3 matches. \n",
    "# Before submitting on Kaggle we should train on full dataset, so al 16 matches\n",
    "train_percentage = 0.8\n",
    "unique_match_ids = df['MatchID'].unique()\n",
    "print(unique_match_ids)\n",
    "num_matches_training = int(ceil(len(unique_match_ids)*train_percentage))\n",
    "print(num_matches_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "target_match_id = num_matches_training\n",
    "# target_match_id is first match id that will appear in test set\n",
    "# all matches from target_match_id and after will be in test test\n",
    "print(target_match_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df2 = df['MatchID'] == 15\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_index is first row with match id target_match_id\n",
    "# row_index is then the first row of the matches that will go to the test\n",
    "\n",
    "\n",
    "row_index = (df['MatchID'] == target_match_id).idxmax()\n",
    "#row_index = df[df['MatchID'] == target_match_id].first_valid_index()\n",
    "df_X_train = df[:row_index].copy()\n",
    "df_X_test = df[row_index:].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train = df_X_train['EventType']\n",
    "df_y_test = df_X_test['EventType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       0.0\n",
       "       ... \n",
       "1702    1.0\n",
       "1703    1.0\n",
       "1704    1.0\n",
       "1705    1.0\n",
       "1706    1.0\n",
       "Name: EventType, Length: 1707, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      0.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      1.0\n",
       "      ... \n",
       "425    1.0\n",
       "426    1.0\n",
       "427    1.0\n",
       "428    1.0\n",
       "429    0.0\n",
       "Name: EventType, Length: 430, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test.reset_index(drop=True, inplace=True)\n",
    "df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train.drop(['EventType'], axis=1, inplace=True)\n",
    "df_X_test.drop(['EventType'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.04978688433766365, 0.1913197934627533, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.09943458437919617, 0.1979677975177765, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.1325032, 0.21106924, 0.112774804, -0.15817...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.11102492362260818, 0.21936477720737457, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.1170713551396477, 0.20770213977042315, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>12</td>\n",
       "      <td>125</td>\n",
       "      <td>[[0.01331692, 0.21187948, 0.1284352, -0.189622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>[[0.016792007, 0.19603887, 0.12457686, -0.1841...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>[[0.008126191, 0.23228367, 0.10223757, -0.2090...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>[[0.009118693, 0.22613892, 0.106851995, -0.202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>[[0.014088696, 0.15124494, 0.15931292, -0.2486...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1707 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID                                       tweet_vector\n",
       "0           0         0  [[0.04978688433766365, 0.1913197934627533, 0.0...\n",
       "1           0         1  [[0.09943458437919617, 0.1979677975177765, 0.1...\n",
       "2           0         2  [[0.1325032, 0.21106924, 0.112774804, -0.15817...\n",
       "3           0         3  [[0.11102492362260818, 0.21936477720737457, 0....\n",
       "4           0         4  [[0.1170713551396477, 0.20770213977042315, 0.1...\n",
       "...       ...       ...                                                ...\n",
       "1702       12       125  [[0.01331692, 0.21187948, 0.1284352, -0.189622...\n",
       "1703       12       126  [[0.016792007, 0.19603887, 0.12457686, -0.1841...\n",
       "1704       12       127  [[0.008126191, 0.23228367, 0.10223757, -0.2090...\n",
       "1705       12       128  [[0.009118693, 0.22613892, 0.106851995, -0.202...\n",
       "1706       12       129  [[0.014088696, 0.15124494, 0.15931292, -0.2486...\n",
       "\n",
       "[1707 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.15184887, 0.2528863, -0.03571834, -0.08834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.16123801, 0.25753284, -0.015193953, -0.090...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.14436208, 0.25661135, -0.016834391, -0.091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.15383919, 0.21019702, 0.0036868062, -0.104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.1350092, 0.21672635, -0.012920625, -0.1162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>[[0.12381656467914581, 0.24038036167621613, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>15</td>\n",
       "      <td>166</td>\n",
       "      <td>[[0.13367936, 0.2413072, 0.04921915, -0.065234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>[[0.12520525245914096, 0.23613955238201428, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>[[0.13684346, 0.24208261, 0.042130414, -0.0524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>[[0.1274963915348053, 0.23482081294059753, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MatchID  PeriodID                                       tweet_vector\n",
       "0         13         0  [[0.15184887, 0.2528863, -0.03571834, -0.08834...\n",
       "1         13         1  [[0.16123801, 0.25753284, -0.015193953, -0.090...\n",
       "2         13         2  [[0.14436208, 0.25661135, -0.016834391, -0.091...\n",
       "3         13         3  [[0.15383919, 0.21019702, 0.0036868062, -0.104...\n",
       "4         13         4  [[0.1350092, 0.21672635, -0.012920625, -0.1162...\n",
       "..       ...       ...                                                ...\n",
       "425       15       165  [[0.12381656467914581, 0.24038036167621613, 0....\n",
       "426       15       166  [[0.13367936, 0.2413072, 0.04921915, -0.065234...\n",
       "427       15       167  [[0.12520525245914096, 0.23613955238201428, 0....\n",
       "428       15       168  [[0.13684346, 0.24208261, 0.042130414, -0.0524...\n",
       "429       15       169  [[0.1274963915348053, 0.23482081294059753, 0.0...\n",
       "\n",
       "[430 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test.reset_index(drop=True, inplace=True)\n",
    "df_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now df_X_train and df_X_test should have columns MatchID, PeriodID, tweet_vector. Tweet_vector is just 200 columns\n",
    "# df_y_train and df_y_test should have 1 column, EventType\n",
    "# the matchids are grouped together so all the rows of the same\n",
    "# match ids are grouped next to each other, and the periodID are ordered chronologically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working on my machine so I keep DF\n",
    "\n",
    "# now we have df_X_train, df_X_test, df_y_train, df_y_test\n",
    "# we no longer need df so we should free up the memory\n",
    "# del df  # remove reference to the original DataFrame\n",
    "# gc.collect()  # force garbage collection to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MatchID  PeriodID\n",
       "0         0       129\n",
       "1         1       129\n",
       "2         2       129\n",
       "3         3       179\n",
       "4         4        96\n",
       "5         5       129\n",
       "6         6       129\n",
       "7         7       129\n",
       "8         8       129\n",
       "9         9       129\n",
       "10       10       129\n",
       "11       11       129\n",
       "12       12       129"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X_train.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "max_periods\n",
    "# as we can see not every match has the same number of periods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MatchID  PeriodID\n",
       "0       13       129\n",
       "1       14       129\n",
       "2       15       169"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X_test.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "max_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data for PyTorch LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor for a PyTorch LSTM should have the shape of (when setting batch_first=True)\n",
    "# (batch_size, seq_len, num_features) when using the batch_first=True parameter\n",
    "# batch_size is number of sequences processed at once\n",
    "\n",
    "# TRY WITHOUT SLIDING WINDOW APPROACH\n",
    "#    which would mean batch size = number of matches\n",
    "#    much easier to format for LSTM as 3D tensor\n",
    "#    dimension of 3D tensor with batch_first=True:(batch_size = num_matches, seq_len = num_periods, num _features = 200)\n",
    "#    (match_id, period_id, num_features=200)\n",
    "#     not every match has the same number of periods!, so seq_len can vary between different matches\n",
    "#     fix: will have to pad with zeroes\n",
    "# we want tensor[match_id][period_id] to return list len 200 of corresponding tweet vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.04978688433766365, 0.1913197934627533, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.09943458437919617, 0.1979677975177765, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.1325032, 0.21106924, 0.112774804, -0.15817...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.11102492362260818, 0.21936477720737457, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.1170713551396477, 0.20770213977042315, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>12</td>\n",
       "      <td>125</td>\n",
       "      <td>[[0.01331692, 0.21187948, 0.1284352, -0.189622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>[[0.016792007, 0.19603887, 0.12457686, -0.1841...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>[[0.008126191, 0.23228367, 0.10223757, -0.2090...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>[[0.009118693, 0.22613892, 0.106851995, -0.202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>[[0.014088696, 0.15124494, 0.15931292, -0.2486...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1707 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID                                       tweet_vector\n",
       "0           0         0  [[0.04978688433766365, 0.1913197934627533, 0.0...\n",
       "1           0         1  [[0.09943458437919617, 0.1979677975177765, 0.1...\n",
       "2           0         2  [[0.1325032, 0.21106924, 0.112774804, -0.15817...\n",
       "3           0         3  [[0.11102492362260818, 0.21936477720737457, 0....\n",
       "4           0         4  [[0.1170713551396477, 0.20770213977042315, 0.1...\n",
       "...       ...       ...                                                ...\n",
       "1702       12       125  [[0.01331692, 0.21187948, 0.1284352, -0.189622...\n",
       "1703       12       126  [[0.016792007, 0.19603887, 0.12457686, -0.1841...\n",
       "1704       12       127  [[0.008126191, 0.23228367, 0.10223757, -0.2090...\n",
       "1705       12       128  [[0.009118693, 0.22613892, 0.106851995, -0.202...\n",
       "1706       12       129  [[0.014088696, 0.15124494, 0.15931292, -0.2486...\n",
       "\n",
       "[1707 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1707, 5, 200)\n",
      "(1707,)\n"
     ]
    }
   ],
   "source": [
    "# modified for array tweet_vector column\n",
    "def convert_df_to_3D_tensor(df_X, df_y):\n",
    "    # df_X should have columns MatchID, PeriodID, tweet_vector. Tweet_vector is just 200x1 array\n",
    "    # rows with same matchID should be grouped together (adjacent rows)\n",
    "    # df_y should have one column (the EventType)\n",
    "    # returns tensor_X numpy array already padded! shape: (num_matches, max_num_periods, num _features = 200)\n",
    "    # and tensor_y of shape: (num_matches, max_num_periods)\n",
    "    num_matches = len(df_X['MatchID'].unique())\n",
    "    max_periods = df_X.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "    total_max_period = max_periods['PeriodID'].max()\n",
    "    #total_max_period is max seq len\n",
    "\n",
    "    tensor_X = np.zeros((len(df_X), period_chunks, 200))\n",
    "\n",
    "    tensor_y = np.zeros((len(df_y,)))\n",
    "    print(tensor_X.shape)\n",
    "    print(tensor_y.shape)\n",
    "    \n",
    "    for row_index, row in df_X.iterrows():\n",
    "        i = row_index        \n",
    "        features = row['tweet_vector']  # Skip MatchID and PeriodID\n",
    "        tensor_X[i, :, :] = features\n",
    "        tensor_y[i] = df_y[row_index]\n",
    "        \n",
    "    return tensor_X, tensor_y\n",
    "\n",
    "\n",
    "X_train_tensor, y_train_tensor = convert_df_to_3D_tensor(df_X_train, df_y_train)\n",
    "# X_train_tensor[match_id][period_id] to return list len 200 of corresponding tweet vector\n",
    "# y_train_tensor[match_id][period_id] to return corresponding EventType (1 or 0)\n",
    "# match_id index starts at 0 even if first match in df doesnt have match id 0\n",
    "#X_train_tensor[12][175]\n",
    "#X_train_tensor[12][179]\n",
    "#X_train_tensor[2][129]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train_tensor[0][3])\n",
    "#print(y_train_tensor[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1707, 5, 200])\n",
      "torch.Size([1707])\n"
     ]
    }
   ],
   "source": [
    "# SCALE DATA? minmaxscaler for example!\n",
    "# SCALING MIGHT BE UNNECESSARY SINCE OUTPUT OF GLOVE TWEET 200 IS ALREADY SCALED BETWEEN -1 AND 1\n",
    "#scaler = MinMaxScaler()\n",
    "#tensor = scaler.fit_transform(tensor)\n",
    "\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_train_tensor = torch.tensor(X_train_tensor, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_tensor, dtype=torch.float32)\n",
    "\n",
    "print(X_train_tensor.shape)\n",
    "print(y_train_tensor.shape)\n",
    "# X_train_tensor, y_train_tensor are now pytorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO VERIFY ITS CORRECT + MAKE MORE SOPHISTICATED\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out)\n",
    "        out = out[:,-1,:]\n",
    "        out = self.sigmoid(out) # applying sigmoid to convert to probabilities\n",
    "        return out.squeeze(-1)\n",
    "\n",
    "#TODOOOOOOOOOO torch.nn.utils.rnn.pack_padded_sequence. This allows the model to ignore the padded values during computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "batch_size = 120\n",
    "hidden_size = 200 # can tune\n",
    "num_layers = 5 # can tune\n",
    "dropout_rate = 0.7 # can tune\n",
    "num_epochs = 800 # can tune\n",
    "lr = 0.0003 # can tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idxs = list(range(0,X_train_tensor.shape[0],batch_size))\n",
    "batched_data = []\n",
    "for idx in batch_idxs:\n",
    "    batched_data.append((X_train_tensor[idx:idx+batch_size], y_train_tensor[idx:idx+batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430, 5, 200)\n",
      "(430,)\n"
     ]
    }
   ],
   "source": [
    "# convert df_X_test and df_y_test to correct format/dimensions\n",
    "X_test_tensor, y_test_tensor = convert_df_to_3D_tensor(df_X_test, df_y_test)\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_test_tensor = torch.tensor(X_test_tensor, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/800], Loss: 0.6958 Eval Loss: 0.6933\n",
      "Epoch [10/800], Loss: 0.6496 Eval Loss: 0.7048\n",
      "Epoch [20/800], Loss: 0.6106 Eval Loss: 0.7197\n",
      "Epoch [30/800], Loss: 0.6249 Eval Loss: 0.7100\n",
      "Epoch [40/800], Loss: 0.5956 Eval Loss: 0.7157\n",
      "Epoch [50/800], Loss: 0.4969 Eval Loss: 0.6898\n",
      "Epoch [60/800], Loss: 0.5776 Eval Loss: 0.6450\n",
      "Epoch [70/800], Loss: 0.4781 Eval Loss: 0.6184\n",
      "Epoch [80/800], Loss: 0.4892 Eval Loss: 0.5887\n",
      "Epoch [90/800], Loss: 0.5078 Eval Loss: 0.5920\n",
      "Epoch [100/800], Loss: 0.5210 Eval Loss: 0.5897\n",
      "Epoch [110/800], Loss: 0.5327 Eval Loss: 0.5950\n",
      "Epoch [120/800], Loss: 0.5194 Eval Loss: 0.5972\n",
      "Epoch [130/800], Loss: 0.5329 Eval Loss: 0.5828\n",
      "Epoch [140/800], Loss: 0.5213 Eval Loss: 0.5883\n",
      "Epoch [150/800], Loss: 0.5238 Eval Loss: 0.5830\n",
      "Epoch [160/800], Loss: 0.4957 Eval Loss: 0.5758\n",
      "Epoch [170/800], Loss: 0.5104 Eval Loss: 0.5714\n",
      "Epoch [180/800], Loss: 0.5017 Eval Loss: 0.5589\n",
      "Epoch [190/800], Loss: 0.5052 Eval Loss: 0.5527\n",
      "Epoch [200/800], Loss: 0.5168 Eval Loss: 0.5461\n",
      "Epoch [210/800], Loss: 0.5053 Eval Loss: 0.5459\n",
      "Epoch [220/800], Loss: 0.5032 Eval Loss: 0.5501\n",
      "Epoch [230/800], Loss: 0.5195 Eval Loss: 0.5601\n",
      "Epoch [240/800], Loss: 0.5069 Eval Loss: 0.5551\n",
      "Epoch [250/800], Loss: 0.5267 Eval Loss: 0.5703\n",
      "Epoch [260/800], Loss: 0.5174 Eval Loss: 0.5782\n",
      "Epoch [270/800], Loss: 0.4877 Eval Loss: 0.5703\n",
      "Epoch [280/800], Loss: 0.5090 Eval Loss: 0.5736\n",
      "Epoch [290/800], Loss: 0.5180 Eval Loss: 0.5889\n",
      "Epoch [300/800], Loss: 0.5110 Eval Loss: 0.5822\n",
      "Epoch [310/800], Loss: 0.5151 Eval Loss: 0.5844\n",
      "Epoch [320/800], Loss: 0.4997 Eval Loss: 0.5907\n",
      "Epoch [330/800], Loss: 0.5045 Eval Loss: 0.5888\n",
      "Epoch [340/800], Loss: 0.5098 Eval Loss: 0.5990\n",
      "Epoch [350/800], Loss: 0.4930 Eval Loss: 0.6175\n",
      "Epoch [360/800], Loss: 0.5096 Eval Loss: 0.6077\n",
      "Epoch [370/800], Loss: 0.4958 Eval Loss: 0.6072\n",
      "Epoch [380/800], Loss: 0.5154 Eval Loss: 0.6021\n",
      "Epoch [390/800], Loss: 0.5010 Eval Loss: 0.6125\n",
      "Epoch [400/800], Loss: 0.4753 Eval Loss: 0.6180\n",
      "Epoch [410/800], Loss: 0.4997 Eval Loss: 0.6301\n",
      "Epoch [420/800], Loss: 0.5030 Eval Loss: 0.6019\n",
      "Epoch [430/800], Loss: 0.4901 Eval Loss: 0.6243\n",
      "Epoch [440/800], Loss: 0.4839 Eval Loss: 0.6380\n",
      "Epoch [450/800], Loss: 0.4966 Eval Loss: 0.6512\n",
      "Epoch [460/800], Loss: 0.4693 Eval Loss: 0.6393\n",
      "Epoch [470/800], Loss: 0.4693 Eval Loss: 0.6559\n",
      "Epoch [480/800], Loss: 0.4708 Eval Loss: 0.6671\n",
      "Epoch [490/800], Loss: 0.4829 Eval Loss: 0.6824\n",
      "Epoch [500/800], Loss: 0.4849 Eval Loss: 0.6830\n",
      "Epoch [510/800], Loss: 0.4676 Eval Loss: 0.6655\n",
      "Epoch [520/800], Loss: 0.4690 Eval Loss: 0.6876\n",
      "Epoch [530/800], Loss: 0.4672 Eval Loss: 0.6758\n",
      "Epoch [540/800], Loss: 0.4593 Eval Loss: 0.7068\n",
      "Epoch [550/800], Loss: 0.4535 Eval Loss: 0.7312\n",
      "Epoch [560/800], Loss: 0.4769 Eval Loss: 0.7385\n",
      "Epoch [570/800], Loss: 0.4326 Eval Loss: 0.7185\n",
      "Epoch [580/800], Loss: 0.4441 Eval Loss: 0.7497\n",
      "Epoch [590/800], Loss: 0.4319 Eval Loss: 0.7598\n",
      "Epoch [600/800], Loss: 0.4279 Eval Loss: 0.7634\n",
      "Epoch [610/800], Loss: 0.4099 Eval Loss: 0.7561\n",
      "Epoch [620/800], Loss: 0.4245 Eval Loss: 0.7984\n",
      "Epoch [630/800], Loss: 0.4083 Eval Loss: 0.7927\n",
      "Epoch [640/800], Loss: 0.4343 Eval Loss: 0.7911\n",
      "Epoch [650/800], Loss: 0.4105 Eval Loss: 0.8264\n",
      "Epoch [660/800], Loss: 0.4419 Eval Loss: 0.8507\n",
      "Epoch [670/800], Loss: 0.4159 Eval Loss: 0.8167\n",
      "Epoch [680/800], Loss: 0.4456 Eval Loss: 0.8640\n",
      "Epoch [690/800], Loss: 0.4220 Eval Loss: 0.8008\n",
      "Epoch [700/800], Loss: 0.4104 Eval Loss: 0.8182\n",
      "Epoch [710/800], Loss: 0.4210 Eval Loss: 0.8910\n",
      "Epoch [720/800], Loss: 0.4263 Eval Loss: 0.8905\n",
      "Epoch [730/800], Loss: 0.4380 Eval Loss: 0.8793\n",
      "Epoch [740/800], Loss: 0.3730 Eval Loss: 0.8751\n",
      "Epoch [750/800], Loss: 0.4370 Eval Loss: 0.8671\n",
      "Epoch [760/800], Loss: 0.4554 Eval Loss: 0.8269\n",
      "Epoch [770/800], Loss: 0.3786 Eval Loss: 0.8860\n",
      "Epoch [780/800], Loss: 0.4191 Eval Loss: 0.9086\n",
      "Epoch [790/800], Loss: 0.4147 Eval Loss: 0.8730\n",
      "Model is trained! (on training data)\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_size=200, hidden_size=hidden_size, num_layers=num_layers, dropout_rate=dropout_rate)\n",
    "model = model.to(gpu)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss() # great for binary classification\n",
    "criterion = criterion.to(gpu)\n",
    "#print(f\"Shape of X_train_tensor: {X_train_tensor.shape}\")\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    for train, label in batched_data:\n",
    "        train = train.to(gpu)\n",
    "        label = label.to(gpu)\n",
    "        outputs = model(train)\n",
    "        #print(f\"shape of outputs: {outputs.shape}\")\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        predict = model(X_test_tensor.to(gpu))\n",
    "        e_loss = criterion(predict, y_test_tensor.to(gpu))\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\", f\"Eval Loss: {e_loss.item():.4f}\")\n",
    "\n",
    "print(\"Model is trained! (on training data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test_tensor[2][129])\n",
    "#print(y_test_tensor[2][129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(gpu)).to('cpu')\n",
    "\n",
    "# predictions have values between 0 and 1 because forward pass of LSTM contains sigmoid at output\n",
    "#print(predictions)\n",
    "\n",
    "predicted_classes = (predictions > 0.5).float() # 0.5 is threshold\n",
    "#this converts to same dimensional array of True or false, and .float() converts True to 1 and False to 0\n",
    "\n",
    "#print(predicted_classes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross-Entropy Loss: 0.8959\n",
      "Accuracy: 69.0698\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "\n",
    "loss = criterion(predictions, y_test_tensor) # use predictions for loss calculation\n",
    "\n",
    "print(f\"Binary Cross-Entropy Loss: {loss.item():.4f}\")\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    if y_true.dtype != y_pred.dtype or y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Inputs do not have same type or shape!\")\n",
    "    y_rand = torch.randint(0,2,y_true.shape)\n",
    "    correct_predictions = (y_true == y_pred).sum().item()\n",
    "    total_predictions = y_true.numel()\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    return accuracy\n",
    "accuracy = accuracy(y_test_tensor, predicted_classes)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "#print(y_test_tensor.shape)\n",
    "#print(predicted_classes.shape)\n",
    "\n",
    "\n",
    "# Visualization of Actual vs Predicted Classes\n",
    "# import matplotlib.pyplot as plt\n",
    "# TODO COULD USE PLT TO VISUALIZE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRAIN MODEL ON ENTIRE TRAINING DATA AND EVALUATE EVAL TWEETS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_X = pd.concat([df_X_train, df_X_test], ignore_index=True)\n",
    "df_y = pd.concat([df_y_train, df_y_test], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.04978688433766365, 0.1913197934627533, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.09943458437919617, 0.1979677975177765, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.1325032, 0.21106924, 0.112774804, -0.15817...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.11102492362260818, 0.21936477720737457, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.1170713551396477, 0.20770213977042315, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>[[0.12381656467914581, 0.24038036167621613, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>15</td>\n",
       "      <td>166</td>\n",
       "      <td>[[0.13367936, 0.2413072, 0.04921915, -0.065234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>[[0.12520525245914096, 0.23613955238201428, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>[[0.13684346, 0.24208261, 0.042130414, -0.0524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>[[0.1274963915348053, 0.23482081294059753, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID                                       tweet_vector\n",
       "0           0         0  [[0.04978688433766365, 0.1913197934627533, 0.0...\n",
       "1           0         1  [[0.09943458437919617, 0.1979677975177765, 0.1...\n",
       "2           0         2  [[0.1325032, 0.21106924, 0.112774804, -0.15817...\n",
       "3           0         3  [[0.11102492362260818, 0.21936477720737457, 0....\n",
       "4           0         4  [[0.1170713551396477, 0.20770213977042315, 0.1...\n",
       "...       ...       ...                                                ...\n",
       "2132       15       165  [[0.12381656467914581, 0.24038036167621613, 0....\n",
       "2133       15       166  [[0.13367936, 0.2413072, 0.04921915, -0.065234...\n",
       "2134       15       167  [[0.12520525245914096, 0.23613955238201428, 0....\n",
       "2135       15       168  [[0.13684346, 0.24208261, 0.042130414, -0.0524...\n",
       "2136       15       169  [[0.1274963915348053, 0.23482081294059753, 0.0...\n",
       "\n",
       "[2137 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       0.0\n",
       "       ... \n",
       "2132    1.0\n",
       "2133    1.0\n",
       "2134    1.0\n",
       "2135    1.0\n",
       "2136    0.0\n",
       "Name: EventType, Length: 2137, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2137, 5, 200)\n",
      "(2137,)\n"
     ]
    }
   ],
   "source": [
    "# convert df_X_test and df_y_test to correct format/dimensions\n",
    "X_tensor, y_tensor = convert_df_to_3D_tensor(df_X, df_y)\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_tensor = torch.tensor(X_tensor, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "et9Eb8hEz1aC"
   },
   "outputs": [],
   "source": [
    "# NOTES\n",
    "# HOW TO MAKE SURE THAT we:\n",
    "# 1. DO NOT ignore the order of the tweets -> (LSTM)\n",
    "# 2. treat each time period as RELATED to the football match they belong to -> treat each match as a sequence, train LSTM on every sequence\n",
    "#                      since pytorch tensor expects multiple sequences (batches)\n",
    "\n",
    "\n",
    "\n",
    "# for LSTM: Each input sequence should consist of tweets from a specific match, ordered by Period ID.\n",
    "#   tweets of different matches are unrelated, but tweets of a same match are related sequentially (chronologically)\n",
    "#   structure training data such that tweets are grouped by match id, and ordered by period id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batch_idxs = list(range(0,X_tensor.shape[0],batch_size))\n",
    "batched_data = []\n",
    "for idx in batch_idxs:\n",
    "    batched_data.append((X_tensor[idx:idx+batch_size], y_tensor[idx:idx+batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/800], Loss: 0.6926\n",
      "Epoch [10/800], Loss: 0.6953\n",
      "Epoch [20/800], Loss: 0.6938\n",
      "Epoch [30/800], Loss: 0.6939\n",
      "Epoch [40/800], Loss: 0.6910\n",
      "Epoch [50/800], Loss: 0.6579\n",
      "Epoch [60/800], Loss: 0.5723\n",
      "Epoch [70/800], Loss: 0.5512\n",
      "Epoch [80/800], Loss: 0.4963\n",
      "Epoch [90/800], Loss: 0.5642\n",
      "Epoch [100/800], Loss: 0.5415\n",
      "Epoch [110/800], Loss: 0.5118\n",
      "Epoch [120/800], Loss: 0.4900\n",
      "Epoch [130/800], Loss: 0.4821\n",
      "Epoch [140/800], Loss: 0.5063\n",
      "Epoch [150/800], Loss: 0.4592\n",
      "Epoch [160/800], Loss: 0.4293\n",
      "Epoch [170/800], Loss: 0.4218\n",
      "Epoch [180/800], Loss: 0.4180\n",
      "Epoch [190/800], Loss: 0.4221\n",
      "Epoch [200/800], Loss: 0.4091\n",
      "Epoch [210/800], Loss: 0.3991\n",
      "Epoch [220/800], Loss: 0.4051\n",
      "Epoch [230/800], Loss: 0.4090\n",
      "Epoch [240/800], Loss: 0.3748\n",
      "Epoch [250/800], Loss: 0.3957\n",
      "Epoch [260/800], Loss: 0.3426\n",
      "Epoch [270/800], Loss: 0.3694\n",
      "Epoch [280/800], Loss: 0.3466\n",
      "Epoch [290/800], Loss: 0.3577\n",
      "Epoch [300/800], Loss: 0.3730\n",
      "Epoch [310/800], Loss: 0.3326\n",
      "Epoch [320/800], Loss: 0.3313\n",
      "Epoch [330/800], Loss: 0.3736\n",
      "Epoch [340/800], Loss: 0.3438\n",
      "Epoch [350/800], Loss: 0.3438\n",
      "Epoch [360/800], Loss: 0.3601\n",
      "Epoch [370/800], Loss: 0.3570\n",
      "Epoch [380/800], Loss: 0.3748\n",
      "Epoch [390/800], Loss: 0.3651\n",
      "Epoch [400/800], Loss: 0.3522\n",
      "Epoch [410/800], Loss: 0.3412\n",
      "Epoch [420/800], Loss: 0.3647\n",
      "Epoch [430/800], Loss: 0.3439\n",
      "Epoch [440/800], Loss: 0.3503\n",
      "Epoch [450/800], Loss: 0.3482\n",
      "Epoch [460/800], Loss: 0.3587\n",
      "Epoch [470/800], Loss: 0.3576\n",
      "Epoch [480/800], Loss: 0.3327\n",
      "Epoch [490/800], Loss: 0.3198\n",
      "Epoch [500/800], Loss: 0.3656\n",
      "Epoch [510/800], Loss: 0.3180\n",
      "Epoch [520/800], Loss: 0.3435\n",
      "Epoch [530/800], Loss: 0.3535\n",
      "Epoch [540/800], Loss: 0.3287\n",
      "Epoch [550/800], Loss: 0.3489\n",
      "Epoch [560/800], Loss: 0.3443\n",
      "Epoch [570/800], Loss: 0.3716\n",
      "Epoch [580/800], Loss: 0.3664\n",
      "Epoch [590/800], Loss: 0.3457\n",
      "Epoch [600/800], Loss: 0.3655\n",
      "Epoch [610/800], Loss: 0.3335\n",
      "Epoch [620/800], Loss: 0.3689\n",
      "Epoch [630/800], Loss: 0.3249\n",
      "Epoch [640/800], Loss: 0.3459\n",
      "Epoch [650/800], Loss: 0.2997\n",
      "Epoch [660/800], Loss: 0.3408\n",
      "Epoch [670/800], Loss: 0.3649\n",
      "Epoch [680/800], Loss: 0.3145\n",
      "Epoch [690/800], Loss: 0.3544\n",
      "Epoch [700/800], Loss: 0.3406\n",
      "Epoch [710/800], Loss: 0.3165\n",
      "Epoch [720/800], Loss: 0.3788\n",
      "Epoch [730/800], Loss: 0.3752\n",
      "Epoch [740/800], Loss: 0.3109\n",
      "Epoch [750/800], Loss: 0.3598\n",
      "Epoch [760/800], Loss: 0.3243\n",
      "Epoch [770/800], Loss: 0.3637\n",
      "Epoch [780/800], Loss: 0.3620\n",
      "Epoch [790/800], Loss: 0.3647\n",
      "Model is trained! (on training data)\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_size=200, hidden_size=hidden_size, num_layers=num_layers, dropout_rate=dropout_rate)\n",
    "model = model.to(gpu)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss() # great for binary classification\n",
    "criterion = criterion.to(gpu)\n",
    "#print(f\"Shape of X_train_tensor: {X_train_tensor.shape}\")\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    for train, label in batched_data:\n",
    "        train = train.to(gpu)\n",
    "        label = label.to(gpu)\n",
    "        outputs = model(train)\n",
    "        #print(f\"shape of outputs: {outputs.shape}\")\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Model is trained! (on training data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreeceIvoryCoast44.csv\n",
      "NetherlandsMexico64.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GermanyGhana32.csv\n",
      "GermanySerbia2010.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>Wana place a bet on an ivory coast win but ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>#WatchLive @FIFAWorldCup: Greece vs. Ivory Coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>Gonna watch the Colombia and Japan game becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>#CIV vs #COL &amp; #GRE vs #JPN! It would be inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>RT @DuncanCastles: Quite a statistic this: Gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072923</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>LETS GO #USA #worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072924</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>another upset in #WC2010 #Srb beat #Ger by 1-0 !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072925</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>RT @FIFAcom: #GER 0:1 #SRB: TheÂ finalÂ whistl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072926</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>dukung yg menang -_- RT @AlikaZahira: #bra #fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072927</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>Serbia win?wow...unexpected,hm? #worldcup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072928 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  MatchID  PeriodID      Timestamp  \\\n",
       "0           9_0        9         0  1403639400000   \n",
       "1           9_0        9         0  1403639400000   \n",
       "2           9_0        9         0  1403639400000   \n",
       "3           9_0        9         0  1403639400000   \n",
       "4           9_0        9         0  1403639400000   \n",
       "...         ...      ...       ...            ...   \n",
       "1072923  16_129       16       129  1276867800000   \n",
       "1072924  16_129       16       129  1276867800000   \n",
       "1072925  16_129       16       129  1276867800000   \n",
       "1072926  16_129       16       129  1276867800000   \n",
       "1072927  16_129       16       129  1276867800000   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        Wana place a bet on an ivory coast win but ain...  \n",
       "1        #WatchLive @FIFAWorldCup: Greece vs. Ivory Coa...  \n",
       "2        Gonna watch the Colombia and Japan game becaus...  \n",
       "3        #CIV vs #COL & #GRE vs #JPN! It would be inter...  \n",
       "4        RT @DuncanCastles: Quite a statistic this: Gre...  \n",
       "...                                                    ...  \n",
       "1072923                             LETS GO #USA #worldcup  \n",
       "1072924  another upset in #WC2010 #Srb beat #Ger by 1-0 !!  \n",
       "1072925  RT @FIFAcom: #GER 0:1 #SRB: TheÂ finalÂ whistl...  \n",
       "1072926  dukung yg menang -_- RT @AlikaZahira: #bra #fr...  \n",
       "1072927          Serbia win?wow...unexpected,hm? #worldcup  \n",
       "\n",
       "[1072928 rows x 5 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all training files and concatenate them into one dataframe\n",
    "\n",
    "#import os\n",
    "#print(os.getcwd())\n",
    "\n",
    "li = []\n",
    "i = 0\n",
    "for filename in listdir(\"eval_tweets\"):\n",
    "    if filename != '.ipynb_checkpoints':\n",
    "        print(filename)\n",
    "        df = pd.read_csv(\"eval_tweets/\" + filename)\n",
    "        # df.drop(columns=['Timestamp'], inplace=True)\n",
    "        # drop unused column(s)\n",
    "        # makes sure that the match IDs are ordered from 0,1,2... with no missing values\n",
    "        i+=1\n",
    "        li.append(df)\n",
    "eval_df = pd.concat(li, ignore_index=True)\n",
    "#print(len(df))\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1072928/1072928 [00:37<00:00, 28824.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>wana place bet ivory coast win aint sure sugge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>watchlive fifaworldcup greece v ivory coast ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>gonna watch colombia japan game watching ivory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>civ v col gre v jpn would interesting greece w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>rt duncancastles quite statistic greece never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072923</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>let go usa worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072924</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>another upset wc srb beat ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072925</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>rt fifacom ger srb final whistle sound httpbit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072926</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>dukung yg menang rt alikazahira bra fra arg wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072927</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>serbia winwowunexpectedhm worldcup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072928 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  MatchID  PeriodID      Timestamp  \\\n",
       "0           9_0        9         0  1403639400000   \n",
       "1           9_0        9         0  1403639400000   \n",
       "2           9_0        9         0  1403639400000   \n",
       "3           9_0        9         0  1403639400000   \n",
       "4           9_0        9         0  1403639400000   \n",
       "...         ...      ...       ...            ...   \n",
       "1072923  16_129       16       129  1276867800000   \n",
       "1072924  16_129       16       129  1276867800000   \n",
       "1072925  16_129       16       129  1276867800000   \n",
       "1072926  16_129       16       129  1276867800000   \n",
       "1072927  16_129       16       129  1276867800000   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        wana place bet ivory coast win aint sure sugge...  \n",
       "1        watchlive fifaworldcup greece v ivory coast ta...  \n",
       "2        gonna watch colombia japan game watching ivory...  \n",
       "3        civ v col gre v jpn would interesting greece w...  \n",
       "4        rt duncancastles quite statistic greece never ...  \n",
       "...                                                    ...  \n",
       "1072923                                let go usa worldcup  \n",
       "1072924                      another upset wc srb beat ger  \n",
       "1072925  rt fifacom ger srb final whistle sound httpbit...  \n",
       "1072926  dukung yg menang rt alikazahira bra fra arg wo...  \n",
       "1072927                 serbia winwowunexpectedhm worldcup  \n",
       "\n",
       "[1072928 rows x 5 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to each tweet\n",
    "eval_df['Tweet'] = eval_df['Tweet'].swifter.apply(preprocess_text)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1072928/1072928 [00:30<00:00, 35129.03it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_df[\"tweet_vector\"] = eval_df[\"Tweet\"].swifter.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2726494/3165773019.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  eval_df['chunk'] = eval_df.groupby(['MatchID', 'PeriodID']).apply(\n"
     ]
    }
   ],
   "source": [
    "# Sort by MatchID, PeriodID, and Timestamp to maintain order\n",
    "eval_df = eval_df.sort_values(by=['MatchID', 'PeriodID', 'Timestamp']).reset_index(drop=True)\n",
    "\n",
    "# Helper function to assign chunks\n",
    "def assign_chunks(group, n_chunks=10):\n",
    "    chunk_size = len(group) / n_chunks\n",
    "    return (np.floor(np.arange(len(group)) / chunk_size)).astype(int)\n",
    "\n",
    "# Apply chunk assignment within each MatchID and PeriodID\n",
    "eval_df['chunk'] = eval_df.groupby(['MatchID', 'PeriodID']).apply(\n",
    "    lambda group: assign_chunks(group)\n",
    ").explode().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.drop(columns=['Tweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the tweets into their corresponding periods to generate an average embedding vector for each period\n",
    "# so there are no duplicate period id rows per match\n",
    "# decreases size of data + makes it easier to fit into LSTM model\n",
    "eval_df = eval_df.groupby(['MatchID', 'PeriodID', 'ID','chunk']).mean().reset_index()\n",
    "eval_df.drop(columns=['ID'], inplace=True) \n",
    "eval_df['MatchID'] = eval_df['MatchID'].astype(int)\n",
    "eval_df['PeriodID'] = eval_df['PeriodID'].astype(int)\n",
    "# need to convert to int before sorting\n",
    "eval_df.sort_values(by=['MatchID', 'PeriodID', 'chunk'], inplace=True)\n",
    "eval_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_agg = (\n",
    "    eval_df.groupby(['MatchID', 'PeriodID'])\n",
    "    .agg(\n",
    "        period_matrix=('tweet_vector', lambda x: np.stack(x.to_numpy())),  # Stack the mean vectors\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.rename(columns={'period_matrix': 'tweet_vector'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.16653539, 0.26003703, 0.059985828, -0.0924...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.15020987, 0.2654425, 0.05469284, -0.114660...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.16435114, 0.27378768, 0.05723621, -0.10151...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.17175293896567598, 0.27191852900369834, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.15491624, 0.28381658, 0.058633655, -0.0947...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>16</td>\n",
       "      <td>125</td>\n",
       "      <td>[[0.09658312052488327, 0.2646336853504181, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>16</td>\n",
       "      <td>126</td>\n",
       "      <td>[[0.07132586327974091, 0.2369798426262357, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>16</td>\n",
       "      <td>127</td>\n",
       "      <td>[[0.08168929815292358, 0.2357352077960968, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>[[0.13000393, 0.25957957, 0.109353416, -0.1556...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>[[0.09243842, 0.21740317, 0.14894113, -0.09702...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MatchID  PeriodID                                       tweet_vector\n",
       "0          6         0  [[0.16653539, 0.26003703, 0.059985828, -0.0924...\n",
       "1          6         1  [[0.15020987, 0.2654425, 0.05469284, -0.114660...\n",
       "2          6         2  [[0.16435114, 0.27378768, 0.05723621, -0.10151...\n",
       "3          6         3  [[0.17175293896567598, 0.27191852900369834, 0....\n",
       "4          6         4  [[0.15491624, 0.28381658, 0.058633655, -0.0947...\n",
       "..       ...       ...                                                ...\n",
       "511       16       125  [[0.09658312052488327, 0.2646336853504181, 0.1...\n",
       "512       16       126  [[0.07132586327974091, 0.2369798426262357, 0.0...\n",
       "513       16       127  [[0.08168929815292358, 0.2357352077960968, 0.1...\n",
       "514       16       128  [[0.13000393, 0.25957957, 0.109353416, -0.1556...\n",
       "515       16       129  [[0.09243842, 0.21740317, 0.14894113, -0.09702...\n",
       "\n",
       "[516 rows x 3 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_X = np.zeros((len(eval_df), 10, 200))\n",
    "\n",
    "for row_index, row in eval_df.iterrows():\n",
    "    i = row_index        \n",
    "    features = row['tweet_vector']  # Skip MatchID and PeriodID\n",
    "    eval_X[i, :, :] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_X = torch.tensor(eval_X, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "eval_predictions = model(eval_X.to(gpu)).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_predicted_classes = (eval_predictions > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "eval_df['ID'] = eval_df.apply(lambda row: str(row.MatchID) + '_' + str(row.PeriodID), axis=1)\n",
    "eval_df['EventType'] = [float(x) for x in eval_predicted_classes]\n",
    "prediction_df = eval_df[['ID','EventType']]\n",
    "\n",
    "\n",
    "submission_filename = \"submissions/Submission \" + datetime.datetime.now().strftime(\"%d%m-%H%M%S\") + \".csv\"\n",
    "prediction_df.to_csv(submission_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
