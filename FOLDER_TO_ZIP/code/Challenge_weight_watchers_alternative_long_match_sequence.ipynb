{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "WWrRFeKRX-DI",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import libraries and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDtRGZMPNrAM",
    "outputId": "ffc1fd2b-0bac-4a28-e9dd-de135042cc38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/infres/kbrowder-24/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/infres/kbrowder-24/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gc\n",
    "import gensim.downloader as api\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from math import ceil\n",
    "import torch.optim as optim\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load GloVe model with Gensim's API - Twitter specific embedding\n",
    "embeddings_model = api.load(\"glove-twitter-200\")  # 200-dimensional GloVe embeddings\n",
    "\n",
    "#To check that T4 GPU is connected\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"modin[all]\"\n",
    "# import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install swifter\n",
    "# import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/kbrowder-24/DeepLearningChallengeCSC_51054_EP/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Options: \"ray\" or \"dask\"\n",
    "# import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swifter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csoDmI8_X2OO"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "5SVFWTlQX0Jy",
    "outputId": "137b7b7f-e522-433b-9a21-04250b9125db"
   },
   "outputs": [],
   "source": [
    "# Read all training files and concatenate them into one dataframe\n",
    "\n",
    "#import os\n",
    "#print(os.getcwd())\n",
    "def make_dataset_df(dir_name):\n",
    "    li = []\n",
    "    i = 0\n",
    "    for filename in listdir(dir_name):\n",
    "        if filename != '.ipynb_checkpoints':\n",
    "            print(filename)\n",
    "            df = pd.read_csv(dir_name + \"/\" + filename)\n",
    "            # df.drop(columns=['Timestamp'], inplace=True)\n",
    "            # drop unused column(s)\n",
    "            df['MatchID'] = str(i)\n",
    "            df['ID'] = str(i)+ '_' + df['PeriodID'].astype(str)\n",
    "            # makes sure that the match IDs are ordered from 0,1,2... with no missing values\n",
    "            i+=1\n",
    "            li.append(df)\n",
    "    df = pd.concat(li, ignore_index=True)\n",
    "    del li\n",
    "    gc.collect()\n",
    "    #print(len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USASlovenia2010.csv\n",
      "ArgentinaBelgium72.csv\n",
      "AustraliaSpain34.csv\n",
      "ArgentinaGermanyFinal77.csv\n",
      "AustraliaNetherlands29.csv\n",
      "BelgiumSouthKorea59.csv\n",
      "HondurasSwitzerland54.csv\n",
      "FranceGermany70.csv\n",
      "GermanyBrazil74.csv\n",
      "GermanyUSA57.csv\n",
      "MexicoCroatia37.csv\n",
      "FranceNigeria66.csv\n",
      "CameroonBrazil36.csv\n",
      "NetherlandsChile35.csv\n",
      "PortugalGhana58.csv\n",
      "GermanyAlgeria67.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>#USA All My Stateside Followers Stand Up And R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>@Lynz_89 I think the ref might have been Basil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>Hoping a #USA win can help ease the pain of la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>When does this actually start?  #worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>Hanson and Roy are a proper pundit line up. #w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>RT @FOXSoccer: 3/4 of the #WorldCup quarterfin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>RT @Rodolph_hilal: Plz guys RETWEET .. \\n\\nLet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>RT @Joey7Barton: Algeria can take a lot of pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>RT @caughtoffside: #ALG gave it their all, was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>So be it...  #FRA #GER in 1/4 finals ^_^ #worl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID MatchID  PeriodID  EventType      Timestamp  \\\n",
       "0           0_0       0         0          0  1276869000000   \n",
       "1           0_0       0         0          0  1276869000000   \n",
       "2           0_0       0         0          0  1276869000000   \n",
       "3           0_0       0         0          0  1276869000000   \n",
       "4           0_0       0         0          0  1276869000000   \n",
       "...         ...     ...       ...        ...            ...   \n",
       "5056045  15_169      15       169          0  1404168000000   \n",
       "5056046  15_169      15       169          0  1404168000000   \n",
       "5056047  15_169      15       169          0  1404168000000   \n",
       "5056048  15_169      15       169          0  1404168000000   \n",
       "5056049  15_169      15       169          0  1404168000000   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        #USA All My Stateside Followers Stand Up And R...  \n",
       "1        @Lynz_89 I think the ref might have been Basil...  \n",
       "2        Hoping a #USA win can help ease the pain of la...  \n",
       "3                When does this actually start?  #worldcup  \n",
       "4        Hanson and Roy are a proper pundit line up. #w...  \n",
       "...                                                    ...  \n",
       "5056045  RT @FOXSoccer: 3/4 of the #WorldCup quarterfin...  \n",
       "5056046  RT @Rodolph_hilal: Plz guys RETWEET .. \\n\\nLet...  \n",
       "5056047  RT @Joey7Barton: Algeria can take a lot of pos...  \n",
       "5056048  RT @caughtoffside: #ALG gave it their all, was...  \n",
       "5056049  So be it...  #FRA #GER in 1/4 finals ^_^ #worl...  \n",
       "\n",
       "[5056050 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_dataset_df(\"train_tweets\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_series(ser:pd.Series):\n",
    "    # Preprocessing of tweet\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    def preprocess_text(text):\n",
    "        # Lowercasing\n",
    "        text = text.lower()\n",
    "        # Remove non letter and whitespace\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "        # Remove numbers\n",
    "        # text = re.sub(r'\\d+', '', text)\n",
    "        # Tokenization\n",
    "        words = text.split()\n",
    "        # Remove stopwords and lemmatize\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "        # Lemmatization\n",
    "        # words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        return ' '.join(words)\n",
    "    return ser.swifter.apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pCBsffiAbRM0",
    "outputId": "38b4c93f-5af9-444c-c2fa-19a31b586353"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 5056050/5056050 [02:55<00:00, 28769.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to each tweet\n",
    "df['Tweet'] = preprocess_series(df['Tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YW4PGmMxrF4r"
   },
   "source": [
    "# Tweet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_avg_embeddings(ser: pd.Series, vector_size = 200):\n",
    "    # Get vector tweet embeddings\n",
    "    # TODOOOOOOOOOOOOOOOO maybe instead of avg word embedding for each tweet can get sentence\n",
    "    #   embeddings to retain more information\n",
    "    #   -> can try more complex functions here\n",
    "    #   -> avg embedding of each word for a tweet is fine for now, maybe works well enough\n",
    "\n",
    "    # Function to compute the average word vector for a tweet\n",
    "    def get_avg_embedding(tweet, model):\n",
    "        words = tweet.split()  # Tokenize by whitespace\n",
    "        word_vectors = [model[word] for word in words if word in model]\n",
    "        if not word_vectors:  # If no words in the tweet are in the vocabulary, return a zero vector\n",
    "            return np.zeros(vector_size)\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    \n",
    "    from functools import partial\n",
    "\n",
    "    f = partial(get_avg_embedding, model=embeddings_model)\n",
    "    f.__name__ = \"paritla\"\n",
    "    f.__module__ = get_avg_embedding.__module__\n",
    "\n",
    "    return ser.swifter.apply(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 5056050/5056050 [02:26<00:00, 34625.78it/s]\n"
     ]
    }
   ],
   "source": [
    "df['tweet_vector'] = gen_avg_embeddings(df['Tweet'], vector_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>usa stateside follower stand represent beautif...</td>\n",
       "      <td>[0.066179484, 0.25621355, 0.08082778, -0.33907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>lynz think ref might basil fawlty actually wor...</td>\n",
       "      <td>[-0.1474687, 0.3667189, 0.10468656, 0.049433, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>hoping usa win help ease pain last night loss ...</td>\n",
       "      <td>[0.22338197, 0.27252772, 0.07159816, -0.293135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>actually start worldcup</td>\n",
       "      <td>[-0.10895123, 0.28830335, 0.40979335, -0.22218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1276869000000</td>\n",
       "      <td>hanson roy proper pundit line worldcup</td>\n",
       "      <td>[-0.112306446, 0.11411217, 0.24610366, -0.4545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056045</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>rt foxsoccer worldcup quarterfinal set ger v f...</td>\n",
       "      <td>[0.13047262, 0.2851209, 0.018671205, -0.052115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056046</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>rt rodolphhilal plz guy retweet let trend alg ...</td>\n",
       "      <td>[0.30743918, 0.36894467, -0.1729, -0.27685714,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056047</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>rt joeybarton algeria take lot positive big bi...</td>\n",
       "      <td>[0.14770256, 0.20187803, -0.1268579, -0.095563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056048</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>rt caughtoffside alg gave wasnt enough heart t...</td>\n",
       "      <td>[0.016947214, 0.28408444, 0.08043686, 0.101969...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056049</th>\n",
       "      <td>15_169</td>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1404168000000</td>\n",
       "      <td>fra ger final worldcup mmfutis</td>\n",
       "      <td>[0.15036534, 0.3681025, 0.21266, -0.239125, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5056050 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID MatchID  PeriodID  EventType      Timestamp  \\\n",
       "0           0_0       0         0          0  1276869000000   \n",
       "1           0_0       0         0          0  1276869000000   \n",
       "2           0_0       0         0          0  1276869000000   \n",
       "3           0_0       0         0          0  1276869000000   \n",
       "4           0_0       0         0          0  1276869000000   \n",
       "...         ...     ...       ...        ...            ...   \n",
       "5056045  15_169      15       169          0  1404168000000   \n",
       "5056046  15_169      15       169          0  1404168000000   \n",
       "5056047  15_169      15       169          0  1404168000000   \n",
       "5056048  15_169      15       169          0  1404168000000   \n",
       "5056049  15_169      15       169          0  1404168000000   \n",
       "\n",
       "                                                     Tweet  \\\n",
       "0        usa stateside follower stand represent beautif...   \n",
       "1        lynz think ref might basil fawlty actually wor...   \n",
       "2        hoping usa win help ease pain last night loss ...   \n",
       "3                                  actually start worldcup   \n",
       "4                   hanson roy proper pundit line worldcup   \n",
       "...                                                    ...   \n",
       "5056045  rt foxsoccer worldcup quarterfinal set ger v f...   \n",
       "5056046  rt rodolphhilal plz guy retweet let trend alg ...   \n",
       "5056047  rt joeybarton algeria take lot positive big bi...   \n",
       "5056048  rt caughtoffside alg gave wasnt enough heart t...   \n",
       "5056049                     fra ger final worldcup mmfutis   \n",
       "\n",
       "                                              tweet_vector  \n",
       "0        [0.066179484, 0.25621355, 0.08082778, -0.33907...  \n",
       "1        [-0.1474687, 0.3667189, 0.10468656, 0.049433, ...  \n",
       "2        [0.22338197, 0.27252772, 0.07159816, -0.293135...  \n",
       "3        [-0.10895123, 0.28830335, 0.40979335, -0.22218...  \n",
       "4        [-0.112306446, 0.11411217, 0.24610366, -0.4545...  \n",
       "...                                                    ...  \n",
       "5056045  [0.13047262, 0.2851209, 0.018671205, -0.052115...  \n",
       "5056046  [0.30743918, 0.36894467, -0.1729, -0.27685714,...  \n",
       "5056047  [0.14770256, 0.20187803, -0.1268579, -0.095563...  \n",
       "5056048  [0.016947214, 0.28408444, 0.08043686, 0.101969...  \n",
       "5056049  [0.15036534, 0.3681025, 0.21266, -0.239125, 0....  \n",
       "\n",
       "[5056050 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by now should have df with columns: ID, match id, period id, Event Type, tweet_vector. Tweet_vector is just 200 columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_chunks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1281451/1731830507.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['chunk'] = df.groupby(['MatchID', 'PeriodID']).apply(\n"
     ]
    }
   ],
   "source": [
    "# Sort by MatchID, PeriodID, and Timestamp to maintain order\n",
    "df = df.sort_values(by=['MatchID', 'PeriodID', 'Timestamp']).reset_index(drop=True)\n",
    "\n",
    "# Helper function to assign chunks\n",
    "def assign_chunks(group, n_chunks=period_chunks):\n",
    "    chunk_size = len(group) / n_chunks\n",
    "    return (np.floor(np.arange(len(group)) / chunk_size)).astype(int)\n",
    "\n",
    "# Apply chunk assignment within each MatchID and PeriodID\n",
    "df['chunk'] = df.groupby(['MatchID', 'PeriodID']).apply(\n",
    "    lambda group: assign_chunks(group)\n",
    ").explode().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the tweets into their corresponding periods to generate an average embedding vector for each period\n",
    "# so there are no duplicate period id rows per match\n",
    "# decreases size of data + makes it easier to fit into LSTM model\n",
    "df.drop(columns=['Tweet'], inplace=True)\n",
    "df = df.groupby(['MatchID', 'PeriodID', 'ID','chunk']).mean().reset_index()\n",
    "df.drop(columns=['ID'], inplace=True) \n",
    "df['MatchID'] = df['MatchID'].astype(int)\n",
    "df['PeriodID'] = df['PeriodID'].astype(int)\n",
    "# need to convert to int before sorting\n",
    "df.sort_values(by=['MatchID', 'PeriodID', 'chunk'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>chunk</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.057772532, 0.23096578, 0.07216391, -0.19907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.041801233, 0.15167381, 0.0639174, -0.114342...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.109296665, 0.26712674, 0.095571965, -0.1406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.07338316502192846, 0.23660319900283447, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276869e+12</td>\n",
       "      <td>[0.105503604, 0.24286334, 0.10696903, -0.17454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21365</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.12281445685245027, 0.24359074410450818, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21366</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.122550234, 0.25029683, 0.04034065, -0.05934...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21367</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.12122838, 0.23808606, 0.04404255, -0.045798...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21368</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.13335473583790153, 0.24798255305110292, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21369</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404168e+12</td>\n",
       "      <td>[0.12614599, 0.23498698, 0.04432407, -0.053685...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21370 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MatchID  PeriodID  chunk  EventType     Timestamp  \\\n",
       "0            0         0      0        0.0  1.276869e+12   \n",
       "1            0         0      1        0.0  1.276869e+12   \n",
       "2            0         0      2        0.0  1.276869e+12   \n",
       "3            0         0      3        0.0  1.276869e+12   \n",
       "4            0         0      4        0.0  1.276869e+12   \n",
       "...        ...       ...    ...        ...           ...   \n",
       "21365       15       169      5        0.0  1.404168e+12   \n",
       "21366       15       169      6        0.0  1.404168e+12   \n",
       "21367       15       169      7        0.0  1.404168e+12   \n",
       "21368       15       169      8        0.0  1.404168e+12   \n",
       "21369       15       169      9        0.0  1.404168e+12   \n",
       "\n",
       "                                            tweet_vector  \n",
       "0      [0.057772532, 0.23096578, 0.07216391, -0.19907...  \n",
       "1      [0.041801233, 0.15167381, 0.0639174, -0.114342...  \n",
       "2      [0.109296665, 0.26712674, 0.095571965, -0.1406...  \n",
       "3      [0.07338316502192846, 0.23660319900283447, 0.1...  \n",
       "4      [0.105503604, 0.24286334, 0.10696903, -0.17454...  \n",
       "...                                                  ...  \n",
       "21365  [0.12281445685245027, 0.24359074410450818, 0.0...  \n",
       "21366  [0.122550234, 0.25029683, 0.04034065, -0.05934...  \n",
       "21367  [0.12122838, 0.23808606, 0.04404255, -0.045798...  \n",
       "21368  [0.13335473583790153, 0.24798255305110292, 0.0...  \n",
       "21369  [0.12614599, 0.23498698, 0.04432407, -0.053685...  \n",
       "\n",
       "[21370 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.loc[df[\"EventType\"] != 0, \"EventType\"] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tweet_vector'] = df['tweet_vector'].swifter.apply(lambda v: v / np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = (\n",
    "    df.groupby(['MatchID', 'PeriodID'])\n",
    "    .agg(\n",
    "        period_matrix=('tweet_vector', lambda x: np.stack(x.to_numpy())),  # Stack the mean vectors\n",
    "        mean_event_type=('EventType', 'mean')  # Compute the mean event type\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'period_matrix': 'tweet_vector', 'mean_event_type':'EventType'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "      <th>EventType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.05777253210544586, 0.2309657782316208, 0.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.09481757879257202, 0.21990607678890228, 0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.14055303, 0.20796777, 0.15461813, -0.15855...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.10580117255449295, 0.19765836000442505, 0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.13657256960868835, 0.2028564214706421, 0.1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>[[0.12338580191135406, 0.23787692189216614, 0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>15</td>\n",
       "      <td>166</td>\n",
       "      <td>[[0.129442, 0.23737937, 0.051139485, -0.065910...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>[[0.12258135131051058, 0.23725832031364097, 0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>[[0.14088391, 0.23857994, 0.048132025, -0.0540...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>[[0.1338859498500824, 0.2394581288099289, 0.04...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID                                       tweet_vector  \\\n",
       "0           0         0  [[0.05777253210544586, 0.2309657782316208, 0.0...   \n",
       "1           0         1  [[0.09481757879257202, 0.21990607678890228, 0....   \n",
       "2           0         2  [[0.14055303, 0.20796777, 0.15461813, -0.15855...   \n",
       "3           0         3  [[0.10580117255449295, 0.19765836000442505, 0....   \n",
       "4           0         4  [[0.13657256960868835, 0.2028564214706421, 0.1...   \n",
       "...       ...       ...                                                ...   \n",
       "2132       15       165  [[0.12338580191135406, 0.23787692189216614, 0....   \n",
       "2133       15       166  [[0.129442, 0.23737937, 0.051139485, -0.065910...   \n",
       "2134       15       167  [[0.12258135131051058, 0.23725832031364097, 0....   \n",
       "2135       15       168  [[0.14088391, 0.23857994, 0.048132025, -0.0540...   \n",
       "2136       15       169  [[0.1338859498500824, 0.2394581288099289, 0.04...   \n",
       "\n",
       "      EventType  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           1.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "2132        1.0  \n",
       "2133        1.0  \n",
       "2134        1.0  \n",
       "2135        1.0  \n",
       "2136        0.0  \n",
       "\n",
       "[2137 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0uLXd2pz1CQ"
   },
   "source": [
    "# Separate Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# train on of the first 13 of 16 matches (16*0.8=12.8~=13)\n",
    "# and the test data would be the last 3 matches. \n",
    "# Before submitting on Kaggle we should train on full dataset, so al 16 matches\n",
    "train_percentage = 0.8\n",
    "unique_match_ids = df['MatchID'].unique()\n",
    "print(unique_match_ids)\n",
    "num_matches_training = int(ceil(len(unique_match_ids)*train_percentage))\n",
    "print(num_matches_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "target_match_id = num_matches_training\n",
    "# target_match_id is first match id that will appear in test set\n",
    "# all matches from target_match_id and after will be in test test\n",
    "print(target_match_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df2 = df['MatchID'] == 15\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_index is first row with match id target_match_id\n",
    "# row_index is then the first row of the matches that will go to the test\n",
    "\n",
    "\n",
    "row_index = (df['MatchID'] == target_match_id).idxmax()\n",
    "#row_index = df[df['MatchID'] == target_match_id].first_valid_index()\n",
    "df_X_train = df[:row_index].copy()\n",
    "df_X_test = df[row_index:].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train = df_X_train['EventType']\n",
    "df_y_test = df_X_test['EventType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       0.0\n",
       "       ... \n",
       "1702    1.0\n",
       "1703    1.0\n",
       "1704    1.0\n",
       "1705    1.0\n",
       "1706    1.0\n",
       "Name: EventType, Length: 1707, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      0.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      1.0\n",
       "      ... \n",
       "425    1.0\n",
       "426    1.0\n",
       "427    1.0\n",
       "428    1.0\n",
       "429    0.0\n",
       "Name: EventType, Length: 430, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test.reset_index(drop=True, inplace=True)\n",
    "df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train.drop(['EventType'], axis=1, inplace=True)\n",
    "df_X_test.drop(['EventType'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.05777253210544586, 0.2309657782316208, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.09481757879257202, 0.21990607678890228, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.14055303, 0.20796777, 0.15461813, -0.15855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.10580117255449295, 0.19765836000442505, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.13657256960868835, 0.2028564214706421, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>12</td>\n",
       "      <td>125</td>\n",
       "      <td>[[0.013565172, 0.21806225, 0.12027183, -0.1911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>[[0.019887732, 0.18984045, 0.12175157, -0.1859...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>[[0.013504726, 0.2305444, 0.10003953, -0.21081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>[[0.006752035, 0.23206353, 0.1094508, -0.21238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>[[0.017332336, 0.1544822, 0.1522759, -0.237889...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1707 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID                                       tweet_vector\n",
       "0           0         0  [[0.05777253210544586, 0.2309657782316208, 0.0...\n",
       "1           0         1  [[0.09481757879257202, 0.21990607678890228, 0....\n",
       "2           0         2  [[0.14055303, 0.20796777, 0.15461813, -0.15855...\n",
       "3           0         3  [[0.10580117255449295, 0.19765836000442505, 0....\n",
       "4           0         4  [[0.13657256960868835, 0.2028564214706421, 0.1...\n",
       "...       ...       ...                                                ...\n",
       "1702       12       125  [[0.013565172, 0.21806225, 0.12027183, -0.1911...\n",
       "1703       12       126  [[0.019887732, 0.18984045, 0.12175157, -0.1859...\n",
       "1704       12       127  [[0.013504726, 0.2305444, 0.10003953, -0.21081...\n",
       "1705       12       128  [[0.006752035, 0.23206353, 0.1094508, -0.21238...\n",
       "1706       12       129  [[0.017332336, 0.1544822, 0.1522759, -0.237889...\n",
       "\n",
       "[1707 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.1479858, 0.24614787, -0.03657544, -0.09510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.1741992, 0.24961157, -0.017150475, -0.0957...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.14361763, 0.26430285, -0.023285097, -0.092...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.157705, 0.23600611, -0.013279277, -0.09872...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.13839455, 0.1971522, -0.012201323, -0.1086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>[[0.12338580191135406, 0.23787692189216614, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>15</td>\n",
       "      <td>166</td>\n",
       "      <td>[[0.129442, 0.23737937, 0.051139485, -0.065910...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>[[0.12258135131051058, 0.23725832031364097, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>[[0.14088391, 0.23857994, 0.048132025, -0.0540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>[[0.1338859498500824, 0.2394581288099289, 0.04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MatchID  PeriodID                                       tweet_vector\n",
       "0         13         0  [[0.1479858, 0.24614787, -0.03657544, -0.09510...\n",
       "1         13         1  [[0.1741992, 0.24961157, -0.017150475, -0.0957...\n",
       "2         13         2  [[0.14361763, 0.26430285, -0.023285097, -0.092...\n",
       "3         13         3  [[0.157705, 0.23600611, -0.013279277, -0.09872...\n",
       "4         13         4  [[0.13839455, 0.1971522, -0.012201323, -0.1086...\n",
       "..       ...       ...                                                ...\n",
       "425       15       165  [[0.12338580191135406, 0.23787692189216614, 0....\n",
       "426       15       166  [[0.129442, 0.23737937, 0.051139485, -0.065910...\n",
       "427       15       167  [[0.12258135131051058, 0.23725832031364097, 0....\n",
       "428       15       168  [[0.14088391, 0.23857994, 0.048132025, -0.0540...\n",
       "429       15       169  [[0.1338859498500824, 0.2394581288099289, 0.04...\n",
       "\n",
       "[430 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test.reset_index(drop=True, inplace=True)\n",
    "df_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now df_X_train and df_X_test should have columns MatchID, PeriodID, tweet_vector. Tweet_vector is just 200 columns\n",
    "# df_y_train and df_y_test should have 1 column, EventType\n",
    "# the matchids are grouped together so all the rows of the same\n",
    "# match ids are grouped next to each other, and the periodID are ordered chronologically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working on my machine so I keep DF\n",
    "\n",
    "# now we have df_X_train, df_X_test, df_y_train, df_y_test\n",
    "# we no longer need df so we should free up the memory\n",
    "# del df  # remove reference to the original DataFrame\n",
    "# gc.collect()  # force garbage collection to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MatchID  PeriodID\n",
       "0         0       129\n",
       "1         1       129\n",
       "2         2       129\n",
       "3         3       179\n",
       "4         4        96\n",
       "5         5       129\n",
       "6         6       129\n",
       "7         7       129\n",
       "8         8       129\n",
       "9         9       129\n",
       "10       10       129\n",
       "11       11       129\n",
       "12       12       129"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X_train.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "max_periods\n",
    "# as we can see not every match has the same number of periods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MatchID  PeriodID\n",
       "0       13       129\n",
       "1       14       129\n",
       "2       15       169"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_periods = df_X_test.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "max_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data for PyTorch LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor for a PyTorch LSTM should have the shape of (when setting batch_first=True)\n",
    "# (batch_size, seq_len, num_features) when using the batch_first=True parameter\n",
    "# batch_size is number of sequences processed at once\n",
    "\n",
    "# TRY WITHOUT SLIDING WINDOW APPROACH\n",
    "#    which would mean batch size = number of matches\n",
    "#    much easier to format for LSTM as 3D tensor\n",
    "#    dimension of 3D tensor with batch_first=True:(batch_size = num_matches, seq_len = num_periods, num _features = 200)\n",
    "#    (match_id, period_id, num_features=200)\n",
    "#     not every match has the same number of periods!, so seq_len can vary between different matches\n",
    "#     fix: will have to pad with zeroes\n",
    "# we want tensor[match_id][period_id] to return list len 200 of corresponding tweet vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.05777253210544586, 0.2309657782316208, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.09481757879257202, 0.21990607678890228, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.14055303, 0.20796777, 0.15461813, -0.15855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.10580117255449295, 0.19765836000442505, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.13657256960868835, 0.2028564214706421, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>12</td>\n",
       "      <td>125</td>\n",
       "      <td>[[0.013565172, 0.21806225, 0.12027183, -0.1911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>[[0.019887732, 0.18984045, 0.12175157, -0.1859...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>[[0.013504726, 0.2305444, 0.10003953, -0.21081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>[[0.006752035, 0.23206353, 0.1094508, -0.21238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>[[0.017332336, 0.1544822, 0.1522759, -0.237889...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1707 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID                                       tweet_vector\n",
       "0           0         0  [[0.05777253210544586, 0.2309657782316208, 0.0...\n",
       "1           0         1  [[0.09481757879257202, 0.21990607678890228, 0....\n",
       "2           0         2  [[0.14055303, 0.20796777, 0.15461813, -0.15855...\n",
       "3           0         3  [[0.10580117255449295, 0.19765836000442505, 0....\n",
       "4           0         4  [[0.13657256960868835, 0.2028564214706421, 0.1...\n",
       "...       ...       ...                                                ...\n",
       "1702       12       125  [[0.013565172, 0.21806225, 0.12027183, -0.1911...\n",
       "1703       12       126  [[0.019887732, 0.18984045, 0.12175157, -0.1859...\n",
       "1704       12       127  [[0.013504726, 0.2305444, 0.10003953, -0.21081...\n",
       "1705       12       128  [[0.006752035, 0.23206353, 0.1094508, -0.21238...\n",
       "1706       12       129  [[0.017332336, 0.1544822, 0.1522759, -0.237889...\n",
       "\n",
       "[1707 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 1800, 200)\n",
      "(13, 180)\n"
     ]
    }
   ],
   "source": [
    "# modified for array tweet_vector column\n",
    "def convert_df_to_3D_tensor(df_X, df_y, max_num_period=None):\n",
    "    # df_X should have columns MatchID, PeriodID, tweet_vector. Tweet_vector is just 200x1 array\n",
    "    # rows with same matchID should be grouped together (adjacent rows)\n",
    "    # df_y should have one column (the EventType)\n",
    "    # returns tensor_X numpy array already padded! shape: (num_matches, max_num_periods, num _features = 200)\n",
    "    # and tensor_y of shape: (num_matches, max_num_periods)\n",
    "    num_matches = len(df_X['MatchID'].unique())\n",
    "    max_periods = df_X.groupby('MatchID')['PeriodID'].max().reset_index()\n",
    "    total_max_period = max_periods['PeriodID'].max()\n",
    "    if max_num_period is None:\n",
    "        max_num_period = total_max_period + 1\n",
    "    #total_max_period is max seq len\n",
    "\n",
    "    tensor_X = np.zeros((num_matches, max_num_period*period_chunks, 200))\n",
    "\n",
    "    tensor_y = np.zeros((num_matches, max_num_period))\n",
    "    print(tensor_X.shape)\n",
    "    print(tensor_y.shape)\n",
    "    \n",
    "    i=0\n",
    "    previous_match_id = df_X['MatchID'][0]\n",
    "    for row_index, row in df_X.iterrows():\n",
    "        match_id = int(row['MatchID'])\n",
    "\n",
    "        if match_id != previous_match_id:\n",
    "            i+=1\n",
    "            previous_match_id = match_id\n",
    "        \n",
    "        period_id = int(row['PeriodID'])\n",
    "        p_i = period_id * period_chunks\n",
    "        p_i_end = p_i + period_chunks\n",
    "        \n",
    "        features = row['tweet_vector']  # Skip MatchID and PeriodID\n",
    "        tensor_X[i, p_i:p_i_end, :] = features\n",
    "        tensor_y[i,period_id] = df_y[row_index]\n",
    "        \n",
    "    return tensor_X, tensor_y\n",
    "\n",
    "\n",
    "X_train_tensor, y_train_tensor = convert_df_to_3D_tensor(df_X_train, df_y_train)\n",
    "# X_train_tensor[match_id][period_id] to return list len 200 of corresponding tweet vector\n",
    "# y_train_tensor[match_id][period_id] to return corresponding EventType (1 or 0)\n",
    "# match_id index starts at 0 even if first match in df doesnt have match id 0\n",
    "#X_train_tensor[12][175]\n",
    "#X_train_tensor[12][179]\n",
    "#X_train_tensor[2][129]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train_tensor[0][3])\n",
    "#print(y_train_tensor[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 1800, 200])\n",
      "torch.Size([13, 180])\n"
     ]
    }
   ],
   "source": [
    "# SCALE DATA? minmaxscaler for example!\n",
    "# SCALING MIGHT BE UNNECESSARY SINCE OUTPUT OF GLOVE TWEET 200 IS ALREADY SCALED BETWEEN -1 AND 1\n",
    "#scaler = MinMaxScaler()\n",
    "#tensor = scaler.fit_transform(tensor)\n",
    "\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_train_tensor = torch.tensor(X_train_tensor, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_tensor, dtype=torch.float32)\n",
    "\n",
    "print(X_train_tensor.shape)\n",
    "print(y_train_tensor.shape)\n",
    "# X_train_tensor, y_train_tensor are now pytorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO VERIFY ITS CORRECT + MAKE MORE SOPHISTICATED\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out)\n",
    "        out = out[:,0::period_chunks,:]\n",
    "        out = self.sigmoid(out) # applying sigmoid to convert to probabilities\n",
    "        return out.squeeze(-1)\n",
    "\n",
    "#TODOOOOOOOOOO torch.nn.utils.rnn.pack_padded_sequence. This allows the model to ignore the padded values during computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "batch_size = 120\n",
    "hidden_size = 300 # can tune\n",
    "num_layers = 2 # can tune\n",
    "dropout_rate = 0.75 # can tune\n",
    "num_epochs = 300 # can tune\n",
    "lr = 0.0003 # can tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idxs = list(range(0,X_train_tensor.shape[0],batch_size))\n",
    "batched_data = []\n",
    "for idx in batch_idxs:\n",
    "    batched_data.append((X_train_tensor[idx:idx+batch_size], y_train_tensor[idx:idx+batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1800, 200)\n",
      "(3, 180)\n"
     ]
    }
   ],
   "source": [
    "# convert df_X_test and df_y_test to correct format/dimensions\n",
    "X_test_tensor, y_test_tensor = convert_df_to_3D_tensor(df_X_test, df_y_test, max_num_period=180)\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_test_tensor = torch.tensor(X_test_tensor, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/300], Loss: 0.6976 Eval Loss: 0.6970\n",
      "Epoch [10/300], Loss: 0.6567 Eval Loss: 0.6758\n",
      "Epoch [20/300], Loss: 0.4884 Eval Loss: 0.5638\n",
      "Epoch [30/300], Loss: 0.4883 Eval Loss: 0.5552\n",
      "Epoch [40/300], Loss: 0.4777 Eval Loss: 0.5484\n",
      "Epoch [50/300], Loss: 0.4674 Eval Loss: 0.5372\n",
      "Epoch [60/300], Loss: 0.4545 Eval Loss: 0.5347\n",
      "Epoch [70/300], Loss: 0.4457 Eval Loss: 0.5242\n",
      "Epoch [80/300], Loss: 0.4374 Eval Loss: 0.5093\n",
      "Epoch [90/300], Loss: 0.4325 Eval Loss: 0.5097\n",
      "Epoch [100/300], Loss: 0.4272 Eval Loss: 0.5046\n",
      "Epoch [110/300], Loss: 0.4192 Eval Loss: 0.4999\n",
      "Epoch [120/300], Loss: 0.4136 Eval Loss: 0.5020\n",
      "Epoch [130/300], Loss: 0.4091 Eval Loss: 0.5124\n",
      "Epoch [140/300], Loss: 0.4066 Eval Loss: 0.5204\n",
      "Epoch [150/300], Loss: 0.4055 Eval Loss: 0.4998\n",
      "Epoch [160/300], Loss: 0.4013 Eval Loss: 0.4854\n",
      "Epoch [170/300], Loss: 0.3946 Eval Loss: 0.4920\n",
      "Epoch [180/300], Loss: 0.3963 Eval Loss: 0.5159\n",
      "Epoch [190/300], Loss: 0.3881 Eval Loss: 0.4975\n",
      "Epoch [200/300], Loss: 0.4102 Eval Loss: 0.4847\n",
      "Epoch [210/300], Loss: 0.5646 Eval Loss: 0.4900\n",
      "Epoch [220/300], Loss: 0.3860 Eval Loss: 0.4993\n",
      "Epoch [230/300], Loss: 0.3924 Eval Loss: 0.5207\n",
      "Epoch [240/300], Loss: 0.3752 Eval Loss: 0.5249\n",
      "Epoch [250/300], Loss: 0.4257 Eval Loss: 0.5315\n",
      "Epoch [260/300], Loss: 0.3956 Eval Loss: 0.5028\n",
      "Epoch [270/300], Loss: 0.3859 Eval Loss: 0.4867\n",
      "Epoch [280/300], Loss: 0.3801 Eval Loss: 0.5103\n",
      "Epoch [290/300], Loss: 0.3713 Eval Loss: 0.5178\n",
      "Model is trained! (on training data)\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_size=200, hidden_size=hidden_size, num_layers=num_layers, dropout_rate=dropout_rate)\n",
    "model = model.to(gpu)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss() # great for binary classification\n",
    "criterion = criterion.to(gpu)\n",
    "#print(f\"Shape of X_train_tensor: {X_train_tensor.shape}\")\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    for train, label in batched_data:\n",
    "        train = train.to(gpu)\n",
    "        label = label.to(gpu)\n",
    "        outputs = model(train)\n",
    "        #print(f\"shape of outputs: {outputs.shape}\")\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            predict = model(X_test_tensor.to(gpu))\n",
    "            e_loss = criterion(predict, y_test_tensor.to(gpu))\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\", f\"Eval Loss: {e_loss.item():.4f}\")\n",
    "\n",
    "print(\"Model is trained! (on training data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test_tensor[2][129])\n",
    "#print(y_test_tensor[2][129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(gpu)).to('cpu')\n",
    "\n",
    "# predictions have values between 0 and 1 because forward pass of LSTM contains sigmoid at output\n",
    "#print(predictions)\n",
    "\n",
    "predicted_classes = (predictions > 0.5).float() # 0.5 is threshold\n",
    "#this converts to same dimensional array of True or false, and .float() converts True to 1 and False to 0\n",
    "\n",
    "#print(predicted_classes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross-Entropy Loss: 0.5183\n",
      "Accuracy: 73.8889\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "\n",
    "loss = criterion(predictions, y_test_tensor) # use predictions for loss calculation\n",
    "\n",
    "print(f\"Binary Cross-Entropy Loss: {loss.item():.4f}\")\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    if y_true.dtype != y_pred.dtype or y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Inputs do not have same type or shape!\")\n",
    "    y_rand = torch.randint(0,2,y_true.shape)\n",
    "    correct_predictions = (y_true == y_pred).sum().item()\n",
    "    total_predictions = y_true.numel()\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    return accuracy\n",
    "accuracy = accuracy(y_test_tensor, predicted_classes)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "#print(y_test_tensor.shape)\n",
    "#print(predicted_classes.shape)\n",
    "\n",
    "\n",
    "# Visualization of Actual vs Predicted Classes\n",
    "# import matplotlib.pyplot as plt\n",
    "# TODO COULD USE PLT TO VISUALIZE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRAIN MODEL ON ENTIRE TRAINING DATA AND EVALUATE EVAL TWEETS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_X = pd.concat([df_X_train, df_X_test], ignore_index=True)\n",
    "df_y = pd.concat([df_y_train, df_y_test], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.05777253210544586, 0.2309657782316208, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.09481757879257202, 0.21990607678890228, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.14055303, 0.20796777, 0.15461813, -0.15855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.10580117255449295, 0.19765836000442505, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.13657256960868835, 0.2028564214706421, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>[[0.12338580191135406, 0.23787692189216614, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>15</td>\n",
       "      <td>166</td>\n",
       "      <td>[[0.129442, 0.23737937, 0.051139485, -0.065910...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>[[0.12258135131051058, 0.23725832031364097, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>[[0.14088391, 0.23857994, 0.048132025, -0.0540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>[[0.1338859498500824, 0.2394581288099289, 0.04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID                                       tweet_vector\n",
       "0           0         0  [[0.05777253210544586, 0.2309657782316208, 0.0...\n",
       "1           0         1  [[0.09481757879257202, 0.21990607678890228, 0....\n",
       "2           0         2  [[0.14055303, 0.20796777, 0.15461813, -0.15855...\n",
       "3           0         3  [[0.10580117255449295, 0.19765836000442505, 0....\n",
       "4           0         4  [[0.13657256960868835, 0.2028564214706421, 0.1...\n",
       "...       ...       ...                                                ...\n",
       "2132       15       165  [[0.12338580191135406, 0.23787692189216614, 0....\n",
       "2133       15       166  [[0.129442, 0.23737937, 0.051139485, -0.065910...\n",
       "2134       15       167  [[0.12258135131051058, 0.23725832031364097, 0....\n",
       "2135       15       168  [[0.14088391, 0.23857994, 0.048132025, -0.0540...\n",
       "2136       15       169  [[0.1338859498500824, 0.2394581288099289, 0.04...\n",
       "\n",
       "[2137 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       0.0\n",
       "       ... \n",
       "2132    1.0\n",
       "2133    1.0\n",
       "2134    1.0\n",
       "2135    1.0\n",
       "2136    0.0\n",
       "Name: EventType, Length: 2137, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1800, 200)\n",
      "(16, 180)\n"
     ]
    }
   ],
   "source": [
    "# convert df_X_test and df_y_test to correct format/dimensions\n",
    "X_tensor, y_tensor = convert_df_to_3D_tensor(df_X, df_y)\n",
    "# CONVERT TO PYTORCH TENSOR\n",
    "X_tensor = torch.tensor(X_tensor, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "et9Eb8hEz1aC"
   },
   "outputs": [],
   "source": [
    "# NOTES\n",
    "# HOW TO MAKE SURE THAT we:\n",
    "# 1. DO NOT ignore the order of the tweets -> (LSTM)\n",
    "# 2. treat each time period as RELATED to the football match they belong to -> treat each match as a sequence, train LSTM on every sequence\n",
    "#                      since pytorch tensor expects multiple sequences (batches)\n",
    "\n",
    "\n",
    "\n",
    "# for LSTM: Each input sequence should consist of tweets from a specific match, ordered by Period ID.\n",
    "#   tweets of different matches are unrelated, but tweets of a same match are related sequentially (chronologically)\n",
    "#   structure training data such that tweets are grouped by match id, and ordered by period id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batch_idxs = list(range(0,X_tensor.shape[0],batch_size))\n",
    "batched_data = []\n",
    "for idx in batch_idxs:\n",
    "    batched_data.append((X_tensor[idx:idx+batch_size], y_tensor[idx:idx+batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/300], Loss: 0.6928\n",
      "Epoch [10/300], Loss: 0.6486\n",
      "Epoch [20/300], Loss: 0.4979\n",
      "Epoch [30/300], Loss: 0.4773\n",
      "Epoch [40/300], Loss: 0.4682\n",
      "Epoch [50/300], Loss: 0.4583\n",
      "Epoch [60/300], Loss: 0.4494\n",
      "Epoch [70/300], Loss: 0.4425\n",
      "Epoch [80/300], Loss: 0.4337\n",
      "Epoch [90/300], Loss: 0.4267\n",
      "Epoch [100/300], Loss: 0.4194\n",
      "Epoch [110/300], Loss: 0.4155\n",
      "Epoch [120/300], Loss: 0.4160\n",
      "Epoch [130/300], Loss: 0.4053\n",
      "Epoch [140/300], Loss: 0.4065\n",
      "Epoch [150/300], Loss: 0.4009\n",
      "Epoch [160/300], Loss: 0.3984\n",
      "Epoch [170/300], Loss: 0.3925\n",
      "Epoch [180/300], Loss: 0.3893\n",
      "Epoch [190/300], Loss: 0.6507\n",
      "Epoch [200/300], Loss: 0.5389\n",
      "Epoch [210/300], Loss: 0.4928\n",
      "Epoch [220/300], Loss: 0.4786\n",
      "Epoch [230/300], Loss: 0.4825\n",
      "Epoch [240/300], Loss: 0.4740\n",
      "Epoch [250/300], Loss: 0.4595\n",
      "Epoch [260/300], Loss: 0.4395\n",
      "Epoch [270/300], Loss: 0.4322\n",
      "Epoch [280/300], Loss: 0.4280\n",
      "Epoch [290/300], Loss: 0.4183\n",
      "Model is trained! (on training data)\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_size=200, hidden_size=hidden_size, num_layers=num_layers, dropout_rate=dropout_rate)\n",
    "model = model.to(gpu)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss() # great for binary classification\n",
    "criterion = criterion.to(gpu)\n",
    "#print(f\"Shape of X_train_tensor: {X_train_tensor.shape}\")\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    for train, label in batched_data:\n",
    "        train = train.to(gpu)\n",
    "        label = label.to(gpu)\n",
    "        outputs = model(train)\n",
    "        #print(f\"shape of outputs: {outputs.shape}\")\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Model is trained! (on training data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreeceIvoryCoast44.csv\n",
      "NetherlandsMexico64.csv\n",
      "GermanyGhana32.csv\n",
      "GermanySerbia2010.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>Wana place a bet on an ivory coast win but ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>#WatchLive @FIFAWorldCup: Greece vs. Ivory Coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>Gonna watch the Colombia and Japan game becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>#CIV vs #COL &amp; #GRE vs #JPN! It would be inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9_0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1403639400000</td>\n",
       "      <td>RT @DuncanCastles: Quite a statistic this: Gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072923</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>LETS GO #USA #worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072924</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>another upset in #WC2010 #Srb beat #Ger by 1-0 !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072925</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>RT @FIFAcom: #GER 0:1 #SRB: TheÂ finalÂ whistl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072926</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>dukung yg menang -_- RT @AlikaZahira: #bra #fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072927</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>1276867800000</td>\n",
       "      <td>Serbia win?wow...unexpected,hm? #worldcup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072928 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  MatchID  PeriodID      Timestamp  \\\n",
       "0           9_0        9         0  1403639400000   \n",
       "1           9_0        9         0  1403639400000   \n",
       "2           9_0        9         0  1403639400000   \n",
       "3           9_0        9         0  1403639400000   \n",
       "4           9_0        9         0  1403639400000   \n",
       "...         ...      ...       ...            ...   \n",
       "1072923  16_129       16       129  1276867800000   \n",
       "1072924  16_129       16       129  1276867800000   \n",
       "1072925  16_129       16       129  1276867800000   \n",
       "1072926  16_129       16       129  1276867800000   \n",
       "1072927  16_129       16       129  1276867800000   \n",
       "\n",
       "                                                     Tweet  \n",
       "0        Wana place a bet on an ivory coast win but ain...  \n",
       "1        #WatchLive @FIFAWorldCup: Greece vs. Ivory Coa...  \n",
       "2        Gonna watch the Colombia and Japan game becaus...  \n",
       "3        #CIV vs #COL & #GRE vs #JPN! It would be inter...  \n",
       "4        RT @DuncanCastles: Quite a statistic this: Gre...  \n",
       "...                                                    ...  \n",
       "1072923                             LETS GO #USA #worldcup  \n",
       "1072924  another upset in #WC2010 #Srb beat #Ger by 1-0 !!  \n",
       "1072925  RT @FIFAcom: #GER 0:1 #SRB: TheÂ finalÂ whistl...  \n",
       "1072926  dukung yg menang -_- RT @AlikaZahira: #bra #fr...  \n",
       "1072927          Serbia win?wow...unexpected,hm? #worldcup  \n",
       "\n",
       "[1072928 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all training files and concatenate them into one dataframe\n",
    "\n",
    "#import os\n",
    "#print(os.getcwd())\n",
    "\n",
    "li = []\n",
    "i = 0\n",
    "for filename in listdir(\"eval_tweets\"):\n",
    "    if filename != '.ipynb_checkpoints':\n",
    "        print(filename)\n",
    "        df = pd.read_csv(\"eval_tweets/\" + filename)\n",
    "        # df.drop(columns=['Timestamp'], inplace=True)\n",
    "        # drop unused column(s)\n",
    "        # makes sure that the match IDs are ordered from 0,1,2... with no missing values\n",
    "        i+=1\n",
    "        li.append(df)\n",
    "eval_df = pd.concat(li, ignore_index=True)\n",
    "#print(len(df))\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1072928/1072928 [00:37<00:00, 28765.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to each tweet\n",
    "eval_df['Tweet'] = preprocess_series(eval_df['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1072928/1072928 [00:30<00:00, 35577.16it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_df[\"tweet_vector\"] = gen_avg_embeddings(eval_df['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1281451/3165773019.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  eval_df['chunk'] = eval_df.groupby(['MatchID', 'PeriodID']).apply(\n"
     ]
    }
   ],
   "source": [
    "# Sort by MatchID, PeriodID, and Timestamp to maintain order\n",
    "eval_df = eval_df.sort_values(by=['MatchID', 'PeriodID', 'Timestamp']).reset_index(drop=True)\n",
    "\n",
    "# Helper function to assign chunks\n",
    "def assign_chunks(group, n_chunks=10):\n",
    "    chunk_size = len(group) / n_chunks\n",
    "    return (np.floor(np.arange(len(group)) / chunk_size)).astype(int)\n",
    "\n",
    "# Apply chunk assignment within each MatchID and PeriodID\n",
    "eval_df['chunk'] = eval_df.groupby(['MatchID', 'PeriodID']).apply(\n",
    "    lambda group: assign_chunks(group)\n",
    ").explode().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.drop(columns=['Tweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the tweets into their corresponding periods to generate an average embedding vector for each period\n",
    "# so there are no duplicate period id rows per match\n",
    "# decreases size of data + makes it easier to fit into LSTM model\n",
    "eval_df = eval_df.groupby(['MatchID', 'PeriodID', 'ID','chunk']).mean().reset_index()\n",
    "eval_df.drop(columns=['ID'], inplace=True) \n",
    "eval_df['MatchID'] = eval_df['MatchID'].astype(int)\n",
    "eval_df['PeriodID'] = eval_df['PeriodID'].astype(int)\n",
    "# need to convert to int before sorting\n",
    "eval_df.sort_values(by=['MatchID', 'PeriodID', 'chunk'], inplace=True)\n",
    "eval_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_agg = (\n",
    "    eval_df.groupby(['MatchID', 'PeriodID'])\n",
    "    .agg(\n",
    "        period_matrix=('tweet_vector', lambda x: np.stack(x.to_numpy())),  # Stack the mean vectors\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.rename(columns={'period_matrix': 'tweet_vector'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.16653539, 0.26003703, 0.059985828, -0.0924...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.15020987, 0.2654425, 0.05469284, -0.114660...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.16435114, 0.27378768, 0.05723621, -0.10151...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.17175293896567598, 0.27191852900369834, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.15491624, 0.28381658, 0.058633655, -0.0947...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>16</td>\n",
       "      <td>125</td>\n",
       "      <td>[[0.09658312052488327, 0.2646336853504181, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>16</td>\n",
       "      <td>126</td>\n",
       "      <td>[[0.07132586327974091, 0.2369798426262357, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>16</td>\n",
       "      <td>127</td>\n",
       "      <td>[[0.08168929815292358, 0.2357352077960968, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>[[0.13000393, 0.25957957, 0.109353416, -0.1556...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>[[0.09243842, 0.21740317, 0.14894113, -0.09702...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MatchID  PeriodID                                       tweet_vector\n",
       "0          6         0  [[0.16653539, 0.26003703, 0.059985828, -0.0924...\n",
       "1          6         1  [[0.15020987, 0.2654425, 0.05469284, -0.114660...\n",
       "2          6         2  [[0.16435114, 0.27378768, 0.05723621, -0.10151...\n",
       "3          6         3  [[0.17175293896567598, 0.27191852900369834, 0....\n",
       "4          6         4  [[0.15491624, 0.28381658, 0.058633655, -0.0947...\n",
       "..       ...       ...                                                ...\n",
       "511       16       125  [[0.09658312052488327, 0.2646336853504181, 0.1...\n",
       "512       16       126  [[0.07132586327974091, 0.2369798426262357, 0.0...\n",
       "513       16       127  [[0.08168929815292358, 0.2357352077960968, 0.1...\n",
       "514       16       128  [[0.13000393, 0.25957957, 0.109353416, -0.1556...\n",
       "515       16       129  [[0.09243842, 0.21740317, 0.14894113, -0.09702...\n",
       "\n",
       "[516 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matches = len(eval_df['MatchID'].unique())\n",
    "eval_X = np.zeros((num_matches, 180*period_chunks, 200))\n",
    "i=0\n",
    "previous_match_id = eval_df['MatchID'][0]\n",
    "for row_index, row in eval_df.iterrows():\n",
    "    match_id = int(row['MatchID'])\n",
    "\n",
    "    if match_id != previous_match_id:\n",
    "        i+=1\n",
    "        previous_match_id = match_id\n",
    "    \n",
    "    period_id = int(row['PeriodID'])\n",
    "    p_i = period_id * period_chunks\n",
    "    p_i_end = p_i + period_chunks\n",
    "    \n",
    "    features = row['tweet_vector']  # Skip MatchID and PeriodID\n",
    "    eval_X[i, p_i:p_i_end, :] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_X = torch.tensor(eval_X, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "eval_predictions = model(eval_X.to(gpu)).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_predicted_classes = (eval_predictions > 0.4).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "eval_df['ID'] = eval_df.apply(lambda row: str(row.MatchID) + '_' + str(row.PeriodID), axis=1)\n",
    "match_ids = {6 : 0, 9 : 1, 15 : 2, 16 : 3}\n",
    "sorted_predictions = []\n",
    "for row_index, row in eval_df.iterrows():\n",
    "    sorted_predictions.append(float(eval_predicted_classes[match_ids[int(row[\"MatchID\"])], int(row[\"PeriodID\"])]))\n",
    "\n",
    "prediction_tab = pd.DataFrame(eval_df[[\"ID\"]])\n",
    "prediction_tab[\"EventType\"] = sorted_predictions\n",
    "\n",
    "submission_filename = \"test_submissions/Submission \" + datetime.datetime.now().strftime(\"%d%m-%H%M%S\") + \".csv\"\n",
    "\n",
    "prediction_tab.to_csv(submission_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
